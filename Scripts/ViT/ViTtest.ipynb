{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ViT CIFAR-10 Evaluation Pipeline\n",
      "==================================================\n",
      "[INFO] Using device: cuda\n",
      "[INFO] GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "[INFO] Available memory: 6.44 GB\n",
      "[INFO] Preparing test dataset...\n",
      "Files already downloaded and verified\n",
      "[INFO] Test dataset loaded with 10000 samples\n",
      "[INFO] Creating DataLoader...\n",
      "[INFO] DataLoader created with batch size 8\n",
      "[INFO] Loading model from: C:\\Users\\Gading\\Downloads\\Research\\Models\\ViT\\checkpoints\\vit_b16_teacher_20250507_234740_best.pth\n",
      "[INFO] Model loaded successfully and set to evaluation mode\n",
      "[INFO] Running inference on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 1250/1250 [05:45<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inference complete on 10000 samples\n",
      "[INFO] Analyzing model performance...\n",
      "[RESULT] Test Accuracy: 92.47%\n",
      "[RESULT] Log Loss: 0.2297\n",
      "[RESULT] F1 Score (Macro): 0.9245\n",
      "[RESULT] F1 Score (Weighted): 0.9245\n",
      "[RESULT] Precision (Macro): 0.9251\n",
      "[RESULT] Precision (Weighted): 0.9251\n",
      "[RESULT] Recall (Macro): 0.9247\n",
      "[RESULT] Recall (Weighted): 0.9247\n",
      "\n",
      "[RESULT] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane      0.930     0.945     0.938      1000\n",
      "  automobile      0.918     0.979     0.947      1000\n",
      "        bird      0.920     0.907     0.913      1000\n",
      "         cat      0.860     0.832     0.846      1000\n",
      "        deer      0.940     0.918     0.929      1000\n",
      "         dog      0.870     0.882     0.876      1000\n",
      "        frog      0.923     0.977     0.949      1000\n",
      "       horse      0.947     0.955     0.951      1000\n",
      "        ship      0.971     0.944     0.957      1000\n",
      "       truck      0.973     0.908     0.939      1000\n",
      "\n",
      "    accuracy                          0.925     10000\n",
      "   macro avg      0.925     0.925     0.925     10000\n",
      "weighted avg      0.925     0.925     0.925     10000\n",
      "\n",
      "[INFO] Evaluation results saved to output\n",
      "[INFO] Generating prediction visualizations...\n",
      "[INFO] Prediction visualizations saved to output/prediction_examples.png\n",
      "[INFO] Generating GradCAM visualizations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding class samples:   0%|          | 25/10000 [00:00<00:11, 847.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Generating GradCAM for class 'airplane'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Generating GradCAM for class 'automobile'\n",
      "[INFO] Generating GradCAM for class 'bird'\n",
      "[INFO] Generating GradCAM for class 'cat'\n",
      "[INFO] Generating GradCAM for class 'deer'\n",
      "[INFO] Generating GradCAM for class 'dog'\n",
      "[INFO] Generating GradCAM for class 'frog'\n",
      "[INFO] Generating GradCAM for class 'horse'\n",
      "[INFO] Generating GradCAM for class 'ship'\n",
      "[INFO] Generating GradCAM for class 'truck'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gading\\AppData\\Local\\Temp\\ipykernel_9280\\3212437095.py:581: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] GradCAM visualizations saved to output/gradcam_visualization.png\n",
      "==================================================\n",
      "Evaluation completed successfully with 92.47% accuracy\n",
      "All results saved to 'output' directory\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.amp import autocast\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.metrics import confusion_matrix, classification_report, log_loss, f1_score, precision_score, recall_score\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set the style for plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Set environment variables for better performance\n",
    "os.environ['OMP_NUM_THREADS'] = '4'  # Optimize CPU threading\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'  # Limit memory fragmentation\n",
    "\n",
    "\n",
    "####################################\n",
    "# 1. Configuration Class\n",
    "####################################\n",
    "class EvalConfig:\n",
    "    def __init__(self):\n",
    "        # Paths\n",
    "        self.dataset_path = r\"C:\\Users\\Gading\\Downloads\\Research\\Dataset\\CIFAR-10\"\n",
    "        self.checkpoint_path = r\"C:\\Users\\Gading\\Downloads\\Research\\Models\\ViT\\checkpoints\\vit_b16_teacher_20250507_234740_best.pth\"\n",
    "        self.output_dir = \"output\"\n",
    "        \n",
    "        # Hardware settings - optimized for stability\n",
    "        self.batch_size = 8  # Reduced for stability\n",
    "        self.num_workers = 0  # Start with 0 workers to avoid hanging\n",
    "        self.use_amp = True\n",
    "        self.pin_memory = True\n",
    "        \n",
    "        # CIFAR-10 classes\n",
    "        self.classes = ('airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "                        'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "        \n",
    "        # ImageNet normalization (used by ViT)\n",
    "        self.mean = [0.485, 0.456, 0.406]\n",
    "        self.std = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "####################################\n",
    "# 2. Utilities\n",
    "####################################\n",
    "def setup_environment():\n",
    "    \"\"\"Setup environment and output directory\"\"\"\n",
    "    # Create output directory\n",
    "    config = EvalConfig()\n",
    "    os.makedirs(config.output_dir, exist_ok=True)\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"[INFO] Using device: {device}\")\n",
    "    \n",
    "    # Show GPU info if available\n",
    "    if device.type == 'cuda':\n",
    "        print(f\"[INFO] GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"[INFO] Available memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    \n",
    "    return config, device\n",
    "\n",
    "\n",
    "####################################\n",
    "# 3. Dataset and DataLoader\n",
    "####################################\n",
    "def get_test_dataset(config):\n",
    "    \"\"\"Create a simple CIFAR-10 test dataset\"\"\"\n",
    "    print(\"[INFO] Preparing test dataset...\")\n",
    "    \n",
    "    # Model transform: resize to 224x224 and normalize\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(224, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=config.mean, std=config.std),\n",
    "    ])\n",
    "    \n",
    "    # Load the dataset\n",
    "    try:\n",
    "        test_dataset = datasets.CIFAR10(\n",
    "            root=config.dataset_path,\n",
    "            train=False,\n",
    "            download=True,  # Always attempt to download\n",
    "            transform=transform\n",
    "        )\n",
    "        print(f\"[INFO] Test dataset loaded with {len(test_dataset)} samples\")\n",
    "        return test_dataset\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to load dataset: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def get_original_images(config, indices):\n",
    "    \"\"\"Get original 32x32 images for display purposes\"\"\"\n",
    "    # Load dataset without transformations\n",
    "    orig_dataset = datasets.CIFAR10(\n",
    "        root=config.dataset_path,\n",
    "        train=False,\n",
    "        download=False  # Already downloaded\n",
    "    )\n",
    "    \n",
    "    originals = []\n",
    "    labels = []\n",
    "    \n",
    "    for idx in indices:\n",
    "        img, label = orig_dataset.data[idx], orig_dataset.targets[idx]\n",
    "        img = Image.fromarray(img)\n",
    "        img_tensor = transforms.ToTensor()(img)\n",
    "        originals.append(img_tensor)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return originals, labels\n",
    "\n",
    "\n",
    "def create_data_loader(dataset, config):\n",
    "    \"\"\"Create a DataLoader with optimized settings\"\"\"\n",
    "    print(\"[INFO] Creating DataLoader...\")\n",
    "    \n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=config.pin_memory,\n",
    "        persistent_workers=False,  # Avoid hanging issues\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    print(f\"[INFO] DataLoader created with batch size {config.batch_size}\")\n",
    "    return loader\n",
    "\n",
    "\n",
    "####################################\n",
    "# 4. Model Loading\n",
    "####################################\n",
    "def load_model(config, device):\n",
    "    \"\"\"Load the ViT model from checkpoint\"\"\"\n",
    "    print(f\"[INFO] Loading model from: {config.checkpoint_path}\")\n",
    "    \n",
    "    try:\n",
    "        import torch.nn as nn\n",
    "        from torchvision.models import vit_b_16\n",
    "        \n",
    "        # Create model architecture\n",
    "        model = vit_b_16(weights=None)\n",
    "        in_features = model.heads.head.in_features\n",
    "        model.heads.head = nn.Linear(in_features, 10)  # CIFAR-10 has 10 classes\n",
    "        \n",
    "        # Load checkpoint with safety settings\n",
    "        checkpoint = torch.load(\n",
    "            config.checkpoint_path, \n",
    "            map_location=device,\n",
    "            weights_only=True  # Safer loading\n",
    "        )\n",
    "        \n",
    "        # Handle different checkpoint formats\n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint)\n",
    "        \n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        print(\"[INFO] Model loaded successfully and set to evaluation mode\")\n",
    "        \n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to load model: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "####################################\n",
    "# 5. Inference\n",
    "####################################\n",
    "def run_inference(model, loader, config, device):\n",
    "    \"\"\"Run inference on the test set\"\"\"\n",
    "    print(\"[INFO] Running inference on test set...\")\n",
    "    \n",
    "    # Store predictions and targets\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Disable gradient computation for inference\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(loader, desc=\"Evaluation\"):\n",
    "            # Move data to device\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Use mixed precision if available and enabled\n",
    "            if config.use_amp and device.type == 'cuda':\n",
    "                with autocast(device_type='cuda'):\n",
    "                    outputs = model(images)\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "            \n",
    "            # Get predictions\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(probs, dim=1)\n",
    "            \n",
    "            # Store results (on CPU to save GPU memory)\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "            \n",
    "            # Free memory\n",
    "            del images, outputs, probs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_probs = np.concatenate(all_probs, axis=0)\n",
    "    \n",
    "    print(f\"[INFO] Inference complete on {len(all_targets)} samples\")\n",
    "    return np.array(all_targets), np.array(all_preds), all_probs\n",
    "\n",
    "\n",
    "####################################\n",
    "# 6. Evaluation Metrics\n",
    "####################################\n",
    "def analyze_results(y_true, y_pred, y_probs, class_names, config):\n",
    "    \"\"\"Generate and save evaluation metrics\"\"\"\n",
    "    print(\"[INFO] Analyzing model performance...\")\n",
    "    \n",
    "    # 1. Calculate and print accuracy\n",
    "    accuracy = np.mean(y_true == y_pred) * 100\n",
    "    print(f\"[RESULT] Test Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    logloss = log_loss(y_true, y_probs, labels=np.arange(len(class_names)))\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    precision_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    precision_weighted = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    recall_weighted = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"[RESULT] Log Loss: {logloss:.4f}\")\n",
    "    print(f\"[RESULT] F1 Score (Macro): {f1_macro:.4f}\")\n",
    "    print(f\"[RESULT] F1 Score (Weighted): {f1_weighted:.4f}\")\n",
    "    print(f\"[RESULT] Precision (Macro): {precision_macro:.4f}\")\n",
    "    print(f\"[RESULT] Precision (Weighted): {precision_weighted:.4f}\")\n",
    "    print(f\"[RESULT] Recall (Macro): {recall_macro:.4f}\")\n",
    "    print(f\"[RESULT] Recall (Weighted): {recall_weighted:.4f}\")\n",
    "    \n",
    "    # 2. Generate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f\"Confusion Matrix - CIFAR-10 (Accuracy: {accuracy:.2f}%)\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{config.output_dir}/confusion_matrix.png\", dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Generate classification report\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names, digits=3)\n",
    "    print(\"\\n[RESULT] Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    # Save report to file\n",
    "    with open(f\"{config.output_dir}/classification_report.txt\", \"w\") as f:\n",
    "        f.write(f\"Test Accuracy: {accuracy:.2f}%\\n\")\n",
    "        f.write(f\"Log Loss: {logloss:.4f}\\n\")\n",
    "        f.write(f\"F1 Score (Macro): {f1_macro:.4f}\\n\")\n",
    "        f.write(f\"F1 Score (Weighted): {f1_weighted:.4f}\\n\")\n",
    "        f.write(f\"Precision (Macro): {precision_macro:.4f}\\n\")\n",
    "        f.write(f\"Precision (Weighted): {precision_weighted:.4f}\\n\")\n",
    "        f.write(f\"Recall (Macro): {recall_macro:.4f}\\n\")\n",
    "        f.write(f\"Recall (Weighted): {recall_weighted:.4f}\\n\\n\")\n",
    "        f.write(\"Classification Report:\\n\")\n",
    "        f.write(report)\n",
    "    \n",
    "    # 4. Per-class accuracy\n",
    "    class_acc = cm.diagonal() / cm.sum(axis=1) * 100\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=list(class_names), y=class_acc)\n",
    "    plt.title(\"Per-Class Accuracy\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.ylim(0, 100)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{config.output_dir}/per_class_accuracy.png\", dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"[INFO] Evaluation results saved to {config.output_dir}\")\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "####################################\n",
    "# 7. Visualization Helpers\n",
    "####################################\n",
    "def visualize_predictions(model, test_dataset, config, device, num_examples=5):\n",
    "    \"\"\"Visualize random predictions with original CIFAR-10 images\"\"\"\n",
    "    print(\"[INFO] Generating prediction visualizations...\")\n",
    "    \n",
    "    # Use a professional style\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'sans-serif',\n",
    "        'font.sans-serif': ['Arial', 'Helvetica', 'DejaVu Sans'],\n",
    "        'font.size': 9,\n",
    "        'axes.titlesize': 10,\n",
    "        'axes.labelsize': 9\n",
    "    })\n",
    "    \n",
    "    # Select random indices\n",
    "    indices = np.random.choice(len(test_dataset), size=num_examples*len(config.classes), replace=False)\n",
    "    \n",
    "    # Get original images and labels\n",
    "    originals, true_labels = get_original_images(config, indices)\n",
    "    \n",
    "    # Prepare a batch of transformed images for the model\n",
    "    batch_images = torch.stack([test_dataset[idx][0] for idx in indices]).to(device)\n",
    "    \n",
    "    # Get predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if config.use_amp and device.type == 'cuda':\n",
    "            with autocast(device_type='cuda'):\n",
    "                outputs = model(batch_images)\n",
    "        else:\n",
    "            outputs = model(batch_images)\n",
    "    \n",
    "    # Get prediction probabilities and classes\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    pred_scores, pred_labels = torch.max(probs, dim=1)\n",
    "    \n",
    "    # Convert to numpy\n",
    "    pred_labels = pred_labels.cpu().numpy()\n",
    "    pred_scores = pred_scores.cpu().numpy()\n",
    "    \n",
    "    # Plot results - create a figure with better proportions\n",
    "    fig, axes = plt.subplots(len(config.classes), num_examples, figsize=(num_examples*2.5, len(config.classes)*2))\n",
    "    fig.suptitle(\"CIFAR-10 Prediction Examples (ViT-B/16)\", fontsize=14, y=0.98)\n",
    "    \n",
    "    # Group samples by true class\n",
    "    class_indices = {i: [] for i in range(len(config.classes))}\n",
    "    for i, label in enumerate(true_labels):\n",
    "        if len(class_indices[label]) < num_examples:\n",
    "            class_indices[label].append(i)\n",
    "    \n",
    "    # Color mapping\n",
    "    correct_color = '#1f77b4'  # Professional blue\n",
    "    incorrect_color = '#d62728'  # Professional red\n",
    "    \n",
    "    # Plot each class\n",
    "    for class_idx in range(len(config.classes)):\n",
    "        for example_idx in range(num_examples):\n",
    "            ax = axes[class_idx, example_idx]\n",
    "            \n",
    "            # Check if we have enough examples for this class\n",
    "            if example_idx < len(class_indices[class_idx]):\n",
    "                i = class_indices[class_idx][example_idx]\n",
    "                \n",
    "                # Plot image with a border\n",
    "                img = originals[i].permute(1, 2, 0).numpy()\n",
    "                ax.imshow(img)\n",
    "                \n",
    "                # Add prediction info with better formatting\n",
    "                true_label = true_labels[i]\n",
    "                pred_label = pred_labels[i]\n",
    "                color = correct_color if true_label == pred_label else incorrect_color\n",
    "                \n",
    "                # Create a clean title with proper formatting\n",
    "                ax.set_title(f\"True: {config.classes[true_label]}\\nPred: {config.classes[pred_label]}\\nConf: {pred_scores[i]:.3f}\", \n",
    "                            color=color, fontsize=9, pad=3)\n",
    "                \n",
    "                # Add a professional border\n",
    "                for spine in ax.spines.values():\n",
    "                    spine.set_edgecolor(color)\n",
    "                    spine.set_linewidth(1.5)\n",
    "            else:\n",
    "                # If not enough examples, hide the empty subplot\n",
    "                ax.set_visible(False)\n",
    "            \n",
    "            # Remove ticks for all subplots (whether they have content or not)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    \n",
    "    # Add row labels on the left\n",
    "    for class_idx in range(len(config.classes)):\n",
    "        if axes[class_idx, 0].get_visible():  # Only add label if the first subplot in row is visible\n",
    "            axes[class_idx, 0].set_ylabel(config.classes[class_idx], fontsize=10, \n",
    "                                        rotation=90, labelpad=10, va='center')\n",
    "    \n",
    "    # Add a footer with model information\n",
    "    plt.figtext(0.5, 0.01, \n",
    "               f\"Vision Transformer (ViT-B/16) evaluation on CIFAR-10 test set\", \n",
    "               ha=\"center\", fontsize=10, style='italic')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.95, bottom=0.05)\n",
    "    plt.savefig(f\"{config.output_dir}/prediction_examples.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"[INFO] Prediction visualizations saved to {config.output_dir}/prediction_examples.png\")\n",
    "\n",
    "\n",
    "####################################\n",
    "# 8. GradCAM Implementation\n",
    "####################################\n",
    "class GradCAM:\n",
    "    \"\"\"Gradient-weighted Class Activation Mapping\"\"\"\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.activations = None\n",
    "        self.gradients = None\n",
    "        self.hook_handles = []\n",
    "        self._register_hooks()\n",
    "    \n",
    "    def _register_hooks(self):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output.detach()\n",
    "        \n",
    "        def backward_hook(module, grad_input, grad_output):\n",
    "            self.gradients = grad_output[0].detach()\n",
    "        \n",
    "        # Register hooks\n",
    "        self.hook_handles.append(self.target_layer.register_forward_hook(forward_hook))\n",
    "        self.hook_handles.append(self.target_layer.register_full_backward_hook(backward_hook))\n",
    "    \n",
    "    def generate_cam(self, input_tensor, target_class=None):\n",
    "        self.model.zero_grad() # Clear gradients\n",
    "        \n",
    "        # Perform a single forward pass to get the logits\n",
    "        # input_tensor is expected to be a batch of size 1 for typical GradCAM visualization\n",
    "        logits = self.model(input_tensor) # logits.shape: (1, num_classes)\n",
    "        \n",
    "        if target_class is None:\n",
    "            # If no target class is specified, use the class with the highest logit score\n",
    "            target_class_idx = logits.argmax(dim=1).item() # Get the index as an integer\n",
    "        else:\n",
    "            target_class_idx = target_class # Use the provided target_class index\n",
    "        \n",
    "        # The \"score\" for GradCAM is the logit of the target class.\n",
    "        # We select the logit for the target_class_idx for the single item in the batch.\n",
    "        score = logits[0, target_class_idx]\n",
    "        \n",
    "        # Backward pass to compute gradients of the score w.r.t. the feature maps in the target_layer\n",
    "        score.backward(retain_graph=False) # Gradients are now in self.gradients via the hook\n",
    "        \n",
    "        # Ensure activations and gradients were captured\n",
    "        if self.activations is None or self.gradients is None:\n",
    "            raise RuntimeError(\"Activations or gradients are None. Check GradCAM hooks and target layer.\")\n",
    "            \n",
    "        # Generate CAM (Global Average Pooling of gradients to get weights)\n",
    "        # self.gradients shape: (1, channels, H_feat, W_feat)\n",
    "        # self.activations shape: (1, channels, H_feat, W_feat)\n",
    "        weights = self.gradients.mean(dim=(2, 3), keepdim=True) # weights shape: (1, channels, 1, 1)\n",
    "        cam = (weights * self.activations).sum(dim=1, keepdim=True) # cam shape: (1, 1, H_feat, W_feat)\n",
    "        cam = torch.relu(cam) # Apply ReLU\n",
    "        \n",
    "        # Upsample CAM to the input image size\n",
    "        cam = torch.nn.functional.interpolate(\n",
    "            cam,\n",
    "            size=input_tensor.shape[2:], # H_input, W_input\n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "        )\n",
    "        \n",
    "        # Normalize CAM to [0, 1] for visualization\n",
    "        cam_min = cam.min()\n",
    "        cam_max = cam.max()\n",
    "        cam = (cam - cam_min) / (cam_max - cam_min + 1e-8)\n",
    "        \n",
    "        return cam # cam shape: (1, 1, H_input, W_input)\n",
    "    \n",
    "    def remove_hooks(self):\n",
    "        for handle in self.hook_handles:\n",
    "            handle.remove()\n",
    "\n",
    "\n",
    "def visualize_gradcam(model, test_dataset, config, device):\n",
    "    \"\"\"Create GradCAM visualizations for each class with improved scientific appearance\"\"\"\n",
    "    print(\"[INFO] Generating GradCAM visualizations...\")\n",
    "    \n",
    "    # Set scientific plotting style\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'sans-serif',\n",
    "        'font.sans-serif': ['Arial', 'Helvetica', 'DejaVu Sans'],\n",
    "        'font.size': 10,\n",
    "        'axes.titlesize': 11,\n",
    "        'axes.labelsize': 10\n",
    "    })\n",
    "    \n",
    "    # Find one sample per class\n",
    "    samples_by_class = {c: None for c in range(len(config.classes))}\n",
    "    indices_by_class = {c: None for c in range(len(config.classes))}\n",
    "    \n",
    "    for idx in tqdm(range(len(test_dataset)), desc=\"Finding class samples\"):\n",
    "        _, label = test_dataset[idx]\n",
    "        if samples_by_class[label] is None:\n",
    "            samples_by_class[label] = test_dataset[idx][0].unsqueeze(0)\n",
    "            indices_by_class[label] = idx\n",
    "        if all(v is not None for v in samples_by_class.values()):\n",
    "            break\n",
    "    \n",
    "    # Initialize GradCAM with the appropriate layer\n",
    "    target_layer = model.conv_proj\n",
    "    grad_cam = GradCAM(model, target_layer)\n",
    "    \n",
    "    # Use a scientific colormap\n",
    "    cmap = 'inferno'  # Scientific colormap that works well for heatmaps\n",
    "    \n",
    "    # Create a figure with 2 rows (original and heatmap) x 5 columns\n",
    "    fig, axes = plt.subplots(4, 5, figsize=(15, 12))\n",
    "    fig.suptitle(\"GradCAM Visualizations for CIFAR-10 Classes (ViT-B/16)\", fontsize=14, y=0.98)\n",
    "    \n",
    "    # Create a mapping for 2x5 grid with proper organization\n",
    "    class_to_position = {\n",
    "        0: (0, 0),  # airplane\n",
    "        1: (0, 1),  # automobile\n",
    "        2: (0, 2),  # bird\n",
    "        3: (0, 3),  # cat\n",
    "        4: (0, 4),  # deer\n",
    "        5: (2, 0),  # dog\n",
    "        6: (2, 1),  # frog\n",
    "        7: (2, 2),  # horse\n",
    "        8: (2, 3),  # ship\n",
    "        9: (2, 4),  # truck\n",
    "    }\n",
    "    \n",
    "    for class_idx in range(len(config.classes)):\n",
    "        print(f\"[INFO] Generating GradCAM for class '{config.classes[class_idx]}'\")\n",
    "        \n",
    "        # Get the sample\n",
    "        input_tensor = samples_by_class[class_idx].to(device)\n",
    "        \n",
    "        # Generate CAM\n",
    "        cam = grad_cam.generate_cam(input_tensor, target_class=class_idx)\n",
    "        cam = cam.cpu().numpy()[0, 0]\n",
    "        \n",
    "        # Get original image\n",
    "        orig_imgs, _ = get_original_images(config, [indices_by_class[class_idx]])\n",
    "        orig_img = orig_imgs[0].permute(1, 2, 0).numpy()\n",
    "        \n",
    "        # Upsample original image to match model input size (224x224)\n",
    "        img_upsampled = transforms.Resize(224)(orig_imgs[0])\n",
    "        img_upsampled = img_upsampled.permute(1, 2, 0).numpy()\n",
    "        \n",
    "        # Get row, col position\n",
    "        row, col = class_to_position[class_idx]\n",
    "        \n",
    "        # Plot original image\n",
    "        ax_orig = axes[row, col]\n",
    "        ax_orig.imshow(img_upsampled)\n",
    "        ax_orig.set_title(f\"{config.classes[class_idx]} (Original)\", fontsize=11)\n",
    "        ax_orig.set_xticks([])\n",
    "        ax_orig.set_yticks([])\n",
    "        \n",
    "        # Plot heatmap overlay\n",
    "        ax_overlay = axes[row+1, col]\n",
    "        ax_overlay.imshow(img_upsampled)\n",
    "        heatmap = ax_overlay.imshow(cam, cmap=cmap, alpha=0.6)\n",
    "        ax_overlay.set_title(f\"{config.classes[class_idx]} (GradCAM)\", fontsize=11)\n",
    "        ax_overlay.set_xticks([])\n",
    "        ax_overlay.set_yticks([])\n",
    "    \n",
    "    # Add a colorbar for the heatmap\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    cbar = fig.colorbar(heatmap, cax=cbar_ax)\n",
    "    cbar.set_label('Activation Strength', fontsize=10)\n",
    "    \n",
    "    # Add a footer with model information\n",
    "    plt.figtext(0.5, 0.01, \n",
    "                \"GradCAM visualizations show regions the model focuses on when classifying each category\",\n",
    "                ha=\"center\", fontsize=10, style='italic')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(right=0.9, top=0.95, bottom=0.05)\n",
    "    plt.savefig(f\"{config.output_dir}/gradcam_visualization.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Clean up\n",
    "    grad_cam.remove_hooks()\n",
    "    \n",
    "    print(f\"[INFO] GradCAM visualizations saved to {config.output_dir}/gradcam_visualization.png\")\n",
    "\n",
    "\n",
    "####################################\n",
    "# 9. Main Evaluation Function\n",
    "####################################\n",
    "def main():\n",
    "    \"\"\"Main evaluation pipeline\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"ViT CIFAR-10 Evaluation Pipeline\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Setup\n",
    "    config, device = setup_environment()\n",
    "    \n",
    "    try:\n",
    "        # 1. Load the dataset\n",
    "        test_dataset = get_test_dataset(config)\n",
    "        test_loader = create_data_loader(test_dataset, config)\n",
    "        \n",
    "        # 2. Load the model\n",
    "        model = load_model(config, device)\n",
    "        \n",
    "        # 3. Run inference\n",
    "        targets, predictions, probabilities = run_inference(model, test_loader, config, device)\n",
    "        \n",
    "        # 4. Generate metrics\n",
    "        accuracy = analyze_results(targets, predictions, probabilities, config.classes, config)\n",
    "        \n",
    "        # 5. Visualize predictions\n",
    "        visualize_predictions(model, test_dataset, config, device)\n",
    "        \n",
    "        # 6. Generate GradCAM visualizations\n",
    "        visualize_gradcam(model, test_dataset, config, device)\n",
    "        \n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Evaluation completed successfully with {accuracy:.2f}% accuracy\")\n",
    "        print(f\"All results saved to '{config.output_dir}' directory\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"[ERROR] An error occurred: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        print(\"\\nTry adjusting the batch_size or num_workers in EvalConfig if experiencing memory issues.\")\n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
