{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 15:58:46,049 [INFO] - Using device: cuda\n",
      "2025-05-07 15:58:46,064 [INFO] - GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "2025-05-07 15:58:46,064 [INFO] - GPU Memory: 6.00 GB\n",
      "2025-05-07 15:58:46,064 [INFO] - CUDA Version: 11.8\n",
      "2025-05-07 15:58:46,064 [INFO] - cuDNN benchmark mode enabled\n",
      "2025-05-07 15:58:46,064 [INFO] - CPU: 16 cores available\n",
      "2025-05-07 15:58:46,064 [INFO] - GPU: NVIDIA GeForce RTX 3060 Laptop GPU with 6.00GB memory\n",
      "2025-05-07 15:58:46,064 [INFO] - RTX 3060 detected - using optimized settings\n",
      "2025-05-07 15:58:46,064 [INFO] - Python version: 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:20:11) [MSC v.1938 64 bit (AMD64)]\n",
      "2025-05-07 15:58:46,064 [INFO] - PyTorch version: 2.5.1\n",
      "2025-05-07 15:58:46,064 [INFO] - Torchvision version: 0.20.1\n",
      "2025-05-07 15:58:46,064 [INFO] - Configuration: {\n",
      "    \"seed\": 42,\n",
      "    \"model_name\": \"vit_b16_teacher\",\n",
      "    \"dataset\": \"CIFAR-10\",\n",
      "    \"use_amp\": true,\n",
      "    \"memory_efficient_attention\": true,\n",
      "    \"prefetch_factor\": 2,\n",
      "    \"pin_memory\": true,\n",
      "    \"persistent_workers\": true,\n",
      "    \"batch_size\": 64,\n",
      "    \"gradient_accumulation_steps\": 2,\n",
      "    \"find_batch_size\": false,\n",
      "    \"gpu_memory_fraction\": 0.75,\n",
      "    \"input_size\": 32,\n",
      "    \"vit_input_size\": 224,\n",
      "    \"num_workers\": 4,\n",
      "    \"val_split\": 0.1,\n",
      "    \"dataset_path\": \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Dataset\",\n",
      "    \"clear_cache_every_n_epochs\": 2,\n",
      "    \"pretrained\": true,\n",
      "    \"temperature\": 1.0,\n",
      "    \"num_classes\": 10,\n",
      "    \"use_zero_padding\": true,\n",
      "    \"epochs\": 50,\n",
      "    \"lr\": 0.0003,\n",
      "    \"weight_decay\": 0.0001,\n",
      "    \"early_stop_patience\": 10,\n",
      "    \"scheduler_T_max\": 50,\n",
      "    \"ce_weight\": 1.0,\n",
      "    \"cal_weight\": 0.1,\n",
      "    \"use_curriculum\": true,\n",
      "    \"curriculum_ramp_epochs\": 30,\n",
      "    \"checkpoint_dir\": \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Models\\\\ViT\\\\checkpoints\",\n",
      "    \"results_dir\": \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Results\\\\ViT\",\n",
      "    \"export_dir\": \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Models\\\\ViT\\\\exports\"\n",
      "}\n",
      "2025-05-07 15:58:46,080 [INFO] - Script saved to C:\\Users\\Gading\\Downloads\\Research\\Scripts\\vit_b16_teacher_20250507_155846.py\n",
      "2025-05-07 15:58:46,086 [INFO] - Random seed set to 42\n",
      "2025-05-07 15:58:46,219 [INFO] - GPU cache cleared: 0.00MB → 0.00MB (freed 0.00MB)\n",
      "2025-05-07 15:58:46,219 [INFO] - Random seed set to 42\n",
      "2025-05-07 15:58:46,219 [INFO] - Using zero padding with pad_size=96 pixels on each side\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 15:58:47,878 [INFO] - Training samples: 45000\n",
      "2025-05-07 15:58:47,878 [INFO] - Validation samples: 5000\n",
      "2025-05-07 15:58:47,878 [INFO] - Test samples: 10000\n",
      "2025-05-07 15:58:47,878 [INFO] - Loading pretrained ViT-B16 model...\n",
      "2025-05-07 15:58:49,255 [INFO] - Enabling memory-efficient attention for transformer blocks\n",
      "2025-05-07 15:58:49,256 [INFO] - Model created: ViT-B16 adapted for CIFAR-10 with 10 classes\n",
      "2025-05-07 15:58:49,481 [INFO] - Configuration saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\ViT\\vit_b16_teacher_20250507_155849_config.json\n",
      "2025-05-07 15:58:49,497 [INFO] - Batch size: 64 with gradient accumulation steps: 2\n",
      "2025-05-07 15:58:49,497 [INFO] - Effective batch size: 128\n",
      "2025-05-07 15:58:49,497 [INFO] - GPU Memory: Current=327.33MB, Peak=327.33MB, Reserved=382.00MB\n",
      "2025-05-07 15:58:49,497 [INFO] - Starting training...\n",
      "2025-05-07 15:58:49,497 [INFO] - Epoch 1/50\n",
      "2025-05-07 15:58:49,633 [INFO] - GPU cache cleared: 327.33MB → 327.33MB (freed 0.00MB)\n",
      "Training (cal_weight=0.0033):   0%|          | 0/704 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Optimized Vision Transformer (ViT-B16) Teacher Model Training Script\n",
    "for Ensemble Distillation on CIFAR-10 Dataset (32x32 resolution)\n",
    "\n",
    "Target Hardware: RTX 3060 Laptop (6GB VRAM) + Ryzen 7 6800H (8 cores/16 threads)\n",
    "Optimizations:\n",
    "- Automatic Mixed Precision (AMP) with updated PyTorch APIs\n",
    "- Memory-efficient attention mechanisms\n",
    "- Conservative batch size with gradient accumulation\n",
    "- Specific RTX 3060 Laptop memory optimizations\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# Updated imports for AMP\n",
    "from torch.amp import autocast, GradScaler  # Updated from torch.cuda.amp\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import gc  # For explicit garbage collection\n",
    "\n",
    "# Define base paths\n",
    "BASE_PATH = \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\"\n",
    "DATASET_PATH = os.path.join(BASE_PATH, \"Dataset\")\n",
    "RESULTS_PATH = os.path.join(BASE_PATH, \"Results\")\n",
    "MODELS_PATH = os.path.join(BASE_PATH, \"Models\")\n",
    "SCRIPTS_PATH = os.path.join(BASE_PATH, \"Scripts\")\n",
    "\n",
    "# Create model-specific paths\n",
    "MODEL_NAME = \"ViT\"\n",
    "\n",
    "# Create path for the specific model\n",
    "MODEL_RESULTS_PATH = os.path.join(RESULTS_PATH, MODEL_NAME)\n",
    "MODEL_CHECKPOINT_PATH = os.path.join(MODELS_PATH, MODEL_NAME, \"checkpoints\")\n",
    "MODEL_EXPORT_PATH = os.path.join(MODELS_PATH, MODEL_NAME, \"exports\")\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(DATASET_PATH, exist_ok=True)\n",
    "os.makedirs(MODEL_RESULTS_PATH, exist_ok=True)\n",
    "os.makedirs(MODEL_CHECKPOINT_PATH, exist_ok=True)\n",
    "os.makedirs(MODEL_EXPORT_PATH, exist_ok=True)\n",
    "os.makedirs(SCRIPTS_PATH, exist_ok=True)\n",
    "\n",
    "# Setup logging\n",
    "log_file = os.path.join(MODEL_RESULTS_PATH, \"vit_b16_teacher_training.log\")\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s [%(levelname)s] - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    logger.info(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    logger.info(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    logger.info(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    # Enable cuDNN benchmark for optimal performance\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    logger.info(\"cuDNN benchmark mode enabled\")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False  # Slightly faster with False\n",
    "    logger.info(f\"Random seed set to {seed}\")\n",
    "\n",
    "# Hyperparameters and configuration\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # General settings\n",
    "        self.seed = 42\n",
    "        self.model_name = \"vit_b16_teacher\"\n",
    "        self.dataset = \"CIFAR-10\"\n",
    "        \n",
    "        # Hardware-specific optimizations - FIXED VALUES for RTX 3060 Laptop (6GB)\n",
    "        self.use_amp = True  # Automatic Mixed Precision\n",
    "        self.memory_efficient_attention = True  # Memory-efficient attention\n",
    "        self.prefetch_factor = 2  # DataLoader prefetch factor\n",
    "        self.pin_memory = True  # Pin memory for faster CPU->GPU transfers\n",
    "        self.persistent_workers = True  # Keep workers alive between epochs\n",
    "        \n",
    "        # RTX 3060 Laptop specific fixes\n",
    "        self.batch_size = 32  # Safe value based on testing\n",
    "        self.gradient_accumulation_steps = 2  # Accumulate for effective batch of 128\n",
    "        self.find_batch_size = False  # Disable auto-finding (using known values)\n",
    "        self.gpu_memory_fraction = 0.75  # More conservative memory usage\n",
    "        \n",
    "        # Data settings\n",
    "        self.input_size = 32  # Original CIFAR-10 image size\n",
    "        self.vit_input_size = 224  # Required size for ViT model\n",
    "        self.num_workers = 6  # Reduced from 8 to prevent memory contention\n",
    "        self.val_split = 0.1  # 10% validation split\n",
    "        self.dataset_path = DATASET_PATH\n",
    "        \n",
    "        # GPU cache clearing settings\n",
    "        self.clear_cache_every_n_epochs = 2  # More frequent cache clearing\n",
    "        \n",
    "        # Model settings\n",
    "        self.pretrained = True\n",
    "        self.temperature = 1.0\n",
    "        self.num_classes = 10  # CIFAR-10 has 10 classes\n",
    "        self.use_zero_padding = False  # Pad images instead of distorting\n",
    "        \n",
    "        # Training settings\n",
    "        self.epochs = 50\n",
    "        self.lr = 3e-4\n",
    "        self.weight_decay = 1e-4\n",
    "        self.early_stop_patience = 10\n",
    "        self.scheduler_T_max = 50\n",
    "        \n",
    "        # Loss weights\n",
    "        self.ce_weight = 1.0      # Cross-entropy weight\n",
    "        self.cal_weight = 0.1     # Maximum calibration weight\n",
    "        \n",
    "        # Curriculum scheduling settings\n",
    "        self.use_curriculum = True  # Whether to use curriculum scheduling\n",
    "        self.curriculum_ramp_epochs = 30  # Extended from 10 to 30 epochs for smoother calibration weight increase\n",
    "        \n",
    "        # Output settings\n",
    "        self.checkpoint_dir = MODEL_CHECKPOINT_PATH\n",
    "        self.results_dir = MODEL_RESULTS_PATH\n",
    "        self.export_dir = MODEL_EXPORT_PATH\n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"String representation of the configuration\"\"\"\n",
    "        return json.dumps(self.__dict__, indent=4)\n",
    "    \n",
    "    def save(self, path):\n",
    "        \"\"\"Save configuration to a JSON file\"\"\"\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(self.__dict__, f, indent=4)\n",
    "\n",
    "    def get_calibration_weight(self, epoch):\n",
    "        \"\"\"\n",
    "        Calculate the calibration weight for the current epoch based on curriculum scheduling\n",
    "        \"\"\"\n",
    "        if not self.use_curriculum:\n",
    "            return self.cal_weight\n",
    "        \n",
    "        # Linear ramp-up of calibration weight\n",
    "        if epoch < self.curriculum_ramp_epochs:\n",
    "            return self.cal_weight * (epoch + 1) / self.curriculum_ramp_epochs\n",
    "        else:\n",
    "            return self.cal_weight\n",
    "\n",
    "\n",
    "# Memory utilities\n",
    "def print_gpu_memory_stats():\n",
    "    \"\"\"Print GPU memory usage statistics\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        current_mem = torch.cuda.memory_allocated() / 1024**2\n",
    "        max_mem = torch.cuda.max_memory_allocated() / 1024**2\n",
    "        reserved_mem = torch.cuda.memory_reserved() / 1024**2\n",
    "        logger.info(f\"GPU Memory: Current={current_mem:.2f}MB, Peak={max_mem:.2f}MB, Reserved={reserved_mem:.2f}MB\")\n",
    "\n",
    "\n",
    "def clear_gpu_cache():\n",
    "    \"\"\"Clear GPU cache to free up memory\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        before_mem = torch.cuda.memory_allocated() / 1024**2\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()  # Explicit garbage collection\n",
    "        after_mem = torch.cuda.memory_allocated() / 1024**2\n",
    "        logger.info(f\"GPU cache cleared: {before_mem:.2f}MB → {after_mem:.2f}MB (freed {before_mem-after_mem:.2f}MB)\")\n",
    "\n",
    "\n",
    "# Calibration Metrics\n",
    "class CalibrationMetrics:\n",
    "    @staticmethod\n",
    "    def compute_ece(probs, targets, n_bins=15):\n",
    "        \"\"\"Compute Expected Calibration Error (ECE)\"\"\"\n",
    "        # Get the confidence (max probability) and predictions\n",
    "        confidences, predictions = torch.max(probs, dim=1)\n",
    "        accuracies = (predictions == targets).float()\n",
    "        \n",
    "        # Sort by confidence\n",
    "        sorted_indices = torch.argsort(confidences)\n",
    "        sorted_confidences = confidences[sorted_indices]\n",
    "        sorted_accuracies = accuracies[sorted_indices]\n",
    "        \n",
    "        # Create bins\n",
    "        bin_size = 1.0 / n_bins\n",
    "        bins = torch.linspace(0, 1.0, n_bins+1)\n",
    "        ece = 0.0\n",
    "        \n",
    "        for i in range(n_bins):\n",
    "            # Determine bin boundaries\n",
    "            bin_start = bins[i]\n",
    "            bin_end = bins[i+1]\n",
    "            \n",
    "            # Find samples in bin\n",
    "            in_bin = (sorted_confidences >= bin_start) & (sorted_confidences < bin_end)\n",
    "            bin_count = in_bin.sum()\n",
    "            \n",
    "            if bin_count > 0:\n",
    "                bin_conf = sorted_confidences[in_bin].mean()\n",
    "                bin_acc = sorted_accuracies[in_bin].mean()\n",
    "                # Add weighted absolute difference to ECE\n",
    "                ece += (bin_count / len(confidences)) * torch.abs(bin_acc - bin_conf)\n",
    "        \n",
    "        return ece\n",
    "    \n",
    "    @staticmethod\n",
    "    def calibration_loss(logits, targets):\n",
    "        \"\"\"Compute a loss term that encourages better calibration (MSE-based)\"\"\"\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(probs, dim=1)\n",
    "        accuracies = (predictions == targets).float()\n",
    "        # MSE between confidence and accuracy\n",
    "        return torch.mean((confidences - accuracies) ** 2)\n",
    "\n",
    "\n",
    "# Dataset Preparation\n",
    "def get_dataloaders(config):\n",
    "    \"\"\"Prepare CIFAR-10 dataset and dataloaders\"\"\"\n",
    "    # For ViT models, we need to use ImageNet normalization\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    if config.use_zero_padding:\n",
    "        # Calculate padding required to bring 32x32 to 224x224\n",
    "        pad_size = (config.vit_input_size - config.input_size) // 2\n",
    "        logger.info(f\"Using zero padding with pad_size={pad_size} pixels on each side\")\n",
    "        \n",
    "        # Transform for training with zero padding and data augmentation\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "            transforms.Pad(pad_size, fill=0),\n",
    "        ])\n",
    "        \n",
    "        # Transform for validation/test (zero padding, no augmentation)\n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "            transforms.Pad(pad_size, fill=0),\n",
    "        ])\n",
    "    else:\n",
    "        # Use resize approach\n",
    "        logger.info(f\"Using resize from {config.input_size}x{config.input_size} to \"\n",
    "                    f\"{config.vit_input_size}x{config.vit_input_size}\")\n",
    "        \n",
    "        # Transform for training with resize and data augmentation\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.Resize(config.vit_input_size, antialias=True),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "        \n",
    "        # Transform for validation/test (resize, no augmentation)\n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.Resize(config.vit_input_size, antialias=True),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "    \n",
    "    # Set CIFAR-10 dataset path\n",
    "    cifar10_path = os.path.join(config.dataset_path, \"CIFAR-10\")\n",
    "    \n",
    "    # Load CIFAR-10 dataset\n",
    "    full_train_dataset = torchvision.datasets.CIFAR10(\n",
    "        root=cifar10_path, train=True, download=True, transform=train_transform\n",
    "    )\n",
    "    test_dataset = torchvision.datasets.CIFAR10(\n",
    "        root=cifar10_path, train=False, download=True, transform=test_transform\n",
    "    )\n",
    "    \n",
    "    # Split training set into train and validation\n",
    "    val_size = int(len(full_train_dataset) * config.val_split)\n",
    "    train_size = len(full_train_dataset) - val_size\n",
    "    train_dataset, val_dataset = random_split(\n",
    "        full_train_dataset, [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(config.seed)\n",
    "    )\n",
    "    \n",
    "    # Create a custom dataset for validation to apply the test transform\n",
    "    val_dataset_with_transform = torch.utils.data.Subset(\n",
    "        torchvision.datasets.CIFAR10(\n",
    "            root=cifar10_path, train=True, download=False, transform=test_transform\n",
    "        ),\n",
    "        val_dataset.indices\n",
    "    )\n",
    "    \n",
    "    # Create data loaders with optimized settings for RTX 3060\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=config.num_workers, \n",
    "        pin_memory=config.pin_memory,\n",
    "        persistent_workers=config.persistent_workers if config.num_workers > 0 else False,\n",
    "        prefetch_factor=config.prefetch_factor if config.num_workers > 0 else None\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset_with_transform, \n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False, \n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=config.pin_memory,\n",
    "        persistent_workers=config.persistent_workers if config.num_workers > 0 else False,\n",
    "        prefetch_factor=config.prefetch_factor if config.num_workers > 0 else None\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False, \n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=config.pin_memory,\n",
    "        persistent_workers=config.persistent_workers if config.num_workers > 0 else False,\n",
    "        prefetch_factor=config.prefetch_factor if config.num_workers > 0 else None\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Training samples: {len(train_dataset)}\")\n",
    "    logger.info(f\"Validation samples: {len(val_dataset)}\")\n",
    "    logger.info(f\"Test samples: {len(test_dataset)}\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "# Model Definition\n",
    "def create_vit_model(config):\n",
    "    \"\"\"Create and initialize a ViT-B16 model for CIFAR-10\"\"\"\n",
    "    if config.pretrained:\n",
    "        # Load pretrained ViT-B16 model\n",
    "        logger.info(\"Loading pretrained ViT-B16 model...\")\n",
    "        weights = ViT_B_16_Weights.IMAGENET1K_V1\n",
    "        model = vit_b_16(weights=weights)\n",
    "    else:\n",
    "        model = vit_b_16()\n",
    "    \n",
    "    # Replace the classification head for CIFAR-10\n",
    "    num_classes = config.num_classes\n",
    "    in_features = model.heads.head.in_features\n",
    "    model.heads.head = nn.Linear(in_features, num_classes)\n",
    "    \n",
    "    # Enable memory-efficient attention if requested\n",
    "    if config.memory_efficient_attention:\n",
    "        logger.info(\"Enabling memory-efficient attention for transformer blocks\")\n",
    "        try:\n",
    "            # Try to enable scaled dot-product attention if available\n",
    "            from torch.nn.functional import scaled_dot_product_attention\n",
    "            \n",
    "            # Replace attention mechanisms with memory efficient implementations\n",
    "            for block in model.encoder.layers:\n",
    "                # Access self-attention modules and set flags if available\n",
    "                if hasattr(block.self_attention, 'use_sdpa'):\n",
    "                    block.self_attention.use_sdpa = True\n",
    "                    logger.info(\"SDPA enabled for attention layer\")\n",
    "        except:\n",
    "            logger.warning(\"Could not enable memory-efficient attention, using default implementation\")\n",
    "    \n",
    "    logger.info(f\"Model created: ViT-B16 adapted for CIFAR-10 with {num_classes} classes\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Training, Validation and Testing Functions\n",
    "def train_epoch(model, train_loader, criterion, optimizer, scaler, device, config, epoch):\n",
    "    \"\"\"Train the model for one epoch with mixed precision and gradient accumulation\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Get calibration weight for current epoch based on curriculum scheduling\n",
    "    current_cal_weight = config.get_calibration_weight(epoch)\n",
    "    \n",
    "    # Initialize counters for gradient accumulation\n",
    "    steps_since_update = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Training (cal_weight={current_cal_weight:.4f})\")\n",
    "    for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "        try:\n",
    "            inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "            \n",
    "            # Zero the parameter gradients if not using gradient accumulation\n",
    "            # or if it's time to update\n",
    "            if config.gradient_accumulation_steps <= 1 or steps_since_update == 0:\n",
    "                optimizer.zero_grad(set_to_none=True)  # More efficient than zero_grad()\n",
    "            \n",
    "            # Forward pass with mixed precision\n",
    "            with autocast(device_type='cuda', enabled=config.use_amp):\n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Calculate loss\n",
    "                ce_loss = criterion(outputs, targets)\n",
    "                \n",
    "                # Add calibration loss with current weight from curriculum scheduling\n",
    "                if current_cal_weight > 0:\n",
    "                    cal_loss = CalibrationMetrics.calibration_loss(outputs, targets)\n",
    "                    loss = config.ce_weight * ce_loss + current_cal_weight * cal_loss\n",
    "                else:\n",
    "                    loss = ce_loss\n",
    "                \n",
    "                # Scale loss if using gradient accumulation\n",
    "                if config.gradient_accumulation_steps > 1:\n",
    "                    loss = loss / config.gradient_accumulation_steps\n",
    "            \n",
    "            # Backward pass with mixed precision\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # Update weights if not using gradient accumulation or if it's time\n",
    "            steps_since_update += 1\n",
    "            if config.gradient_accumulation_steps <= 1 or steps_since_update == config.gradient_accumulation_steps:\n",
    "                # Unscale gradients before applying optimizer\n",
    "                scaler.unscale_(optimizer)\n",
    "                \n",
    "                # Apply gradient clipping after unscaling but before stepping\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                steps_since_update = 0\n",
    "            \n",
    "            # Update statistics\n",
    "            # If using gradient accumulation, we need to scale the loss back up for accurate reporting\n",
    "            running_loss += loss.item() * (config.gradient_accumulation_steps if config.gradient_accumulation_steps > 1 else 1)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': running_loss / (batch_idx + 1),\n",
    "                'acc': 100. * correct / total\n",
    "            })\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in training batch {batch_idx}: {str(e)}\")\n",
    "            # Try to free up memory\n",
    "            clear_gpu_cache()\n",
    "            # If problem persists, skip this batch and continue\n",
    "            continue\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device, config):\n",
    "    \"\"\"Validate the model with mixed precision\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(val_loader, desc=\"Validating\"):\n",
    "            try:\n",
    "                inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "                \n",
    "                # Forward pass with mixed precision\n",
    "                with autocast(device_type='cuda', enabled=config.use_amp):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                \n",
    "                # Update statistics\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "                \n",
    "                # Store for metrics calculation\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                all_probs.append(F.softmax(outputs, dim=1).cpu())\n",
    "            \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in validation: {str(e)}\")\n",
    "                clear_gpu_cache()\n",
    "                continue\n",
    "    \n",
    "    # Calculate metrics\n",
    "    all_probs = torch.cat(all_probs, dim=0)\n",
    "    all_targets_tensor = torch.tensor(all_targets)\n",
    "    \n",
    "    avg_loss = running_loss / len(val_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    f1 = f1_score(all_targets, all_predictions, average='macro')\n",
    "    ece = CalibrationMetrics.compute_ece(all_probs, all_targets_tensor).item()\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    precision = precision_score(all_targets, all_predictions, average='macro')\n",
    "    recall = recall_score(all_targets, all_predictions, average='macro')\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': avg_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'ece': ece\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def test(model, test_loader, device, config):\n",
    "    \"\"\"Test the model on the test set with mixed precision\"\"\"\n",
    "    return validate(model, test_loader, nn.CrossEntropyLoss(), device, config)\n",
    "\n",
    "\n",
    "# Main Training Loop\n",
    "def train_model(config):\n",
    "    \"\"\"Main training function optimized for RTX 3060 Laptop GPU\"\"\"\n",
    "    set_seed(config.seed)\n",
    "    \n",
    "    # Get dataloaders\n",
    "    train_loader, val_loader, test_loader = get_dataloaders(config)\n",
    "    \n",
    "    # Create model\n",
    "    model = create_vit_model(config)\n",
    "    model = model.to(device)\n",
    "    model = torch.compile(model, mode=\"default\")\n",
    "    from torch.utils.checkpoint import checkpoint_sequential\n",
    "    model.encoder.layers = checkpoint_sequential(model.encoder.layers, segments=3)\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=config.scheduler_T_max)\n",
    "    \n",
    "    # Initialize AMP gradient scaler\n",
    "    scaler = GradScaler(device='cuda') if config.use_amp else None\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'val_f1': [],\n",
    "        'val_ece': [],\n",
    "        'cal_weights': [],  # Track calibration weights over epochs\n",
    "        'best_epoch': 0\n",
    "    }\n",
    "    \n",
    "    # Early stopping setup\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_counter = 0\n",
    "    \n",
    "    # Get current time for model naming\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_name = f\"{config.model_name}_{timestamp}\"\n",
    "    \n",
    "    # Save full configuration before training\n",
    "    config_path = os.path.join(config.results_dir, f\"{model_name}_config.json\")\n",
    "    config.save(config_path)\n",
    "    logger.info(f\"Configuration saved to {config_path}\")\n",
    "    \n",
    "    # Log effective batch size information\n",
    "    effective_batch_size = config.batch_size * config.gradient_accumulation_steps\n",
    "    logger.info(f\"Batch size: {config.batch_size} with gradient accumulation steps: {config.gradient_accumulation_steps}\")\n",
    "    logger.info(f\"Effective batch size: {effective_batch_size}\")\n",
    "    \n",
    "    # Measure initial GPU memory usage\n",
    "    print_gpu_memory_stats()\n",
    "    \n",
    "    # Training loop\n",
    "    logger.info(\"Starting training...\")\n",
    "    try:\n",
    "        for epoch in range(config.epochs):\n",
    "            epoch_start_time = time.time()\n",
    "            logger.info(f\"Epoch {epoch+1}/{config.epochs}\")\n",
    "            \n",
    "            # Clear GPU cache at the beginning of each epoch to ensure clean state\n",
    "            clear_gpu_cache()\n",
    "            \n",
    "            # Get current calibration weight for logging\n",
    "            current_cal_weight = config.get_calibration_weight(epoch)\n",
    "            history['cal_weights'].append(current_cal_weight)\n",
    "            \n",
    "            # Train\n",
    "            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, scaler, device, config, epoch)\n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['train_acc'].append(train_acc)\n",
    "            \n",
    "            # Clear cache before validation to ensure maximum available memory\n",
    "            clear_gpu_cache()\n",
    "            \n",
    "            # Validate\n",
    "            val_metrics = validate(model, val_loader, criterion, device, config)\n",
    "            val_loss = val_metrics['loss']\n",
    "            val_acc = val_metrics['accuracy']\n",
    "            val_f1 = val_metrics['f1_score']\n",
    "            val_ece = val_metrics['ece']\n",
    "            \n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['val_acc'].append(val_acc)\n",
    "            history['val_f1'].append(val_f1)\n",
    "            history['val_ece'].append(val_ece)\n",
    "            \n",
    "            # Update learning rate scheduler\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Calculate epoch time\n",
    "            epoch_time = time.time() - epoch_start_time\n",
    "            \n",
    "            # Log metrics\n",
    "            logger.info(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "            logger.info(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, Val F1: {val_f1:.4f}, Val ECE: {val_ece:.4f}\")\n",
    "            logger.info(f\"Epoch time: {epoch_time:.2f}s\")\n",
    "            \n",
    "            # Save checkpoint after clearing cache\n",
    "            clear_gpu_cache()\n",
    "            \n",
    "            try:\n",
    "                # Save model checkpoint\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),\n",
    "                    'train_loss': train_loss,\n",
    "                    'val_loss': val_loss,\n",
    "                    'val_acc': val_acc,\n",
    "                    'val_f1': val_f1,\n",
    "                    'val_ece': val_ece,\n",
    "                    'config': config.__dict__\n",
    "                }\n",
    "                \n",
    "                # Save latest model\n",
    "                latest_path = os.path.join(config.checkpoint_dir, f\"{model_name}_latest.pth\")\n",
    "                torch.save(checkpoint, latest_path)\n",
    "                \n",
    "                # Check if this is the best model\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    early_stop_counter = 0\n",
    "                    history['best_epoch'] = epoch + 1\n",
    "                    \n",
    "                    # Save best model\n",
    "                    best_path = os.path.join(config.checkpoint_dir, f\"{model_name}_best.pth\")\n",
    "                    torch.save(checkpoint, best_path)\n",
    "                    logger.info(f\"Best model saved with Val Loss: {val_loss:.4f}\")\n",
    "                else:\n",
    "                    early_stop_counter += 1\n",
    "            \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error saving checkpoint: {str(e)}\")\n",
    "            \n",
    "            # Print memory stats at end of epoch\n",
    "            print_gpu_memory_stats()\n",
    "            \n",
    "            # Early stopping\n",
    "            if early_stop_counter >= config.early_stop_patience:\n",
    "                logger.info(f\"Early stopping after {epoch+1} epochs\")\n",
    "                break\n",
    "        \n",
    "        # Final evaluation on test set\n",
    "        logger.info(\"Loading best model for final evaluation...\")\n",
    "        best_path = os.path.join(config.checkpoint_dir, f\"{model_name}_best.pth\")\n",
    "        checkpoint = torch.load(best_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        # Clear cache before final testing\n",
    "        clear_gpu_cache()\n",
    "        \n",
    "        # Test\n",
    "        test_metrics = test(model, test_loader, device, config)\n",
    "        logger.info(f\"Test Metrics: {test_metrics}\")\n",
    "        \n",
    "        # Save training history and config\n",
    "        history_path = os.path.join(config.results_dir, f\"{model_name}_history.json\")\n",
    "        with open(history_path, 'w') as f:\n",
    "            json.dump\n",
    "\n",
    "        # Final memory stats\n",
    "        print_gpu_memory_stats()\n",
    "        \n",
    "        logger.info(\"Training completed!\")\n",
    "        return model, history\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during training: {str(e)}\")\n",
    "        import traceback\n",
    "        logger.error(traceback.format_exc())\n",
    "        \n",
    "        # Try to save a partial history for debugging\n",
    "        try:\n",
    "            partial_history_path = os.path.join(config.results_dir, f\"{model_name}_partial_history.json\")\n",
    "            with open(partial_history_path, 'w') as f:\n",
    "                json.dump(history, f, indent=4)\n",
    "            logger.info(f\"Partial training history saved to {partial_history_path}\")\n",
    "        except:\n",
    "            logger.error(\"Could not save partial history\")\n",
    "        \n",
    "        # Clear cache in case of error\n",
    "        clear_gpu_cache()\n",
    "        raise\n",
    "\n",
    "\n",
    "def export_model_outputs(model, loader, device, config, num_batches=1):\n",
    "    \"\"\"Export model outputs for a few batches with mixed precision\"\"\"\n",
    "    model.eval()\n",
    "    exports = {\n",
    "        'logits': [],\n",
    "        'soft_probs': [],\n",
    "        'targets': [],\n",
    "        'temperature': config.temperature\n",
    "    }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(loader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "            \n",
    "            inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "            \n",
    "            # Forward pass with mixed precision\n",
    "            with autocast(device_type='cuda', enabled=config.use_amp):\n",
    "                logits = model(inputs)\n",
    "            \n",
    "            # Apply temperature scaling to soften the probabilities\n",
    "            soft_probs = F.softmax(logits / config.temperature, dim=1)\n",
    "            \n",
    "            # Store outputs\n",
    "            exports['logits'].append(logits.cpu().numpy())\n",
    "            exports['soft_probs'].append(soft_probs.cpu().numpy())\n",
    "            exports['targets'].append(targets.cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    for key in ['logits', 'soft_probs', 'targets']:\n",
    "        if exports[key]:  # Check if there's any data\n",
    "            exports[key] = np.vstack(exports[key]) if key != 'targets' else np.concatenate(exports[key])\n",
    "    \n",
    "    return exports\n",
    "\n",
    "\n",
    "# Plot training history\n",
    "def plot_history(history, save_path=None):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # Plot training & validation loss\n",
    "    plt.subplot(3, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train')\n",
    "    plt.plot(history['val_loss'], label='Validation')\n",
    "    plt.axvline(x=history['best_epoch']-1, color='r', linestyle='--', label='Best Model')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot training & validation accuracy\n",
    "    plt.subplot(3, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Train')\n",
    "    plt.plot(history['val_acc'], label='Validation')\n",
    "    plt.axvline(x=history['best_epoch']-1, color='r', linestyle='--', label='Best Model')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot validation F1 score\n",
    "    plt.subplot(3, 2, 3)\n",
    "    plt.plot(history['val_f1'], label='Validation')\n",
    "    plt.axvline(x=history['best_epoch']-1, color='r', linestyle='--', label='Best Model')\n",
    "    plt.title('F1 Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot validation ECE\n",
    "    plt.subplot(3, 2, 4)\n",
    "    plt.plot(history['val_ece'], label='Validation')\n",
    "    plt.axvline(x=history['best_epoch']-1, color='r', linestyle='--', label='Best Model')\n",
    "    plt.title('Expected Calibration Error')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('ECE')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot calibration weights over epochs\n",
    "    plt.subplot(3, 2, 5)\n",
    "    plt.plot(history['cal_weights'], label='Cal. Weight')\n",
    "    plt.axvline(x=history['best_epoch']-1, color='r', linestyle='--', label='Best Model')\n",
    "    plt.title('Calibration Weights (Curriculum)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Weight')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Add additional space for the title\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "    \n",
    "    # Add an overall title\n",
    "    plt.suptitle(f\"Training History - ViT-B16 Teacher Model for CIFAR-10\", fontsize=16)\n",
    "    \n",
    "    # Save if path is provided\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        logger.info(f\"Plot saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_calibration_curve(model, test_loader, device, config, save_path=None):\n",
    "    \"\"\"Plot calibration curve showing reliability diagram (predicted confidence vs actual accuracy)\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_targets = []\n",
    "    all_confidences = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader, desc=\"Computing calibration data\"):\n",
    "            try:\n",
    "                inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "                \n",
    "                # Forward pass with mixed precision\n",
    "                with autocast(device_type='cuda', enabled=config.use_amp):\n",
    "                    outputs = model(inputs)\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                \n",
    "                # Store confidence (max probability) and targets\n",
    "                confidences, predictions = torch.max(probs, dim=1)\n",
    "                all_targets.extend((predictions == targets).cpu().numpy())\n",
    "                all_confidences.extend(confidences.cpu().numpy())\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in calibration calculation: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_targets = np.array(all_targets, dtype=np.bool_)\n",
    "    all_confidences = np.array(all_confidences)\n",
    "    \n",
    "    # Create bins for the reliability diagram\n",
    "    n_bins = 10\n",
    "    bin_edges = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_centers = (bin_edges[1:] + bin_edges[:-1]) / 2\n",
    "    \n",
    "    # Initialize arrays for bin statistics\n",
    "    bin_accuracies = np.zeros(n_bins)\n",
    "    bin_confidences = np.zeros(n_bins)\n",
    "    bin_counts = np.zeros(n_bins)\n",
    "    \n",
    "    # Compute statistics for each bin\n",
    "    for i in range(n_bins):\n",
    "        bin_mask = (all_confidences >= bin_edges[i]) & (all_confidences < bin_edges[i+1])\n",
    "        bin_counts[i] = np.sum(bin_mask)\n",
    "        if bin_counts[i] > 0:\n",
    "            bin_accuracies[i] = np.mean(all_targets[bin_mask])\n",
    "            bin_confidences[i] = np.mean(all_confidences[bin_mask])\n",
    "    \n",
    "    # Plot reliability diagram\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Plot perfect calibration line\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect Calibration')\n",
    "    \n",
    "    # Plot actual calibration\n",
    "    bin_sizes_norm = bin_counts / np.sum(bin_counts)\n",
    "    plt.bar(bin_centers, bin_accuracies, width=1/n_bins, alpha=0.3, label='Accuracy in Bin', color='blue')\n",
    "    plt.bar(bin_centers, bin_confidences, width=1/n_bins, alpha=0.3, label='Confidence in Bin', color='red')\n",
    "    \n",
    "    # Plot confidence histogram\n",
    "    plt.twinx()\n",
    "    plt.bar(bin_centers, bin_sizes_norm, width=1/n_bins, alpha=0.2, label='Data Frequency', color='gray')\n",
    "    \n",
    "    plt.title('Calibration Reliability Diagram')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Accuracy / Frequency')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        logger.info(f\"Calibration curve saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Helper function to visualize a few examples\n",
    "def visualize_examples(model, dataloader, device, config, num_examples=5):\n",
    "    \"\"\"Visualize a few examples from the dataset and model predictions\"\"\"\n",
    "    # Get a batch of data\n",
    "    dataiter = iter(dataloader)\n",
    "    images, labels = next(dataiter)\n",
    "    \n",
    "    # Make predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Forward pass with mixed precision\n",
    "        with autocast(device_type='cuda', enabled=config.use_amp):\n",
    "            images_device = images[:num_examples].to(device, non_blocking=True)\n",
    "            outputs = model(images_device)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    # Convert back to CPU for visualization\n",
    "    images = images[:num_examples].cpu()\n",
    "    labels = labels[:num_examples].cpu()\n",
    "    predicted = predicted.cpu()\n",
    "    probs = probs.cpu()\n",
    "    \n",
    "    # Get the class names for CIFAR-10\n",
    "    classes = ('airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    \n",
    "    # Denormalize images for display\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    # Create a function to denormalize and prepare for plotting\n",
    "    def denormalize(img):\n",
    "        # First convert to numpy and transpose dimensions\n",
    "        img = img.numpy().transpose((1, 2, 0))\n",
    "        \n",
    "        # Apply denormalization\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        # If using padding, extract the center 32x32 region\n",
    "        if img.shape[0] == 224:  # Check if we're using the 224x224 size\n",
    "            pad = (img.shape[0] - 32) // 2\n",
    "            img = img[pad:pad+32, pad:pad+32, :]\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    # Plot the examples\n",
    "    fig, axes = plt.subplots(1, num_examples, figsize=(15, 3))\n",
    "    for i in range(num_examples):\n",
    "        ax = axes[i]\n",
    "        img = denormalize(images[i])\n",
    "        ax.imshow(img)\n",
    "        \n",
    "        true_label = classes[labels[i]]\n",
    "        pred_label = classes[predicted[i]]\n",
    "        confidence = probs[i, predicted[i]].item() * 100\n",
    "        \n",
    "        title = f\"True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.1f}%\"\n",
    "        ax.set_title(title, fontsize=10)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Initialize configuration\n",
    "        config = Config()\n",
    "        \n",
    "        # Check CPU and GPU information\n",
    "        logger.info(f\"CPU: {os.cpu_count()} cores available\")\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_name = torch.cuda.get_device_name(0)\n",
    "            gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "            logger.info(f\"GPU: {gpu_name} with {gpu_mem:.2f}GB memory\")\n",
    "            \n",
    "            # Check if this is the target RTX 3060\n",
    "            if \"3060\" in gpu_name.lower():\n",
    "                logger.info(\"RTX 3060 detected - using optimized settings\")\n",
    "                # Keep the predefined settings from Config() - already optimized for RTX 3060\n",
    "            else:\n",
    "                logger.info(f\"Non-target GPU detected ({gpu_name}) - adjusting settings\")\n",
    "                # Adjust settings for unknown GPU\n",
    "                config.batch_size = 32  # More conservative\n",
    "        else:\n",
    "            logger.warning(\"No GPU detected - using CPU settings (training will be slow)\")\n",
    "            config.batch_size = 8\n",
    "            config.use_amp = False\n",
    "            config.memory_efficient_attention = False\n",
    "        \n",
    "        # Log system information\n",
    "        logger.info(f\"Python version: {sys.version}\")\n",
    "        logger.info(f\"PyTorch version: {torch.__version__}\")\n",
    "        logger.info(f\"Torchvision version: {torchvision.__version__}\")\n",
    "        logger.info(f\"Configuration: {config}\")\n",
    "        \n",
    "        # Create a reference script with metadata\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        script_destination = os.path.join(SCRIPTS_PATH, f\"vit_b16_teacher_{timestamp}.py\")\n",
    "        \n",
    "        try:\n",
    "            # Check if running in a notebook or interactive environment\n",
    "            if 'get_ipython' in globals():\n",
    "                # We're in a notebook, save metadata\n",
    "                with open(script_destination, 'w') as f:\n",
    "                    f.write(f\"# ViT-B16 Teacher Training Script (Optimized for RTX 3060 Laptop)\\n\")\n",
    "                    f.write(f\"# Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "                    f.write(f\"# Python: {sys.version}\\n\")\n",
    "                    f.write(f\"# PyTorch: {torch.__version__}\\n\")\n",
    "                    f.write(f\"# Torchvision: {torchvision.__version__}\\n\\n\")\n",
    "                    f.write(f\"# Configuration:\\n\")\n",
    "                    f.write(json.dumps(config.__dict__, indent=4))\n",
    "            else:\n",
    "                # We're in a normal Python script\n",
    "                with open(__file__, 'r') as src_file, open(script_destination, 'w') as dst_file:\n",
    "                    dst_file.write(src_file.read())\n",
    "                    \n",
    "            logger.info(f\"Script saved to {script_destination}\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not save script: {e}\")\n",
    "        \n",
    "        # Set seed for reproducibility\n",
    "        set_seed(config.seed)\n",
    "        \n",
    "        # Clear GPU cache before starting to ensure clean state\n",
    "        clear_gpu_cache()\n",
    "        \n",
    "        # Train model\n",
    "        model, history = train_model(config)\n",
    "        \n",
    "        # Plot and save training history\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        plot_history(history, save_path=os.path.join(config.results_dir, f\"{config.model_name}_{timestamp}_training_plot.png\"))\n",
    "        \n",
    "        # Clear cache before evaluation\n",
    "        clear_gpu_cache()\n",
    "        \n",
    "        # Plot calibration curve\n",
    "        train_loader, val_loader, test_loader = get_dataloaders(config)\n",
    "        plot_calibration_curve(model, test_loader, device, config,\n",
    "                              save_path=os.path.join(config.results_dir, f\"{config.model_name}_{timestamp}_calibration_curve.png\"))\n",
    "        \n",
    "        # Visualize some examples\n",
    "        visualize_examples(model, test_loader, device, config)\n",
    "        \n",
    "        logger.info(\"Script completed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        logger.error(traceback.format_exc())\n",
    "        \n",
    "        # Clean up GPU memory in case of error\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            logger.info(\"GPU memory cleared after error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
