{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "DenseNet121 CIFAR-10 Evaluation Pipeline\n",
      "==================================================\n",
      "[INFO] Using device: cuda\n",
      "[INFO] GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "[INFO] Available memory: 6.44 GB\n",
      "[INFO] Preparing test dataset...\n",
      "Files already downloaded and verified\n",
      "[INFO] Test dataset loaded with 10000 samples\n",
      "[INFO] Creating DataLoader...\n",
      "[INFO] DataLoader created with batch size 8\n",
      "[INFO] Loading model from: C:\\Users\\Gading\\Downloads\\Research\\Models\\DenseNet121\\checkpoints\\densenet121_teacher_20250508_114100_best.pth\n",
      "[INFO] DenseNet121 model loaded successfully and set to evaluation mode\n",
      "[INFO] Running inference on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 1250/1250 [00:42<00:00, 29.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inference complete on 10000 samples\n",
      "[INFO] Analyzing model performance...\n",
      "[RESULT] Test Accuracy: 96.76%\n",
      "[RESULT] Test Cross-Entropy Loss: 0.1663\n",
      "[RESULT] AUC-ROC (Macro): 0.9988\n",
      "[RESULT] AUC-ROC (Weighted): 0.9988\n",
      "[RESULT] AUC-PR (Macro): 0.9906\n",
      "[RESULT] AUC-PR (Weighted): 0.9906\n",
      "\n",
      "[RESULT] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane      0.977     0.970     0.973      1000\n",
      "  automobile      0.972     0.989     0.980      1000\n",
      "        bird      0.974     0.955     0.965      1000\n",
      "         cat      0.937     0.928     0.933      1000\n",
      "        deer      0.940     0.987     0.963      1000\n",
      "         dog      0.935     0.940     0.938      1000\n",
      "        frog      0.988     0.986     0.987      1000\n",
      "       horse      0.993     0.969     0.981      1000\n",
      "        ship      0.981     0.983     0.982      1000\n",
      "       truck      0.981     0.969     0.975      1000\n",
      "\n",
      "    accuracy                          0.968     10000\n",
      "   macro avg      0.968     0.968     0.968     10000\n",
      "weighted avg      0.968     0.968     0.968     10000\n",
      "\n",
      "[INFO] Evaluation results saved to output\n",
      "[INFO] Generating prediction visualizations...\n",
      "[INFO] Prediction visualizations saved to output/prediction_examples.png\n",
      "[INFO] Generating GradCAM visualizations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding class samples:   0%|          | 25/10000 [00:00<00:10, 932.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Generating GradCAM for class 'airplane'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Generating GradCAM for class 'automobile'\n",
      "[INFO] Generating GradCAM for class 'bird'\n",
      "[INFO] Generating GradCAM for class 'cat'\n",
      "[INFO] Generating GradCAM for class 'deer'\n",
      "[INFO] Generating GradCAM for class 'dog'\n",
      "[INFO] Generating GradCAM for class 'frog'\n",
      "[INFO] Generating GradCAM for class 'horse'\n",
      "[INFO] Generating GradCAM for class 'ship'\n",
      "[INFO] Generating GradCAM for class 'truck'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gading\\AppData\\Local\\Temp\\ipykernel_2972\\4289822869.py:614: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] GradCAM visualizations saved to output/gradcam_visualization.png\n",
      "==================================================\n",
      "Evaluation completed successfully with 96.76% accuracy\n",
      "All results saved to 'output' directory\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.amp import autocast\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set the style for plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Set environment variables for better performance\n",
    "os.environ['OMP_NUM_THREADS'] = '4'  # Optimize CPU threading\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'  # Limit memory fragmentation\n",
    "\n",
    "\n",
    "####################################\n",
    "# 1. Configuration Class\n",
    "####################################\n",
    "class EvalConfig:\n",
    "    def __init__(self):\n",
    "        # Paths\n",
    "        self.dataset_path = r\"C:\\Users\\Gading\\Downloads\\Research\\Dataset\\CIFAR-10\"\n",
    "        self.checkpoint_path = r\"C:\\Users\\Gading\\Downloads\\Research\\Models\\DenseNet121\\checkpoints\\densenet121_teacher_20250508_114100_best.pth\"\n",
    "        self.output_dir = \"output\"\n",
    "        \n",
    "        # Hardware settings - optimized for stability\n",
    "        self.batch_size = 8  # Reduced for stability\n",
    "        self.num_workers = 0  # Start with 0 workers to avoid hanging\n",
    "        self.use_amp = True\n",
    "        self.pin_memory = True\n",
    "        \n",
    "        # CIFAR-10 classes\n",
    "        self.classes = ('airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "                        'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "        \n",
    "        # ImageNet normalization (used by DenseNet121)\n",
    "        self.mean = [0.485, 0.456, 0.406]\n",
    "        self.std = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "####################################\n",
    "# 2. Utilities\n",
    "####################################\n",
    "def setup_environment():\n",
    "    \"\"\"Setup environment and output directory\"\"\"\n",
    "    # Create output directory\n",
    "    config = EvalConfig()\n",
    "    os.makedirs(config.output_dir, exist_ok=True)\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"[INFO] Using device: {device}\")\n",
    "    \n",
    "    # Show GPU info if available\n",
    "    if device.type == 'cuda':\n",
    "        print(f\"[INFO] GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"[INFO] Available memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    \n",
    "    return config, device\n",
    "\n",
    "\n",
    "####################################\n",
    "# 3. Dataset and DataLoader\n",
    "####################################\n",
    "def get_test_dataset(config):\n",
    "    \"\"\"Create a simple CIFAR-10 test dataset\"\"\"\n",
    "    print(\"[INFO] Preparing test dataset...\")\n",
    "    \n",
    "    # Model transform: resize to 224x224 (ResNet50 standard) and normalize\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(224, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=config.mean, std=config.std),\n",
    "    ])\n",
    "    \n",
    "    # Load the dataset\n",
    "    try:\n",
    "        test_dataset = datasets.CIFAR10(\n",
    "            root=config.dataset_path,\n",
    "            train=False,\n",
    "            download=True,  # Always attempt to download\n",
    "            transform=transform\n",
    "        )\n",
    "        print(f\"[INFO] Test dataset loaded with {len(test_dataset)} samples\")\n",
    "        return test_dataset\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to load dataset: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def get_original_images(config, indices):\n",
    "    \"\"\"Get original 32x32 images for display purposes\"\"\"\n",
    "    # Load dataset without transformations\n",
    "    orig_dataset = datasets.CIFAR10(\n",
    "        root=config.dataset_path,\n",
    "        train=False,\n",
    "        download=False  # Already downloaded\n",
    "    )\n",
    "    \n",
    "    originals = []\n",
    "    labels = []\n",
    "    \n",
    "    for idx in indices:\n",
    "        img, label = orig_dataset.data[idx], orig_dataset.targets[idx]\n",
    "        img = Image.fromarray(img)\n",
    "        img_tensor = transforms.ToTensor()(img)\n",
    "        originals.append(img_tensor)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return originals, labels\n",
    "\n",
    "\n",
    "def create_data_loader(dataset, config):\n",
    "    \"\"\"Create a DataLoader with optimized settings\"\"\"\n",
    "    print(\"[INFO] Creating DataLoader...\")\n",
    "    \n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=config.pin_memory,\n",
    "        persistent_workers=False,  # Avoid hanging issues\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    print(f\"[INFO] DataLoader created with batch size {config.batch_size}\")\n",
    "    return loader\n",
    "\n",
    "\n",
    "####################################\n",
    "# 4. Model Loading\n",
    "####################################\n",
    "def load_model(config, device):\n",
    "    \"\"\"Load the DenseNet121 model from checkpoint\"\"\"\n",
    "    print(f\"[INFO] Loading model from: {config.checkpoint_path}\")\n",
    "    \n",
    "    try:\n",
    "        import torch.nn as nn\n",
    "        from torchvision.models import densenet121\n",
    "        \n",
    "        # Create model architecture\n",
    "        model = densenet121(weights=None)\n",
    "        \n",
    "        # Get the in_features for the classifier\n",
    "        in_features = model.classifier.in_features\n",
    "        \n",
    "        # Replace the classifier for CIFAR-10\n",
    "        model.classifier = nn.Linear(in_features, 10)  # CIFAR-10 has 10 classes\n",
    "        \n",
    "        # Load checkpoint with safety settings\n",
    "        checkpoint = torch.load(\n",
    "            config.checkpoint_path, \n",
    "            map_location=device,\n",
    "            weights_only=True  # Safer loading\n",
    "        )\n",
    "        \n",
    "        # Handle different checkpoint formats\n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint)\n",
    "        \n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        print(\"[INFO] DenseNet121 model loaded successfully and set to evaluation mode\")\n",
    "        \n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to load model: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "####################################\n",
    "# 5. Inference\n",
    "####################################\n",
    "def run_inference(model, loader, config, device):\n",
    "    \"\"\"Run inference on the test set\"\"\"\n",
    "    print(\"[INFO] Running inference on test set...\")\n",
    "    \n",
    "    # Store predictions and targets\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_logits = []  # Added to store raw logits\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Disable gradient computation for inference\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(loader, desc=\"Evaluation\"):\n",
    "            # Move data to device\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Use mixed precision if available and enabled\n",
    "            if config.use_amp and device.type == 'cuda':\n",
    "                with autocast(device_type='cuda'):\n",
    "                    outputs = model(images)\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "            \n",
    "            # Get predictions\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(probs, dim=1)\n",
    "            \n",
    "            # Store results (on CPU to save GPU memory)\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "            all_logits.append(outputs.cpu().numpy())  # Store logits\n",
    "            \n",
    "            # Free memory\n",
    "            del images, outputs, probs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_probs = np.concatenate(all_probs, axis=0)\n",
    "    all_logits = np.concatenate(all_logits, axis=0)  # Concatenate logits\n",
    "    \n",
    "    print(f\"[INFO] Inference complete on {len(all_targets)} samples\")\n",
    "    return np.array(all_targets), np.array(all_preds), all_probs, np.array(all_logits)\n",
    "\n",
    "\n",
    "####################################\n",
    "# 6. Evaluation Metrics\n",
    "####################################\n",
    "def analyze_results(y_true, y_pred, y_logits, y_probs, class_names, config):\n",
    "    \"\"\"Generate and save evaluation metrics\"\"\"\n",
    "    print(\"[INFO] Analyzing model performance...\")\n",
    "    \n",
    "    # 1. Calculate and print accuracy\n",
    "    accuracy = np.mean(y_true == y_pred) * 100\n",
    "    print(f\"[RESULT] Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Calculate Cross-Entropy Loss\n",
    "    try:\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        loss = loss_fn(torch.from_numpy(y_logits), torch.from_numpy(y_true).long())\n",
    "        loss_value = loss.item()\n",
    "        print(f\"[RESULT] Test Cross-Entropy Loss: {loss_value:.4f}\")\n",
    "    except Exception as e:\n",
    "        loss_value = \"N/A\"\n",
    "        print(f\"[WARNING] Could not calculate Cross-Entropy Loss: {e}\")\n",
    "    \n",
    "    # Binarize y_true for AUC calculations\n",
    "    y_true_binarized = label_binarize(y_true, classes=range(len(class_names)))\n",
    "\n",
    "    # 2. Calculate AUC-ROC\n",
    "    auc_roc_macro = \"N/A\"\n",
    "    auc_roc_weighted = \"N/A\"\n",
    "    try:\n",
    "        if y_probs is not None and y_true_binarized.shape[1] > 1:  # Check for multi-class\n",
    "            auc_roc_macro = roc_auc_score(y_true_binarized, y_probs, average='macro', multi_class='ovr')\n",
    "            auc_roc_weighted = roc_auc_score(y_true_binarized, y_probs, average='weighted', multi_class='ovr')\n",
    "            print(f\"[RESULT] AUC-ROC (Macro): {auc_roc_macro:.4f}\")\n",
    "            print(f\"[RESULT] AUC-ROC (Weighted): {auc_roc_weighted:.4f}\")\n",
    "        elif y_probs is not None and y_true_binarized.shape[1] == 1:  # Binary case (should not happen for CIFAR-10)\n",
    "            y_probs_binary = y_probs[:, 1] if y_probs.ndim == 2 and y_probs.shape[1] == 2 else y_probs\n",
    "            auc_roc_macro = roc_auc_score(y_true, y_probs_binary)  # default is macro for binary\n",
    "            auc_roc_weighted = auc_roc_macro  # weighted is same as macro for binary\n",
    "            print(f\"[RESULT] AUC-ROC: {auc_roc_macro:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARNING] Could not calculate AUC-ROC: {e}\")\n",
    "\n",
    "    # 3. Calculate AUC-PR (Average Precision)\n",
    "    auc_pr_macro = \"N/A\"\n",
    "    auc_pr_weighted = \"N/A\"\n",
    "    try:\n",
    "        if y_probs is not None and y_true_binarized.shape[1] > 1:  # Check for multi-class\n",
    "            auc_pr_macro = average_precision_score(y_true_binarized, y_probs, average='macro')\n",
    "            auc_pr_weighted = average_precision_score(y_true_binarized, y_probs, average='weighted')\n",
    "            print(f\"[RESULT] AUC-PR (Macro): {auc_pr_macro:.4f}\")\n",
    "            print(f\"[RESULT] AUC-PR (Weighted): {auc_pr_weighted:.4f}\")\n",
    "        elif y_probs is not None and y_true_binarized.shape[1] == 1:  # Binary case\n",
    "            y_probs_binary = y_probs[:, 1] if y_probs.ndim == 2 and y_probs.shape[1] == 2 else y_probs\n",
    "            auc_pr_macro = average_precision_score(y_true, y_probs_binary)  # default is macro for binary\n",
    "            auc_pr_weighted = auc_pr_macro\n",
    "            print(f\"[RESULT] AUC-PR: {auc_pr_macro:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARNING] Could not calculate AUC-PR: {e}\")\n",
    "\n",
    "    # 4. Generate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f\"Confusion Matrix - CIFAR-10 (Accuracy: {accuracy:.2f}%)\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{config.output_dir}/confusion_matrix.png\", dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. Generate classification report\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names, digits=3)\n",
    "    print(\"\\n[RESULT] Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    # Save report to file\n",
    "    with open(f\"{config.output_dir}/classification_report.txt\", \"w\") as f:\n",
    "        f.write(f\"Test Accuracy: {accuracy:.2f}%\\n\")\n",
    "        f.write(f\"Test Cross-Entropy Loss: {loss_value if isinstance(loss_value, str) else f'{loss_value:.4f}'}\\n\")\n",
    "        f.write(f\"AUC-ROC (Macro): {auc_roc_macro if isinstance(auc_roc_macro, str) else f'{auc_roc_macro:.4f}'}\\n\")\n",
    "        f.write(f\"AUC-ROC (Weighted): {auc_roc_weighted if isinstance(auc_roc_weighted, str) else f'{auc_roc_weighted:.4f}'}\\n\")\n",
    "        f.write(f\"AUC-PR (Macro): {auc_pr_macro if isinstance(auc_pr_macro, str) else f'{auc_pr_macro:.4f}'}\\n\")\n",
    "        f.write(f\"AUC-PR (Weighted): {auc_pr_weighted if isinstance(auc_pr_weighted, str) else f'{auc_pr_weighted:.4f}'}\\n\\n\")\n",
    "        f.write(report)\n",
    "    \n",
    "    # 6. Per-class accuracy\n",
    "    class_acc = cm.diagonal() / cm.sum(axis=1) * 100\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=list(class_names), y=class_acc)\n",
    "    plt.title(\"Per-Class Accuracy\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.ylim(0, 100)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{config.output_dir}/per_class_accuracy.png\", dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"[INFO] Evaluation results saved to {config.output_dir}\")\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "####################################\n",
    "# 7. Visualization Helpers\n",
    "####################################\n",
    "def visualize_predictions(model, test_dataset, config, device, num_examples=5):\n",
    "    \"\"\"Visualize random predictions with original CIFAR-10 images\"\"\"\n",
    "    print(\"[INFO] Generating prediction visualizations...\")\n",
    "    \n",
    "    # Use a professional style\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'sans-serif',\n",
    "        'font.sans-serif': ['Arial', 'Helvetica', 'DejaVu Sans'],\n",
    "        'font.size': 9,\n",
    "        'axes.titlesize': 10,\n",
    "        'axes.labelsize': 9\n",
    "    })\n",
    "    \n",
    "    # Define colors for correct and incorrect predictions\n",
    "    correct_color = '#1f77b4'  # Professional blue\n",
    "    incorrect_color = '#d62728'  # Professional red\n",
    "    \n",
    "    # Select random indices\n",
    "    indices = np.random.choice(len(test_dataset), size=num_examples*len(config.classes), replace=False)\n",
    "    \n",
    "    # Get original images and labels\n",
    "    originals, true_labels = get_original_images(config, indices)\n",
    "    \n",
    "    # Prepare a batch of transformed images for the model\n",
    "    batch_images = torch.stack([test_dataset[idx][0] for idx in indices]).to(device)\n",
    "    \n",
    "    # Get predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if config.use_amp and device.type == 'cuda':\n",
    "            with autocast(device_type='cuda'):\n",
    "                outputs = model(batch_images)\n",
    "        else:\n",
    "            outputs = model(batch_images)\n",
    "    \n",
    "    # Get prediction probabilities and classes\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    pred_scores, pred_labels = torch.max(probs, dim=1)\n",
    "    \n",
    "    # Convert to numpy\n",
    "    pred_labels = pred_labels.cpu().numpy()\n",
    "    pred_scores = pred_scores.cpu().numpy()\n",
    "    \n",
    "    # Plot results - create a figure with better proportions\n",
    "    fig, axes = plt.subplots(len(config.classes), num_examples, figsize=(num_examples*2.5, len(config.classes)*2))\n",
    "    fig.suptitle(\"CIFAR-10 Prediction Examples (DenseNet121)\", fontsize=14, y=0.98)\n",
    "    \n",
    "    # Group samples by true class\n",
    "    class_indices = {i: [] for i in range(len(config.classes))}\n",
    "    for i, label in enumerate(true_labels):\n",
    "        if len(class_indices[label]) < num_examples:\n",
    "            class_indices[label].append(i)\n",
    "    \n",
    "    for class_idx in range(len(config.classes)):\n",
    "        for example_idx in range(num_examples):\n",
    "            ax = axes[class_idx, example_idx]\n",
    "            \n",
    "            # Check if we have enough examples for this class\n",
    "            if example_idx < len(class_indices[class_idx]):\n",
    "                i = class_indices[class_idx][example_idx]\n",
    "                \n",
    "                # Plot image with a border\n",
    "                img = originals[i].permute(1, 2, 0).numpy()\n",
    "                ax.imshow(img)\n",
    "                \n",
    "                # Add prediction info with better formatting\n",
    "                true_label = true_labels[i]\n",
    "                pred_label = pred_labels[i]\n",
    "                color = correct_color if true_label == pred_label else incorrect_color\n",
    "                \n",
    "                # Create a clean title with proper formatting\n",
    "                ax.set_title(f\"True: {config.classes[true_label]}\\nPred: {config.classes[pred_label]}\\nConf: {pred_scores[i]:.3f}\", \n",
    "                            color=color, fontsize=9, pad=3)\n",
    "                \n",
    "                # Add a professional border\n",
    "                for spine in ax.spines.values():\n",
    "                    spine.set_edgecolor(color)\n",
    "                    spine.set_linewidth(1.5)\n",
    "            else:\n",
    "                # If not enough examples, hide the empty subplot\n",
    "                ax.set_visible(False)\n",
    "            \n",
    "            # Remove ticks for all subplots (whether they have content or not)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    \n",
    "    # Add row labels on the left\n",
    "    for class_idx in range(len(config.classes)):\n",
    "        if axes[class_idx, 0].get_visible():  # Only add label if the first subplot in row is visible\n",
    "            axes[class_idx, 0].set_ylabel(config.classes[class_idx], fontsize=10, \n",
    "                                        rotation=90, labelpad=10, va='center')\n",
    "    \n",
    "    # Add a footer with model information\n",
    "    plt.figtext(0.5, 0.01, \n",
    "               f\"DenseNet121 evaluation on CIFAR-10 test set\", \n",
    "               ha=\"center\", fontsize=10, style='italic')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.95, bottom=0.05)\n",
    "    plt.savefig(f\"{config.output_dir}/prediction_examples.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"[INFO] Prediction visualizations saved to {config.output_dir}/prediction_examples.png\")\n",
    "\n",
    "\n",
    "####################################\n",
    "# 8. GradCAM Implementation\n",
    "####################################\n",
    "class GradCAM:\n",
    "    \"\"\"Gradient-weighted Class Activation Mapping\"\"\"\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.activations = None\n",
    "        self.gradients = None\n",
    "        self.hook_handles = []\n",
    "        self._register_hooks()\n",
    "    \n",
    "    def _register_hooks(self):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output.clone().detach()  # Use clone to avoid view issues\n",
    "        \n",
    "        def backward_hook(module, grad_input, grad_output):\n",
    "            self.gradients = grad_output[0].clone().detach()  # Use clone to avoid view issues\n",
    "        \n",
    "        # Register hooks\n",
    "        self.hook_handles.append(self.target_layer.register_forward_hook(forward_hook))\n",
    "        self.hook_handles.append(self.target_layer.register_full_backward_hook(backward_hook))\n",
    "    \n",
    "    def generate_cam(self, input_tensor, target_class=None):\n",
    "        # Forward pass\n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        # Get prediction if target class not specified\n",
    "        if target_class is None:\n",
    "            with torch.no_grad():\n",
    "                output = self.model(input_tensor)\n",
    "                target_class = output.argmax(dim=1)\n",
    "        \n",
    "        # Forward pass with gradients\n",
    "        output = self.model(input_tensor)\n",
    "        loss = output[:, target_class].sum()\n",
    "        \n",
    "        # Backward pass\n",
    "        self.model.zero_grad()\n",
    "        loss.backward(retain_graph=True)  # Use retain_graph=True to ensure proper gradient flow\n",
    "        \n",
    "        # Generate CAM\n",
    "        weights = self.gradients.mean(dim=(2, 3), keepdim=True)\n",
    "        cam = (weights * self.activations).sum(dim=1, keepdim=True)\n",
    "        cam = torch.relu(cam)  # Use functional relu instead of inplace operation\n",
    "        \n",
    "        # Upsample CAM to input size\n",
    "        cam = torch.nn.functional.interpolate(\n",
    "            cam, \n",
    "            size=input_tensor.shape[2:], \n",
    "            mode='bilinear', \n",
    "            align_corners=False\n",
    "        )\n",
    "        \n",
    "        # Normalize CAM\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
    "        \n",
    "        return cam\n",
    "    \n",
    "    def remove_hooks(self):\n",
    "        for handle in self.hook_handles:\n",
    "            handle.remove()\n",
    "\n",
    "\n",
    "def visualize_gradcam(model, test_dataset, config, device):\n",
    "    \"\"\"Create GradCAM visualizations for each class with improved scientific appearance\"\"\"\n",
    "    print(\"[INFO] Generating GradCAM visualizations...\")\n",
    "    \n",
    "    # Set scientific plotting style\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'sans-serif',\n",
    "        'font.sans-serif': ['Arial', 'Helvetica', 'DejaVu Sans'],\n",
    "        'font.size': 10,\n",
    "        'axes.titlesize': 11,\n",
    "        'axes.labelsize': 10\n",
    "    })\n",
    "    \n",
    "    # Find one sample per class\n",
    "    samples_by_class = {c: None for c in range(len(config.classes))}\n",
    "    indices_by_class = {c: None for c in range(len(config.classes))}\n",
    "    \n",
    "    for idx in tqdm(range(len(test_dataset)), desc=\"Finding class samples\"):\n",
    "        _, label = test_dataset[idx]\n",
    "        if samples_by_class[label] is None:\n",
    "            samples_by_class[label] = test_dataset[idx][0].unsqueeze(0)\n",
    "            indices_by_class[label] = idx\n",
    "        if all(v is not None for v in samples_by_class.values()):\n",
    "            break\n",
    "    \n",
    "    # Create a modified copy of the model with inplace operations disabled to avoid GradCAM issues\n",
    "    import copy\n",
    "    model_for_gradcam = copy.deepcopy(model)\n",
    "    \n",
    "    # Turn off in-place ReLU operations in the model\n",
    "    for module in model_for_gradcam.modules():\n",
    "        if hasattr(module, 'inplace'):\n",
    "            module.inplace = False\n",
    "            \n",
    "    # Initialize GradCAM with the appropriate layer for DenseNet121\n",
    "    target_layer = model_for_gradcam.features.denseblock4.denselayer16.norm2  # Final norm layer in last dense block\n",
    "    grad_cam = GradCAM(model_for_gradcam, target_layer)\n",
    "    \n",
    "    # Use a scientific colormap\n",
    "    cmap = 'inferno'  # Scientific colormap that works well for heatmaps\n",
    "    \n",
    "    # Create a figure with 2 rows (original and heatmap) x 5 columns\n",
    "    fig, axes = plt.subplots(4, 5, figsize=(15, 12))\n",
    "    fig.suptitle(\"GradCAM Visualizations for CIFAR-10 Classes (DenseNet121)\", fontsize=14, y=0.98)\n",
    "    \n",
    "    # Create a mapping for 2x5 grid with proper organization\n",
    "    class_to_position = {\n",
    "        0: (0, 0),  # airplane\n",
    "        1: (0, 1),  # automobile\n",
    "        2: (0, 2),  # bird\n",
    "        3: (0, 3),  # cat\n",
    "        4: (0, 4),  # deer\n",
    "        5: (2, 0),  # dog\n",
    "        6: (2, 1),  # frog\n",
    "        7: (2, 2),  # horse\n",
    "        8: (2, 3),  # ship\n",
    "        9: (2, 4),  # truck\n",
    "    }\n",
    "    \n",
    "    for class_idx in range(len(config.classes)):\n",
    "        print(f\"[INFO] Generating GradCAM for class '{config.classes[class_idx]}'\")\n",
    "        \n",
    "        # Get the sample\n",
    "        input_tensor = samples_by_class[class_idx].to(device)\n",
    "        \n",
    "        # Generate CAM\n",
    "        cam = grad_cam.generate_cam(input_tensor, target_class=class_idx)\n",
    "        cam = cam.cpu().numpy()[0, 0]\n",
    "        \n",
    "        # Get original image\n",
    "        orig_imgs, _ = get_original_images(config, [indices_by_class[class_idx]])\n",
    "        orig_img = orig_imgs[0].permute(1, 2, 0).numpy()\n",
    "        \n",
    "        # Upsample original image to match model input size (224x224)\n",
    "        img_upsampled = transforms.Resize(224)(orig_imgs[0])\n",
    "        img_upsampled = img_upsampled.permute(1, 2, 0).numpy()\n",
    "        \n",
    "        # Get row, col position\n",
    "        row, col = class_to_position[class_idx]\n",
    "        \n",
    "        # Plot original image\n",
    "        ax_orig = axes[row, col]\n",
    "        ax_orig.imshow(img_upsampled)\n",
    "        ax_orig.set_title(f\"{config.classes[class_idx]} (Original)\", fontsize=11)\n",
    "        ax_orig.set_xticks([])\n",
    "        ax_orig.set_yticks([])\n",
    "        \n",
    "        # Plot heatmap overlay\n",
    "        ax_overlay = axes[row+1, col]\n",
    "        ax_overlay.imshow(img_upsampled)\n",
    "        heatmap = ax_overlay.imshow(cam, cmap=cmap, alpha=0.6)\n",
    "        ax_overlay.set_title(f\"{config.classes[class_idx]} (GradCAM)\", fontsize=11)\n",
    "        ax_overlay.set_xticks([])\n",
    "        ax_overlay.set_yticks([])\n",
    "    \n",
    "    # Add a colorbar for the heatmap\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    cbar = fig.colorbar(heatmap, cax=cbar_ax)\n",
    "    cbar.set_label('Activation Strength', fontsize=10)\n",
    "    \n",
    "    # Add a footer with model information\n",
    "    plt.figtext(0.5, 0.01, \n",
    "                \"GradCAM visualizations show regions the model focuses on when classifying each category\",\n",
    "                ha=\"center\", fontsize=10, style='italic')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(right=0.9, top=0.95, bottom=0.05)\n",
    "    plt.savefig(f\"{config.output_dir}/gradcam_visualization.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Clean up\n",
    "    grad_cam.remove_hooks()\n",
    "    del model_for_gradcam  # Clean up the modified model\n",
    "    torch.cuda.empty_cache()  # Free up GPU memory\n",
    "    \n",
    "    print(f\"[INFO] GradCAM visualizations saved to {config.output_dir}/gradcam_visualization.png\")\n",
    "\n",
    "\n",
    "####################################\n",
    "# 9. Main Evaluation Function\n",
    "####################################\n",
    "def main():\n",
    "    \"\"\"Main evaluation pipeline\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"DenseNet121 CIFAR-10 Evaluation Pipeline\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Setup\n",
    "    config, device = setup_environment()\n",
    "    \n",
    "    try:\n",
    "        # 1. Load the dataset\n",
    "        test_dataset = get_test_dataset(config)\n",
    "        test_loader = create_data_loader(test_dataset, config)\n",
    "        \n",
    "        # 2. Load the model\n",
    "        model = load_model(config, device)\n",
    "        \n",
    "        # 3. Run inference\n",
    "        targets, predictions, probabilities, logits = run_inference(model, test_loader, config, device)\n",
    "        \n",
    "        # 4. Generate metrics\n",
    "        accuracy = analyze_results(targets, predictions, logits, probabilities, config.classes, config)\n",
    "        \n",
    "        # 5. Visualize predictions\n",
    "        visualize_predictions(model, test_dataset, config, device)\n",
    "        \n",
    "        # 6. Generate GradCAM visualizations\n",
    "        visualize_gradcam(model, test_dataset, config, device)\n",
    "        \n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Evaluation completed successfully with {accuracy:.2f}% accuracy\")\n",
    "        print(f\"All results saved to '{config.output_dir}' directory\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"[ERROR] An error occurred: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        print(\"\\nTry adjusting the batch_size or num_workers in EvalConfig if experiencing memory issues.\")\n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
