{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Visualization of Mutual Learning Metrics\n",
    "\n",
    "This notebook produces professional-grade visualizations for an IEEE research paper on mutual learning, ensemble distillation, and uncertainty calibration. It generates multiple plots from the training logs:\n",
    "\n",
    "1. **Main Dashboard**: Combined metrics with smoothed, interpolated curves\n",
    "2. **Teacher vs. Student Comparison**: Direct comparison between teacher models and student\n",
    "3. **Final Performance Radar**: Multi-dimensional performance visualization\n",
    "4. **Weight Evolution**: How mutual learning and calibration weights changed\n",
    "5. **Calibration Reliability**: Visualization of model calibration quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the enhanced visualization script\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure all required packages are installed\n",
    "try:\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    from scipy.interpolate import make_interp_spline\n",
    "    from scipy.ndimage import gaussian_filter1d\n",
    "except ImportError:\n",
    "    !pip install numpy matplotlib pandas seaborn scipy\n",
    "    \n",
    "# Execute the visualization script\n",
    "%run -i visualize_metrics.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dashboard with Smoothed Metrics\n",
    "\n",
    "The main dashboard shows all training metrics with professionally smoothed curves using Gaussian filtering. This enhances the visual appearance while preserving the underlying trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the main dashboard\n",
    "from IPython.display import Image, display\n",
    "\n",
    "dashboard_path = Path(r\"C:\\Users\\Gading\\Downloads\\Research\\Results\\MutualLearning\\plots\\mutual_learning_metrics_dashboard_smooth.png\")\n",
    "if dashboard_path.exists():\n",
    "    display(Image(str(dashboard_path)))\n",
    "else:\n",
    "    print(f\"Dashboard image not found at {dashboard_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Teacher vs. Student Performance Comparison\n",
    "\n",
    "This visualization directly compares the performance of teacher models against the student model, highlighting knowledge transfer effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the teacher vs student comparison\n",
    "teacher_student_path = Path(r\"C:\\Users\\Gading\\Downloads\\Research\\Results\\MutualLearning\\plots\\teacher_vs_student_comparison.png\")\n",
    "if teacher_student_path.exists():\n",
    "    display(Image(str(teacher_student_path)))\n",
    "else:\n",
    "    print(f\"Teacher vs Student comparison not found at {teacher_student_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Final Model Performance Radar Chart\n",
    "\n",
    "The radar chart provides a multi-dimensional view of model performance across accuracy, loss, and calibration metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the radar chart\n",
    "radar_path = Path(r\"C:\\Users\\Gading\\Downloads\\Research\\Results\\MutualLearning\\plots\\final_performance_radar.png\")\n",
    "if radar_path.exists():\n",
    "    display(Image(str(radar_path)))\n",
    "else:\n",
    "    print(f\"Radar chart not found at {radar_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Weight Evolution During Training\n",
    "\n",
    "This plot shows how mutual learning and calibration weights evolved throughout training, providing insight into the learning process dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the weight evolution plot\n",
    "weights_path = Path(r\"C:\\Users\\Gading\\Downloads\\Research\\Results\\MutualLearning\\plots\\weight_evolution.png\")\n",
    "if weights_path.exists():\n",
    "    display(Image(str(weights_path)))\n",
    "else:\n",
    "    print(f\"Weight evolution plot not found at {weights_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calibration Reliability Diagram\n",
    "\n",
    "The reliability diagram visualizes model calibration by showing the relationship between predicted confidence and actual accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the reliability diagram\n",
    "reliability_path = Path(r\"C:\\Users\\Gading\\Downloads\\Research\\Results\\MutualLearning\\plots\\calibration_reliability_diagram.png\")\n",
    "if reliability_path.exists():\n",
    "    display(Image(str(reliability_path)))\n",
    "else:\n",
    "    print(f\"Reliability diagram not found at {reliability_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Key Findings\n",
    "\n",
    "These visualizations demonstrate several important findings:\n",
    "\n",
    "1. **Student Performance**: The student model achieves accuracy comparable to or better than most teacher models while maintaining good calibration.\n",
    "\n",
    "2. **Calibration Quality**: All models show low Expected Calibration Error (ECE), indicating well-calibrated predictions.\n",
    "\n",
    "3. **Temperature Evolution**: Temperature parameters stabilize after initial epochs, suggesting convergence to optimal confidence levels.\n",
    "\n",
    "4. **Architecture Patterns**: Different architectures show distinct learning patterns, with some (like ViT) having slower convergence but comparable final performance.\n",
    "\n",
    "5. **Knowledge Transfer**: The mutual learning approach successfully transfers knowledge across diverse architectures, demonstrating the effectiveness of the collaborative learning framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final performance table for the paper\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_final_metrics(log_path):\n",
    "    # Extract metrics from log file\n",
    "    metrics_df, _ = extract_metrics_from_log(log_path)\n",
    "    \n",
    "    # Get the final epoch\n",
    "    max_epoch = metrics_df['epoch'].max()\n",
    "    final_metrics = metrics_df[metrics_df['epoch'] == max_epoch]\n",
    "    \n",
    "    # Prepare table data\n",
    "    table_data = []\n",
    "    for _, row in final_metrics.iterrows():\n",
    "        table_data.append({\n",
    "            'Model': MODEL_DISPLAY_NAMES[row['model']],\n",
    "            'Validation Accuracy (%)': f\"{row['val_acc']:.2f}\",\n",
    "            'Training Accuracy (%)': f\"{row['train_acc']:.2f}\",\n",
    "            'Validation Loss': f\"{row['val_loss']:.4f}\",\n",
    "            'Training Loss': f\"{row['train_loss']:.4f}\",\n",
    "            'ECE': f\"{row['ece']:.4f}\",\n",
    "            'Temperature': f\"{row['temperature']:.2f}\"\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(table_data)\n",
    "\n",
    "# Get log path and extract metrics\n",
    "log_path = Path(r\"C:\\Users\\Gading\\Downloads\\Research\\Results\\MutualLearning\\logs\\error.log\")\n",
    "final_table = extract_final_metrics(log_path)\n",
    "\n",
    "# Style the table with highlighted best values\n",
    "def highlight_max(s, props=''):\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: lightgreen' if v else '' for v in is_max]\n",
    "\n",
    "def highlight_min(s, props=''):\n",
    "    is_min = s == s.min()\n",
    "    return ['background-color: lightgreen' if v else '' for v in is_min]\n",
    "\n",
    "# Convert string columns to numeric for comparison\n",
    "numeric_cols = final_table.columns[1:]\n",
    "comparison_df = final_table.copy()\n",
    "for col in numeric_cols:\n",
    "    comparison_df[col] = pd.to_numeric(final_table[col], errors='coerce')\n",
    "\n",
    "# Apply styling\n",
    "styled_table = final_table.style\\\n",
    "    .apply(highlight_max, subset=['Validation Accuracy (%)', 'Training Accuracy (%)'])\\\n",
    "    .apply(highlight_min, subset=['Validation Loss', 'Training Loss', 'ECE'])\\\n",
    "    .set_properties(**{'text-align': 'center'})\\\n",
    "    .set_caption(\"Final Model Performance Metrics (Epoch 49)\")\n",
    "\n",
    "# Display the table\n",
    "styled_table"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
