{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a785e16",
   "metadata": {},
   "source": [
    "Baseline Training Script for Student Model (Scaled EfficientNet-B0) on CIFAR-10\n",
    "- Uses only cross-entropy loss (no ensemble distillation, no mutual learning, no calibration)\n",
    "- Initialized with ImageNet pre-trained weights\n",
    "- Two training modes:\n",
    "  1. Default (--include-warmup): Two-phase schedule with 5 epochs warm-up + 50 epochs main training (CE-only baseline for mutual learning)\n",
    "  2. No warm-up (--no-warmup): Single-phase schedule with 50 epochs (CE-only baseline for ensemble distillation)\n",
    "\n",
    "Part of the research: \n",
    "\"Comparative Analysis of Ensemble Distillation and Mutual Learning: \n",
    "A Unified Framework for Uncertainty-Calibrated Vision Systems\"\n",
    "\n",
    "Target Hardware: RTX 3060 Laptop (6GB VRAM)\n",
    "Optimizations: AMP, gradient accumulation, memory-efficient techniques, GPU cache clearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48124bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-19 16:49:15,714 [INFO] - Using device: cuda\n",
      "2025-04-19 16:49:15,715 [INFO] - GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "2025-04-19 16:49:15,716 [INFO] - GPU Memory: 6.00 GB\n",
      "2025-04-19 16:49:15,717 [INFO] - CUDA Version: 12.4\n",
      "2025-04-19 16:49:15,717 [INFO] - cuDNN benchmark mode enabled\n",
      "2025-04-19 16:49:15,722 [INFO] - Running in Jupyter Notebook environment\n",
      "2025-04-19 16:49:15,723 [INFO] - Using include_warmup_phase=True\n",
      "2025-04-19 16:49:15,724 [INFO] - Training with two-phase schedule: 5 warm-up epochs + 50 main epochs\n",
      "2025-04-19 16:49:15,725 [INFO] - This will establish a baseline for MUTUAL LEARNING comparison\n",
      "2025-04-19 16:49:15,725 [INFO] - Total epochs: 55\n",
      "2025-04-19 16:49:15,725 [INFO] - Configuration: {\n",
      "    \"seed\": 42,\n",
      "    \"model_name\": \"baseline_student\",\n",
      "    \"dataset\": \"CIFAR-10\",\n",
      "    \"use_amp\": true,\n",
      "    \"prefetch_factor\": 2,\n",
      "    \"pin_memory\": true,\n",
      "    \"persistent_workers\": true,\n",
      "    \"batch_size\": 64,\n",
      "    \"gradient_accumulation_steps\": 1,\n",
      "    \"input_size\": 32,\n",
      "    \"model_input_size\": 224,\n",
      "    \"num_workers\": 4,\n",
      "    \"val_split\": 0.1,\n",
      "    \"dataset_path\": \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Dataset\",\n",
      "    \"clear_cache_every_n_epochs\": 1,\n",
      "    \"pretrained\": true,\n",
      "    \"num_classes\": 10,\n",
      "    \"include_warmup_phase\": true,\n",
      "    \"warmup_epochs\": 5,\n",
      "    \"main_epochs\": 50,\n",
      "    \"total_epochs\": 55,\n",
      "    \"lr\": 0.001,\n",
      "    \"weight_decay\": 0.0001,\n",
      "    \"early_stop_patience\": 10,\n",
      "    \"checkpoint_dir\": \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Models\\\\Baseline\\\\checkpoints\",\n",
      "    \"results_dir\": \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Results\\\\Baseline\",\n",
      "    \"export_dir\": \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Models\\\\Baseline\\\\exports\"\n",
      "}\n",
      "2025-04-19 16:49:15,728 [INFO] - Random seed set to 42\n",
      "2025-04-19 16:49:15,735 [INFO] - GPU Memory: Current=0.00MB, Peak=0.00MB, Reserved=0.00MB\n",
      "2025-04-19 16:49:15,735 [INFO] - Preparing data loaders...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-19 16:49:17,568 [INFO] - Training samples: 45000\n",
      "2025-04-19 16:49:17,569 [INFO] - Validation samples: 5000\n",
      "2025-04-19 16:49:17,569 [INFO] - Test samples: 10000\n",
      "2025-04-19 16:49:17,569 [INFO] - Creating student model...\n",
      "2025-04-19 16:49:17,569 [INFO] - Creating EfficientNet-B0 student model with ImageNet pre-trained weights...\n",
      "2025-04-19 16:49:17,724 [INFO] - Student model created with 4.02M parameters\n",
      "2025-04-19 16:49:17,888 [INFO] - Training student with baseline supervised learning...\n",
      "2025-04-19 16:49:17,888 [INFO] - Training student model with baseline supervised learning...\n",
      "2025-04-19 16:49:17,895 [INFO] - Configuration saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline\\baseline_student_20250419_164917_config.json\n",
      "2025-04-19 16:49:17,895 [INFO] - Epoch 1/55 (Warmup Phase)\n",
      "2025-04-19 16:49:18,047 [INFO] - GPU cache cleared: 15.57MB → 15.57MB (freed 0.00MB)\n",
      "Training (Warmup Phase): 100%|██████████| 704/704 [01:48<00:00,  6.48it/s, loss=0.419, acc=85.9]\n",
      "Validating: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n",
      "2025-04-19 16:51:27,310 [INFO] - Epoch 1 Results - Time: 129.41s, LR: 0.000999\n",
      "2025-04-19 16:51:27,310 [INFO] - Train - Loss: 0.4185, Acc: 85.87%\n",
      "2025-04-19 16:51:27,310 [INFO] - Val - Loss: 0.2695, Acc: 90.40%, F1: 0.9022, ECE: 0.0279\n",
      "2025-04-19 16:51:27,570 [INFO] - New best model saved (val_loss: 0.2695)\n",
      "2025-04-19 16:51:27,698 [INFO] - New best accuracy model saved (val_acc: 90.40%)\n",
      "2025-04-19 16:51:27,701 [INFO] - GPU Memory: Current=83.84MB, Peak=2894.07MB, Reserved=698.00MB\n",
      "2025-04-19 16:51:27,701 [INFO] - Epoch 2/55 (Warmup Phase)\n",
      "2025-04-19 16:51:27,914 [INFO] - GPU cache cleared: 83.84MB → 83.84MB (freed 0.00MB)\n",
      "Training (Warmup Phase): 100%|██████████| 704/704 [01:23<00:00,  8.41it/s, loss=0.247, acc=91.7]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 27.30it/s]\n",
      "2025-04-19 16:52:54,548 [INFO] - Epoch 2 Results - Time: 86.85s, LR: 0.000997\n",
      "2025-04-19 16:52:54,548 [INFO] - Train - Loss: 0.2465, Acc: 91.68%\n",
      "2025-04-19 16:52:54,549 [INFO] - Val - Loss: 0.1985, Acc: 93.12%, F1: 0.9309, ECE: 0.0055\n",
      "2025-04-19 16:52:54,823 [INFO] - New best model saved (val_loss: 0.1985)\n",
      "2025-04-19 16:52:54,948 [INFO] - New best accuracy model saved (val_acc: 93.12%)\n",
      "2025-04-19 16:52:54,948 [INFO] - GPU Memory: Current=84.09MB, Peak=2894.07MB, Reserved=3292.00MB\n",
      "2025-04-19 16:52:54,954 [INFO] - Epoch 3/55 (Warmup Phase)\n",
      "2025-04-19 16:52:55,121 [INFO] - GPU cache cleared: 84.09MB → 84.09MB (freed 0.00MB)\n",
      "Training (Warmup Phase): 100%|██████████| 704/704 [01:26<00:00,  8.16it/s, loss=0.197, acc=93.4]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 26.28it/s]\n",
      "2025-04-19 16:54:24,467 [INFO] - Epoch 3 Results - Time: 89.51s, LR: 0.000993\n",
      "2025-04-19 16:54:24,468 [INFO] - Train - Loss: 0.1969, Acc: 93.40%\n",
      "2025-04-19 16:54:24,468 [INFO] - Val - Loss: 0.2059, Acc: 93.62%, F1: 0.9362, ECE: 0.0151\n",
      "2025-04-19 16:54:24,740 [INFO] - New best accuracy model saved (val_acc: 93.62%)\n",
      "2025-04-19 16:54:24,741 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3280.00MB\n",
      "2025-04-19 16:54:24,741 [INFO] - Epoch 4/55 (Warmup Phase)\n",
      "2025-04-19 16:54:24,908 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Warmup Phase): 100%|██████████| 704/704 [01:26<00:00,  8.10it/s, loss=0.162, acc=94.5]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.60it/s]\n",
      "2025-04-19 16:55:54,890 [INFO] - Epoch 4 Results - Time: 90.15s, LR: 0.000987\n",
      "2025-04-19 16:55:54,891 [INFO] - Train - Loss: 0.1620, Acc: 94.45%\n",
      "2025-04-19 16:55:54,891 [INFO] - Val - Loss: 0.1712, Acc: 94.42%, F1: 0.9438, ECE: 0.0154\n",
      "2025-04-19 16:55:55,168 [INFO] - New best model saved (val_loss: 0.1712)\n",
      "2025-04-19 16:55:55,290 [INFO] - New best accuracy model saved (val_acc: 94.42%)\n",
      "2025-04-19 16:55:55,291 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 16:55:55,293 [INFO] - Epoch 5/55 (Warmup Phase)\n",
      "2025-04-19 16:55:55,460 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Warmup Phase): 100%|██████████| 704/704 [01:27<00:00,  8.06it/s, loss=0.148, acc=94.9]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.46it/s]\n",
      "2025-04-19 16:57:25,808 [INFO] - Epoch 5 Results - Time: 90.52s, LR: 0.000980\n",
      "2025-04-19 16:57:25,809 [INFO] - Train - Loss: 0.1485, Acc: 94.95%\n",
      "2025-04-19 16:57:25,810 [INFO] - Val - Loss: 0.2063, Acc: 93.28%, F1: 0.9326, ECE: 0.0225\n",
      "2025-04-19 16:57:26,085 [INFO] - Warmup phase completed, model saved to C:\\Users\\Gading\\Downloads\\Research\\Models\\Baseline\\checkpoints\\baseline_student_20250419_164917_warmup.pth\n",
      "2025-04-19 16:57:26,086 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 16:57:26,087 [INFO] - Epoch 6/55 (Main Phase)\n",
      "2025-04-19 16:57:26,266 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:28<00:00,  8.00it/s, loss=0.125, acc=95.7]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 26.14it/s]\n",
      "2025-04-19 16:58:57,333 [INFO] - Epoch 6 Results - Time: 91.25s, LR: 0.000971\n",
      "2025-04-19 16:58:57,334 [INFO] - Train - Loss: 0.1248, Acc: 95.68%\n",
      "2025-04-19 16:58:57,335 [INFO] - Val - Loss: 0.1958, Acc: 94.22%, F1: 0.9420, ECE: 0.0214\n",
      "2025-04-19 16:58:57,490 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 16:58:57,491 [INFO] - Epoch 7/55 (Main Phase)\n",
      "2025-04-19 16:58:57,661 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:28<00:00,  8.00it/s, loss=0.117, acc=96]  \n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.52it/s]\n",
      "2025-04-19 17:00:28,704 [INFO] - Epoch 7 Results - Time: 91.21s, LR: 0.000961\n",
      "2025-04-19 17:00:28,705 [INFO] - Train - Loss: 0.1173, Acc: 95.99%\n",
      "2025-04-19 17:00:28,706 [INFO] - Val - Loss: 0.1676, Acc: 94.52%, F1: 0.9447, ECE: 0.0139\n",
      "2025-04-19 17:00:28,979 [INFO] - New best model saved (val_loss: 0.1676)\n",
      "2025-04-19 17:00:29,097 [INFO] - New best accuracy model saved (val_acc: 94.52%)\n",
      "2025-04-19 17:00:29,099 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:00:29,099 [INFO] - Epoch 8/55 (Main Phase)\n",
      "2025-04-19 17:00:29,264 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:28<00:00,  7.97it/s, loss=0.102, acc=96.5] \n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.75it/s]\n",
      "2025-04-19 17:02:00,584 [INFO] - Epoch 8 Results - Time: 91.48s, LR: 0.000949\n",
      "2025-04-19 17:02:00,585 [INFO] - Train - Loss: 0.1017, Acc: 96.45%\n",
      "2025-04-19 17:02:00,586 [INFO] - Val - Loss: 0.1924, Acc: 94.24%, F1: 0.9418, ECE: 0.0222\n",
      "2025-04-19 17:02:00,728 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:02:00,728 [INFO] - Epoch 9/55 (Main Phase)\n",
      "2025-04-19 17:02:00,903 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:28<00:00,  7.97it/s, loss=0.0982, acc=96.7]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.33it/s]\n",
      "2025-04-19 17:03:32,320 [INFO] - Epoch 9 Results - Time: 91.59s, LR: 0.000935\n",
      "2025-04-19 17:03:32,321 [INFO] - Train - Loss: 0.0982, Acc: 96.72%\n",
      "2025-04-19 17:03:32,322 [INFO] - Val - Loss: 0.1761, Acc: 94.78%, F1: 0.9476, ECE: 0.0173\n",
      "2025-04-19 17:03:32,585 [INFO] - New best accuracy model saved (val_acc: 94.78%)\n",
      "2025-04-19 17:03:32,587 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:03:32,587 [INFO] - Epoch 10/55 (Main Phase)\n",
      "2025-04-19 17:03:32,748 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:28<00:00,  7.95it/s, loss=0.0833, acc=97.2]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.50it/s]\n",
      "2025-04-19 17:05:04,287 [INFO] - Epoch 10 Results - Time: 91.70s, LR: 0.000921\n",
      "2025-04-19 17:05:04,288 [INFO] - Train - Loss: 0.0833, Acc: 97.19%\n",
      "2025-04-19 17:05:04,289 [INFO] - Val - Loss: 0.1631, Acc: 94.60%, F1: 0.9458, ECE: 0.0213\n",
      "2025-04-19 17:05:04,568 [INFO] - New best model saved (val_loss: 0.1631)\n",
      "2025-04-19 17:05:04,569 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:05:04,570 [INFO] - Epoch 11/55 (Main Phase)\n",
      "2025-04-19 17:05:04,733 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:28<00:00,  7.93it/s, loss=0.0804, acc=97.2]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.34it/s]\n",
      "2025-04-19 17:06:36,518 [INFO] - Epoch 11 Results - Time: 91.95s, LR: 0.000905\n",
      "2025-04-19 17:06:36,519 [INFO] - Train - Loss: 0.0804, Acc: 97.20%\n",
      "2025-04-19 17:06:36,520 [INFO] - Val - Loss: 0.1890, Acc: 94.34%, F1: 0.9431, ECE: 0.0274\n",
      "2025-04-19 17:06:36,666 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:06:36,667 [INFO] - Epoch 12/55 (Main Phase)\n",
      "2025-04-19 17:06:36,840 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:28<00:00,  7.94it/s, loss=0.0728, acc=97.5]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 26.18it/s]\n",
      "2025-04-19 17:08:08,611 [INFO] - Epoch 12 Results - Time: 91.94s, LR: 0.000887\n",
      "2025-04-19 17:08:08,611 [INFO] - Train - Loss: 0.0728, Acc: 97.52%\n",
      "2025-04-19 17:08:08,611 [INFO] - Val - Loss: 0.1752, Acc: 95.12%, F1: 0.9512, ECE: 0.0224\n",
      "2025-04-19 17:08:08,890 [INFO] - New best accuracy model saved (val_acc: 95.12%)\n",
      "2025-04-19 17:08:08,891 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:08:08,891 [INFO] - Epoch 13/55 (Main Phase)\n",
      "2025-04-19 17:08:09,057 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:28<00:00,  7.92it/s, loss=0.0666, acc=97.8]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 25.62it/s]\n",
      "2025-04-19 17:09:41,026 [INFO] - Epoch 13 Results - Time: 92.14s, LR: 0.000868\n",
      "2025-04-19 17:09:41,028 [INFO] - Train - Loss: 0.0666, Acc: 97.77%\n",
      "2025-04-19 17:09:41,029 [INFO] - Val - Loss: 0.1852, Acc: 94.52%, F1: 0.9451, ECE: 0.0222\n",
      "2025-04-19 17:09:41,168 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:09:41,170 [INFO] - Epoch 14/55 (Main Phase)\n",
      "2025-04-19 17:09:41,344 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:29<00:00,  7.90it/s, loss=0.0639, acc=97.8]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 25.79it/s]\n",
      "2025-04-19 17:11:13,532 [INFO] - Epoch 14 Results - Time: 92.36s, LR: 0.000848\n",
      "2025-04-19 17:11:13,532 [INFO] - Train - Loss: 0.0639, Acc: 97.83%\n",
      "2025-04-19 17:11:13,533 [INFO] - Val - Loss: 0.2030, Acc: 94.78%, F1: 0.9475, ECE: 0.0267\n",
      "2025-04-19 17:11:13,672 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:11:13,673 [INFO] - Epoch 15/55 (Main Phase)\n",
      "2025-04-19 17:11:13,846 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:29<00:00,  7.88it/s, loss=0.0564, acc=98.1]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 26.31it/s]\n",
      "2025-04-19 17:12:46,283 [INFO] - Epoch 15 Results - Time: 92.61s, LR: 0.000827\n",
      "2025-04-19 17:12:46,284 [INFO] - Train - Loss: 0.0564, Acc: 98.07%\n",
      "2025-04-19 17:12:46,285 [INFO] - Val - Loss: 0.1707, Acc: 95.22%, F1: 0.9520, ECE: 0.0212\n",
      "2025-04-19 17:12:46,568 [INFO] - New best accuracy model saved (val_acc: 95.22%)\n",
      "2025-04-19 17:12:46,568 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:12:46,568 [INFO] - Epoch 16/55 (Main Phase)\n",
      "2025-04-19 17:12:46,737 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:29<00:00,  7.90it/s, loss=0.0546, acc=98.3]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 25.99it/s]\n",
      "2025-04-19 17:14:18,866 [INFO] - Epoch 16 Results - Time: 92.30s, LR: 0.000805\n",
      "2025-04-19 17:14:18,866 [INFO] - Train - Loss: 0.0546, Acc: 98.29%\n",
      "2025-04-19 17:14:18,867 [INFO] - Val - Loss: 0.1750, Acc: 95.16%, F1: 0.9513, ECE: 0.0229\n",
      "2025-04-19 17:14:19,009 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:14:19,010 [INFO] - Epoch 17/55 (Main Phase)\n",
      "2025-04-19 17:14:19,186 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:29<00:00,  7.90it/s, loss=0.0504, acc=98.3]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 25.98it/s]\n",
      "2025-04-19 17:15:51,317 [INFO] - Epoch 17 Results - Time: 92.31s, LR: 0.000782\n",
      "2025-04-19 17:15:51,317 [INFO] - Train - Loss: 0.0504, Acc: 98.34%\n",
      "2025-04-19 17:15:51,318 [INFO] - Val - Loss: 0.1822, Acc: 94.86%, F1: 0.9483, ECE: 0.0267\n",
      "2025-04-19 17:15:51,466 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:15:51,467 [INFO] - Epoch 18/55 (Main Phase)\n",
      "2025-04-19 17:15:51,638 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:29<00:00,  7.89it/s, loss=0.0436, acc=98.6]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 26.00it/s]\n",
      "2025-04-19 17:17:23,949 [INFO] - Epoch 18 Results - Time: 92.48s, LR: 0.000758\n",
      "2025-04-19 17:17:23,950 [INFO] - Train - Loss: 0.0436, Acc: 98.56%\n",
      "2025-04-19 17:17:23,951 [INFO] - Val - Loss: 0.1690, Acc: 95.52%, F1: 0.9552, ECE: 0.0220\n",
      "2025-04-19 17:17:24,225 [INFO] - New best accuracy model saved (val_acc: 95.52%)\n",
      "2025-04-19 17:17:24,226 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:17:24,227 [INFO] - Epoch 19/55 (Main Phase)\n",
      "2025-04-19 17:17:24,393 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:29<00:00,  7.90it/s, loss=0.041, acc=98.6] \n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.46it/s]\n",
      "2025-04-19 17:18:56,502 [INFO] - Epoch 19 Results - Time: 92.28s, LR: 0.000733\n",
      "2025-04-19 17:18:56,503 [INFO] - Train - Loss: 0.0410, Acc: 98.60%\n",
      "2025-04-19 17:18:56,503 [INFO] - Val - Loss: 0.2087, Acc: 94.92%, F1: 0.9489, ECE: 0.0271\n",
      "2025-04-19 17:18:56,648 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:18:56,648 [INFO] - Epoch 20/55 (Main Phase)\n",
      "2025-04-19 17:18:56,825 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:29<00:00,  7.88it/s, loss=0.0429, acc=98.6]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 25.99it/s]\n",
      "2025-04-19 17:20:29,292 [INFO] - Epoch 20 Results - Time: 92.64s, LR: 0.000708\n",
      "2025-04-19 17:20:29,293 [INFO] - Train - Loss: 0.0429, Acc: 98.56%\n",
      "2025-04-19 17:20:29,293 [INFO] - Val - Loss: 0.1510, Acc: 95.88%, F1: 0.9586, ECE: 0.0208\n",
      "2025-04-19 17:20:29,571 [INFO] - New best model saved (val_loss: 0.1510)\n",
      "2025-04-19 17:20:29,690 [INFO] - New best accuracy model saved (val_acc: 95.88%)\n",
      "2025-04-19 17:20:29,690 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:20:29,690 [INFO] - Epoch 21/55 (Main Phase)\n",
      "2025-04-19 17:20:29,858 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:29<00:00,  7.90it/s, loss=0.0335, acc=98.8]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 25.82it/s]\n",
      "2025-04-19 17:22:02,029 [INFO] - Epoch 21 Results - Time: 92.34s, LR: 0.000681\n",
      "2025-04-19 17:22:02,035 [INFO] - Train - Loss: 0.0335, Acc: 98.85%\n",
      "2025-04-19 17:22:02,035 [INFO] - Val - Loss: 0.1731, Acc: 95.68%, F1: 0.9567, ECE: 0.0237\n",
      "2025-04-19 17:22:02,185 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:22:02,186 [INFO] - Epoch 22/55 (Main Phase)\n",
      "2025-04-19 17:22:02,359 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:29<00:00,  7.87it/s, loss=0.0301, acc=99]  \n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 25.93it/s]\n",
      "2025-04-19 17:23:34,875 [INFO] - Epoch 22 Results - Time: 92.69s, LR: 0.000655\n",
      "2025-04-19 17:23:34,876 [INFO] - Train - Loss: 0.0301, Acc: 98.96%\n",
      "2025-04-19 17:23:34,876 [INFO] - Val - Loss: 0.1736, Acc: 95.74%, F1: 0.9572, ECE: 0.0221\n",
      "2025-04-19 17:23:35,014 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:23:35,015 [INFO] - Epoch 23/55 (Main Phase)\n",
      "2025-04-19 17:23:35,194 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:29<00:00,  7.90it/s, loss=0.0278, acc=99.1]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 25.95it/s]\n",
      "2025-04-19 17:25:07,399 [INFO] - Epoch 23 Results - Time: 92.38s, LR: 0.000627\n",
      "2025-04-19 17:25:07,399 [INFO] - Train - Loss: 0.0278, Acc: 99.05%\n",
      "2025-04-19 17:25:07,400 [INFO] - Val - Loss: 0.1741, Acc: 95.50%, F1: 0.9547, ECE: 0.0261\n",
      "2025-04-19 17:25:07,542 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:25:07,543 [INFO] - Epoch 24/55 (Main Phase)\n",
      "2025-04-19 17:25:07,715 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:29<00:00,  7.90it/s, loss=0.0237, acc=99.2]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 26.03it/s]\n",
      "2025-04-19 17:26:39,955 [INFO] - Epoch 24 Results - Time: 92.41s, LR: 0.000599\n",
      "2025-04-19 17:26:39,955 [INFO] - Train - Loss: 0.0237, Acc: 99.21%\n",
      "2025-04-19 17:26:39,957 [INFO] - Val - Loss: 0.1772, Acc: 95.20%, F1: 0.9517, ECE: 0.0246\n",
      "2025-04-19 17:26:40,103 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:26:40,104 [INFO] - Epoch 25/55 (Main Phase)\n",
      "2025-04-19 17:26:40,269 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:29<00:00,  7.88it/s, loss=0.0274, acc=99.1]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 25.77it/s]\n",
      "2025-04-19 17:28:12,711 [INFO] - Epoch 25 Results - Time: 92.61s, LR: 0.000571\n",
      "2025-04-19 17:28:12,713 [INFO] - Train - Loss: 0.0274, Acc: 99.07%\n",
      "2025-04-19 17:28:12,714 [INFO] - Val - Loss: 0.1508, Acc: 96.16%, F1: 0.9613, ECE: 0.0209\n",
      "2025-04-19 17:28:12,991 [INFO] - New best model saved (val_loss: 0.1508)\n",
      "2025-04-19 17:28:13,109 [INFO] - New best accuracy model saved (val_acc: 96.16%)\n",
      "2025-04-19 17:28:13,117 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:28:13,117 [INFO] - Epoch 26/55 (Main Phase)\n",
      "2025-04-19 17:28:13,282 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:29<00:00,  7.89it/s, loss=0.021, acc=99.3] \n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 25.91it/s]\n",
      "2025-04-19 17:29:45,562 [INFO] - Epoch 26 Results - Time: 92.45s, LR: 0.000543\n",
      "2025-04-19 17:29:45,563 [INFO] - Train - Loss: 0.0210, Acc: 99.34%\n",
      "2025-04-19 17:29:45,564 [INFO] - Val - Loss: 0.1611, Acc: 96.06%, F1: 0.9604, ECE: 0.0205\n",
      "2025-04-19 17:29:45,704 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:29:45,705 [INFO] - Epoch 27/55 (Main Phase)\n",
      "2025-04-19 17:29:45,879 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:29<00:00,  7.88it/s, loss=0.0216, acc=99.3]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 25.83it/s]\n",
      "2025-04-19 17:31:18,276 [INFO] - Epoch 27 Results - Time: 92.57s, LR: 0.000514\n",
      "2025-04-19 17:31:18,277 [INFO] - Train - Loss: 0.0216, Acc: 99.31%\n",
      "2025-04-19 17:31:18,278 [INFO] - Val - Loss: 0.1655, Acc: 96.26%, F1: 0.9624, ECE: 0.0202\n",
      "2025-04-19 17:31:18,563 [INFO] - New best accuracy model saved (val_acc: 96.26%)\n",
      "2025-04-19 17:31:18,565 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:31:18,565 [INFO] - Epoch 28/55 (Main Phase)\n",
      "2025-04-19 17:31:18,725 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:29<00:00,  7.89it/s, loss=0.0166, acc=99.5]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 25.86it/s]\n",
      "2025-04-19 17:32:51,018 [INFO] - Epoch 28 Results - Time: 92.45s, LR: 0.000486\n",
      "2025-04-19 17:32:51,019 [INFO] - Train - Loss: 0.0166, Acc: 99.47%\n",
      "2025-04-19 17:32:51,019 [INFO] - Val - Loss: 0.1893, Acc: 95.82%, F1: 0.9578, ECE: 0.0237\n",
      "2025-04-19 17:32:51,160 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:32:51,161 [INFO] - Epoch 29/55 (Main Phase)\n",
      "2025-04-19 17:32:51,333 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:29<00:00,  7.90it/s, loss=0.0169, acc=99.4]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 26.14it/s]\n",
      "2025-04-19 17:34:23,545 [INFO] - Epoch 29 Results - Time: 92.38s, LR: 0.000457\n",
      "2025-04-19 17:34:23,546 [INFO] - Train - Loss: 0.0169, Acc: 99.43%\n",
      "2025-04-19 17:34:23,547 [INFO] - Val - Loss: 0.1773, Acc: 96.10%, F1: 0.9607, ECE: 0.0213\n",
      "2025-04-19 17:34:23,688 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:34:23,688 [INFO] - Epoch 30/55 (Main Phase)\n",
      "2025-04-19 17:34:23,861 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:29<00:00,  7.90it/s, loss=0.0154, acc=99.5]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 26.04it/s]\n",
      "2025-04-19 17:35:56,086 [INFO] - Epoch 30 Results - Time: 92.40s, LR: 0.000429\n",
      "2025-04-19 17:35:56,087 [INFO] - Train - Loss: 0.0154, Acc: 99.45%\n",
      "2025-04-19 17:35:56,087 [INFO] - Val - Loss: 0.1759, Acc: 96.04%, F1: 0.9602, ECE: 0.0217\n",
      "2025-04-19 17:35:56,230 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:35:56,236 [INFO] - Epoch 31/55 (Main Phase)\n",
      "2025-04-19 17:35:56,408 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:29<00:00,  7.88it/s, loss=0.0126, acc=99.6]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 25.52it/s]\n",
      "2025-04-19 17:37:28,928 [INFO] - Epoch 31 Results - Time: 92.69s, LR: 0.000401\n",
      "2025-04-19 17:37:28,929 [INFO] - Train - Loss: 0.0126, Acc: 99.57%\n",
      "2025-04-19 17:37:28,930 [INFO] - Val - Loss: 0.1862, Acc: 95.84%, F1: 0.9583, ECE: 0.0237\n",
      "2025-04-19 17:37:29,069 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:37:29,069 [INFO] - Epoch 32/55 (Main Phase)\n",
      "2025-04-19 17:37:29,245 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:29<00:00,  7.87it/s, loss=0.0119, acc=99.6]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 26.09it/s]\n",
      "2025-04-19 17:39:01,810 [INFO] - Epoch 32 Results - Time: 92.74s, LR: 0.000373\n",
      "2025-04-19 17:39:01,811 [INFO] - Train - Loss: 0.0119, Acc: 99.59%\n",
      "2025-04-19 17:39:01,811 [INFO] - Val - Loss: 0.1621, Acc: 96.34%, F1: 0.9631, ECE: 0.0205\n",
      "2025-04-19 17:39:02,096 [INFO] - New best accuracy model saved (val_acc: 96.34%)\n",
      "2025-04-19 17:39:02,097 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:39:02,098 [INFO] - Epoch 33/55 (Main Phase)\n",
      "2025-04-19 17:39:02,262 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:28<00:00,  7.93it/s, loss=0.00905, acc=99.7]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.34it/s]\n",
      "2025-04-19 17:40:34,080 [INFO] - Epoch 33 Results - Time: 91.98s, LR: 0.000345\n",
      "2025-04-19 17:40:34,081 [INFO] - Train - Loss: 0.0091, Acc: 99.68%\n",
      "2025-04-19 17:40:34,082 [INFO] - Val - Loss: 0.1658, Acc: 96.42%, F1: 0.9640, ECE: 0.0215\n",
      "2025-04-19 17:40:34,358 [INFO] - New best accuracy model saved (val_acc: 96.42%)\n",
      "2025-04-19 17:40:34,368 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:40:34,368 [INFO] - Epoch 34/55 (Main Phase)\n",
      "2025-04-19 17:40:34,538 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:28<00:00,  7.98it/s, loss=0.00932, acc=99.7]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.37it/s]\n",
      "2025-04-19 17:42:05,813 [INFO] - Epoch 34 Results - Time: 91.44s, LR: 0.000319\n",
      "2025-04-19 17:42:05,814 [INFO] - Train - Loss: 0.0093, Acc: 99.72%\n",
      "2025-04-19 17:42:05,815 [INFO] - Val - Loss: 0.1705, Acc: 96.44%, F1: 0.9641, ECE: 0.0212\n",
      "2025-04-19 17:42:06,086 [INFO] - New best accuracy model saved (val_acc: 96.44%)\n",
      "2025-04-19 17:42:06,086 [INFO] - GPU Memory: Current=84.10MB, Peak=2894.07MB, Reserved=3296.00MB\n",
      "2025-04-19 17:42:06,086 [INFO] - Epoch 35/55 (Main Phase)\n",
      "2025-04-19 17:42:06,257 [INFO] - GPU cache cleared: 84.10MB → 84.10MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:28<00:00,  7.95it/s, loss=0.00772, acc=99.8]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.61it/s]\n",
      "2025-04-19 17:43:37,767 [INFO] - Epoch 35 Results - Time: 91.68s, LR: 0.000292\n",
      "2025-04-19 17:43:37,768 [INFO] - Train - Loss: 0.0077, Acc: 99.75%\n",
      "2025-04-19 17:43:37,769 [INFO] - Val - Loss: 0.1850, Acc: 96.22%, F1: 0.9621, ECE: 0.0232\n",
      "2025-04-19 17:43:37,905 [INFO] - Early stopping triggered after 35 epochs (no improvement for 10 epochs)\n",
      "2025-04-19 17:43:37,905 [INFO] - Training completed. Best validation accuracy: 96.44%\n",
      "2025-04-19 17:43:37,905 [INFO] - Training history saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline\\baseline_student_20250419_164917_history.json\n",
      "2025-04-19 17:43:37,905 [INFO] - Plotting training history...\n",
      "2025-04-19 17:43:39,850 [INFO] - Training history plot saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline\\plots\\training_history_with_warmup.png\n",
      "2025-04-19 17:43:40,558 [INFO] - Testing student model...\n",
      "2025-04-19 17:43:40,558 [INFO] - Testing student model on test set...\n",
      "Validating: 100%|██████████| 157/157 [00:21<00:00,  7.18it/s]\n",
      "2025-04-19 17:44:02,485 [INFO] - Test Results:\n",
      "2025-04-19 17:44:02,486 [INFO] - Loss: 0.2009\n",
      "2025-04-19 17:44:02,487 [INFO] - Accuracy: 96.06%\n",
      "2025-04-19 17:44:02,488 [INFO] - F1 Score: 0.9607\n",
      "2025-04-19 17:44:02,488 [INFO] - Precision: 0.9610\n",
      "2025-04-19 17:44:02,489 [INFO] - Recall: 0.9606\n",
      "2025-04-19 17:44:02,491 [INFO] - ECE: 0.0235\n",
      "2025-04-19 17:44:02,491 [INFO] - Per-class accuracy:\n",
      "2025-04-19 17:44:02,492 [INFO] -   airplane: 96.80%\n",
      "2025-04-19 17:44:02,493 [INFO] -   automobile: 97.10%\n",
      "2025-04-19 17:44:02,493 [INFO] -   bird: 94.90%\n",
      "2025-04-19 17:44:02,494 [INFO] -   cat: 93.50%\n",
      "2025-04-19 17:44:02,494 [INFO] -   deer: 97.20%\n",
      "2025-04-19 17:44:02,496 [INFO] -   dog: 92.40%\n",
      "2025-04-19 17:44:02,496 [INFO] -   frog: 96.90%\n",
      "2025-04-19 17:44:02,497 [INFO] -   horse: 97.30%\n",
      "2025-04-19 17:44:02,497 [INFO] -   ship: 97.30%\n",
      "2025-04-19 17:44:02,498 [INFO] -   truck: 97.20%\n",
      "Generating classification report: 100%|██████████| 157/157 [00:05<00:00, 28.69it/s]\n",
      "2025-04-19 17:44:07,988 [INFO] - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.95      0.97      0.96      1000\n",
      "  automobile       0.98      0.97      0.97      1000\n",
      "        bird       0.98      0.95      0.96      1000\n",
      "         cat       0.89      0.94      0.91      1000\n",
      "        deer       0.97      0.97      0.97      1000\n",
      "         dog       0.95      0.92      0.94      1000\n",
      "        frog       0.98      0.97      0.98      1000\n",
      "       horse       0.98      0.97      0.98      1000\n",
      "        ship       0.97      0.97      0.97      1000\n",
      "       truck       0.96      0.97      0.96      1000\n",
      "\n",
      "    accuracy                           0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "2025-04-19 17:44:07,990 [INFO] - Test metrics saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline\\test_metrics.json\n",
      "2025-04-19 17:44:07,991 [INFO] - Plotting calibration curve...\n",
      "Computing calibration data: 100%|██████████| 157/157 [00:05<00:00, 28.00it/s]\n",
      "2025-04-19 17:44:14,071 [INFO] - Calibration curve saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline\\plots\\calibration_curve.png\n",
      "2025-04-19 17:44:14,071 [INFO] - Final ECE: 0.1628\n",
      "2025-04-19 17:44:14,071 [INFO] - Exporting final model...\n",
      "2025-04-19 17:44:14,123 [INFO] - Final model exported to C:\\Users\\Gading\\Downloads\\Research\\Models\\Baseline\\exports\\mutual_learning\\20250419_174414\\baseline_student_mutual_learning.pth\n",
      "2025-04-19 17:44:14,125 [INFO] - Baseline metrics for mutual_learning saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline\\baselines\\mutual_learning\\metrics.json\n",
      "2025-04-19 17:44:14,126 [INFO] - GPU Memory: Current=47.83MB, Peak=2894.07MB, Reserved=654.00MB\n",
      "2025-04-19 17:44:14,127 [INFO] - Baseline student training for MUTUAL LEARNING completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import traceback\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "# Define base paths\n",
    "BASE_PATH = \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\"\n",
    "DATASET_PATH = os.path.join(BASE_PATH, \"Dataset\")\n",
    "RESULTS_PATH = os.path.join(BASE_PATH, \"Results\")\n",
    "MODELS_PATH = os.path.join(BASE_PATH, \"Models\")\n",
    "SCRIPTS_PATH = os.path.join(BASE_PATH, \"Scripts\")\n",
    "\n",
    "# Create model-specific paths\n",
    "MODEL_NAME = \"Baseline\"\n",
    "MODEL_RESULTS_PATH = os.path.join(RESULTS_PATH, MODEL_NAME)\n",
    "MODEL_CHECKPOINT_PATH = os.path.join(MODELS_PATH, MODEL_NAME, \"checkpoints\")\n",
    "MODEL_EXPORT_PATH = os.path.join(MODELS_PATH, MODEL_NAME, \"exports\")\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(DATASET_PATH, exist_ok=True)\n",
    "os.makedirs(MODEL_RESULTS_PATH, exist_ok=True)\n",
    "os.makedirs(MODEL_CHECKPOINT_PATH, exist_ok=True)\n",
    "os.makedirs(MODEL_EXPORT_PATH, exist_ok=True)\n",
    "os.makedirs(SCRIPTS_PATH, exist_ok=True)\n",
    "os.makedirs(os.path.join(MODEL_RESULTS_PATH, \"logs\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(MODEL_RESULTS_PATH, \"plots\"), exist_ok=True)\n",
    "\n",
    "# Setup logging\n",
    "log_file = os.path.join(MODEL_RESULTS_PATH, \"logs\", \"baseline_student.log\")\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s [%(levelname)s] - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Set up tensorboard writer\n",
    "writer = SummaryWriter(log_dir=os.path.join(MODEL_RESULTS_PATH, \"logs\"))\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    logger.info(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    logger.info(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    logger.info(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    # Enable cuDNN benchmark for optimal performance\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    logger.info(\"cuDNN benchmark mode enabled\")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False  # Slightly faster with False\n",
    "    logger.info(f\"Random seed set to {seed}\")\n",
    "\n",
    "# Hyperparameters and configuration\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # General settings\n",
    "        self.seed = 42\n",
    "        self.model_name = \"baseline_student\"\n",
    "        self.dataset = \"CIFAR-10\"\n",
    "        \n",
    "        # Hardware-specific optimizations - FIXED VALUES for RTX 3060 Laptop (6GB)\n",
    "        self.use_amp = True  # Automatic Mixed Precision\n",
    "        self.prefetch_factor = 2  # DataLoader prefetch factor\n",
    "        self.pin_memory = True  # Pin memory for faster CPU->GPU transfers\n",
    "        self.persistent_workers = True  # Keep workers alive between epochs\n",
    "        \n",
    "        # RTX 3060 Laptop specific fixes\n",
    "        self.batch_size = 64  # As specified in the requirements\n",
    "        self.gradient_accumulation_steps = 1  # No gradient accumulation for baseline\n",
    "        \n",
    "        # Data settings\n",
    "        self.input_size = 32  # Original CIFAR-10 image size\n",
    "        self.model_input_size = 224  # Required size for pretrained models\n",
    "        self.num_workers = 4  # For data loading\n",
    "        self.val_split = 0.1  # 10% validation split\n",
    "        self.dataset_path = DATASET_PATH\n",
    "        \n",
    "        # GPU cache clearing settings\n",
    "        self.clear_cache_every_n_epochs = 1  # Clear cache every epoch\n",
    "        \n",
    "        # Model settings\n",
    "        self.pretrained = True  # Use pretrained models\n",
    "        self.num_classes = 10  # CIFAR-10 has 10 classes\n",
    "                \n",
    "        # Training settings\n",
    "        self.include_warmup_phase = True  # Whether to include the warm-up phase\n",
    "        self.warmup_epochs = 5  # Phase 1: Warm-up epochs (if include_warmup_phase is True)\n",
    "        self.main_epochs = 50  # Phase 2: Main training epochs\n",
    "        self.total_epochs = self.warmup_epochs + self.main_epochs if self.include_warmup_phase else self.main_epochs  # Total training epochs\n",
    "        self.lr = 1e-3  # Learning rate (AdamW)\n",
    "        self.weight_decay = 1e-4  # Weight decay\n",
    "        self.early_stop_patience = 10  # Early stopping patience\n",
    "        \n",
    "        # Output settings\n",
    "        self.checkpoint_dir = MODEL_CHECKPOINT_PATH\n",
    "        self.results_dir = MODEL_RESULTS_PATH\n",
    "        self.export_dir = MODEL_EXPORT_PATH\n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"String representation of the configuration\"\"\"\n",
    "        return json.dumps(self.__dict__, indent=4)\n",
    "    \n",
    "    def save(self, path):\n",
    "        \"\"\"Save configuration to a JSON file\"\"\"\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(self.__dict__, f, indent=4)\n",
    "\n",
    "# Memory utilities\n",
    "def print_gpu_memory_stats():\n",
    "    \"\"\"Print GPU memory usage statistics\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        current_mem = torch.cuda.memory_allocated() / 1024**2\n",
    "        max_mem = torch.cuda.max_memory_allocated() / 1024**2\n",
    "        reserved_mem = torch.cuda.memory_reserved() / 1024**2\n",
    "        logger.info(f\"GPU Memory: Current={current_mem:.2f}MB, Peak={max_mem:.2f}MB, Reserved={reserved_mem:.2f}MB\")\n",
    "\n",
    "def clear_gpu_cache():\n",
    "    \"\"\"Clear GPU cache to free up memory\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        before_mem = torch.cuda.memory_allocated() / 1024**2\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()  # Explicit garbage collection\n",
    "        after_mem = torch.cuda.memory_allocated() / 1024**2\n",
    "        logger.info(f\"GPU cache cleared: {before_mem:.2f}MB → {after_mem:.2f}MB (freed {before_mem-after_mem:.2f}MB)\")\n",
    "\n",
    "# Calibration Metrics\n",
    "class CalibrationMetrics:\n",
    "    @staticmethod\n",
    "    def compute_ece(probs, targets, n_bins=10):\n",
    "        \"\"\"Compute Expected Calibration Error (ECE)\"\"\"\n",
    "        # Get the confidence (max probability) and predictions\n",
    "        confidences, predictions = torch.max(probs, dim=1)\n",
    "        accuracies = (predictions == targets).float()\n",
    "        \n",
    "        # Sort by confidence\n",
    "        sorted_indices = torch.argsort(confidences)\n",
    "        sorted_confidences = confidences[sorted_indices]\n",
    "        sorted_accuracies = accuracies[sorted_indices]\n",
    "        \n",
    "        # Create bins\n",
    "        bin_size = 1.0 / n_bins\n",
    "        bins = torch.linspace(0, 1.0, n_bins+1)\n",
    "        ece = 0.0\n",
    "        \n",
    "        for i in range(n_bins):\n",
    "            # Find samples in this bin\n",
    "            bin_start, bin_end = bins[i], bins[i+1]\n",
    "            in_bin = (sorted_confidences >= bin_start) & (sorted_confidences < bin_end)\n",
    "            bin_count = in_bin.sum().item()\n",
    "            \n",
    "            if bin_count > 0:\n",
    "                bin_confidence = sorted_confidences[in_bin].mean().item()\n",
    "                bin_accuracy = sorted_accuracies[in_bin].mean().item()\n",
    "                # Weight ECE contribution by bin size\n",
    "                ece += bin_count * abs(bin_confidence - bin_accuracy)\n",
    "        \n",
    "        # Normalize by total samples\n",
    "        ece = ece / len(probs)\n",
    "        \n",
    "        # Return as Python float instead of tensor to avoid .item() issues\n",
    "        return float(ece)\n",
    "\n",
    "# Data Preparation\n",
    "def get_cifar10_loaders(config):\n",
    "    \"\"\"Prepare CIFAR-10 dataset and dataloaders\"\"\"\n",
    "    # For pretrained models, we need to use ImageNet normalization\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    # Transform for training with data augmentation - as specified in requirements\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Resize(config.model_input_size, antialias=True),  # Moved Resize before ToTensor/Normalize\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "    \n",
    "    # Transform for validation/test (no augmentation)\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize(config.model_input_size, antialias=True),  # Moved Resize before ToTensor/Normalize\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "    \n",
    "    # Set CIFAR-10 dataset path\n",
    "    cifar10_path = os.path.join(config.dataset_path, \"CIFAR-10\")\n",
    "    \n",
    "    # Load CIFAR-10 dataset\n",
    "    full_train_dataset = datasets.CIFAR10(\n",
    "        root=cifar10_path, train=True, download=True, transform=train_transform\n",
    "    )\n",
    "    test_dataset = datasets.CIFAR10(\n",
    "        root=cifar10_path, train=False, download=True, transform=test_transform\n",
    "    )\n",
    "    \n",
    "    # Split training set into train and validation\n",
    "    val_size = int(len(full_train_dataset) * config.val_split)\n",
    "    train_size = len(full_train_dataset) - val_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        full_train_dataset, [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(config.seed)\n",
    "    )\n",
    "    \n",
    "    # Create a custom dataset for validation to apply the test transform\n",
    "    val_dataset_with_transform = torch.utils.data.Subset(\n",
    "        datasets.CIFAR10(\n",
    "            root=cifar10_path, train=True, download=False, transform=test_transform\n",
    "        ),\n",
    "        val_dataset.indices\n",
    "    )\n",
    "    \n",
    "    # Create data loaders with optimized settings for RTX 3060\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=config.num_workers, \n",
    "        pin_memory=config.pin_memory,\n",
    "        persistent_workers=config.persistent_workers if config.num_workers > 0 else False,\n",
    "        prefetch_factor=config.prefetch_factor if config.num_workers > 0 else None\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset_with_transform, \n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False, \n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=config.pin_memory,\n",
    "        persistent_workers=config.persistent_workers if config.num_workers > 0 else False,\n",
    "        prefetch_factor=config.prefetch_factor if config.num_workers > 0 else None\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False, \n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=config.pin_memory,\n",
    "        persistent_workers=config.persistent_workers if config.num_workers > 0 else False,\n",
    "        prefetch_factor=config.prefetch_factor if config.num_workers > 0 else None\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Training samples: {len(train_dataset)}\")\n",
    "    logger.info(f\"Validation samples: {len(val_dataset)}\")\n",
    "    logger.info(f\"Test samples: {len(test_dataset)}\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# Create student model\n",
    "def create_student_model(config):\n",
    "    \"\"\"Create a student model based on EfficientNetB0\"\"\"\n",
    "    logger.info(f\"Creating EfficientNet-B0 student model with ImageNet pre-trained weights...\")\n",
    "    \n",
    "    # Initialize the model with ImageNet weights\n",
    "    model = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "    \n",
    "    # Modify the classifier for our number of classes\n",
    "    if hasattr(model, 'classifier'):\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, config.num_classes)\n",
    "    \n",
    "    # Log model parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    logger.info(f\"Student model created with {total_params/1e6:.2f}M parameters\")\n",
    "    \n",
    "    return model.to(device)\n",
    "\n",
    "def validate(model, val_loader, criterion, config):\n",
    "    \"\"\"Validate the model and compute metrics\"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(val_loader, desc=\"Validating\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass with mixed precision\n",
    "            with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu', enabled=config.use_amp):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Update statistics\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            # Store for metrics calculation\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_probs.append(F.softmax(outputs, dim=1).cpu())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    all_probs = torch.cat(all_probs, dim=0)\n",
    "    all_targets_tensor = torch.tensor(all_targets)\n",
    "    \n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    f1 = f1_score(all_targets, all_predictions, average='macro')\n",
    "    ece = CalibrationMetrics.compute_ece(all_probs, all_targets_tensor)\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    precision = precision_score(all_targets, all_predictions, average='macro')\n",
    "    recall = recall_score(all_targets, all_predictions, average='macro')\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    per_class_accuracy = []\n",
    "    for class_idx in range(config.num_classes):\n",
    "        class_indices = [i for i, target in enumerate(all_targets) if target == class_idx]\n",
    "        if len(class_indices) > 0:\n",
    "            class_correct = sum(all_predictions[i] == all_targets[i] for i in class_indices)\n",
    "            per_class_accuracy.append(100. * class_correct / len(class_indices))\n",
    "        else:\n",
    "            per_class_accuracy.append(0.0)\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': val_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'ece': ece,\n",
    "        'per_class_accuracy': per_class_accuracy\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def train_student(student, train_loader, val_loader, config):\n",
    "    \"\"\"Train the student model with two-phase training\"\"\"\n",
    "    logger.info(\"Training student model with baseline supervised learning...\")\n",
    "    \n",
    "    # Cross-entropy loss (no distillation, no mutual learning, no calibration)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Optimizer - AdamW as specified\n",
    "    optimizer = optim.AdamW(student.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    \n",
    "    # Scheduler - CosineAnnealingLR over the full training period (warmup + main)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=config.total_epochs)\n",
    "    \n",
    "    # Mixed precision training\n",
    "    scaler = GradScaler() if config.use_amp else None\n",
    "    \n",
    "    # Initialize tracking variables\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_acc = 0.0\n",
    "    early_stop_counter = 0\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [], \n",
    "        'val_loss': [], 'val_acc': [], 'val_ece': [], 'val_f1': [],\n",
    "        'best_epoch': 0,\n",
    "        'per_class_accuracy': [],\n",
    "        'phase': []  # Track which phase we're in (warmup or main)\n",
    "    }\n",
    "    \n",
    "    # Get timestamp for model naming\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_name = f\"{config.model_name}_{timestamp}\"\n",
    "    \n",
    "    # Save configuration\n",
    "    config_path = os.path.join(config.results_dir, f\"{model_name}_config.json\")\n",
    "    config.save(config_path)\n",
    "    logger.info(f\"Configuration saved to {config_path}\")\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(config.total_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        # Determine which phase we're in\n",
    "        phase = \"Warmup\" if config.include_warmup_phase and epoch < config.warmup_epochs else \"Main\"\n",
    "        history['phase'].append(phase)\n",
    "        \n",
    "        logger.info(f\"Epoch {epoch+1}/{config.total_epochs} ({phase} Phase)\")\n",
    "        \n",
    "        # Clear GPU cache\n",
    "        clear_gpu_cache()\n",
    "        \n",
    "        # Set model to training mode\n",
    "        student.train()\n",
    "        \n",
    "        # Training phase\n",
    "        train_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Training ({phase} Phase)\")\n",
    "        for batch_idx, (inputs, labels) in enumerate(pbar):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass with mixed precision\n",
    "            with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu', enabled=config.use_amp):\n",
    "                outputs = student(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass with mixed precision\n",
    "            if config.use_amp:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            # Update statistics\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': train_loss / (batch_idx + 1),\n",
    "                'acc': 100. * correct / total\n",
    "            })\n",
    "        \n",
    "        # Calculate epoch statistics\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_acc = 100. * correct / total\n",
    "        \n",
    "        # Validation phase\n",
    "        student.eval()\n",
    "        val_metrics = validate(student, val_loader, criterion, config)\n",
    "        \n",
    "        val_loss = val_metrics['loss']\n",
    "        val_acc = val_metrics['accuracy']\n",
    "        val_f1 = val_metrics['f1_score']\n",
    "        val_ece = val_metrics['ece']\n",
    "        per_class_acc = val_metrics['per_class_accuracy']\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        \n",
    "        # Calculate epoch time\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        \n",
    "        # Log results\n",
    "        logger.info(f\"Epoch {epoch+1} Results - Time: {epoch_time:.2f}s, LR: {current_lr:.6f}\")\n",
    "        logger.info(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%\")\n",
    "        logger.info(f\"Val - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%, F1: {val_f1:.4f}, ECE: {val_ece:.4f}\")\n",
    "        \n",
    "        # Save to history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        history['val_ece'].append(val_ece)\n",
    "        history['per_class_accuracy'].append(per_class_acc)\n",
    "        \n",
    "        # Log to tensorboard\n",
    "        writer.add_scalar('student/train_loss', train_loss, epoch)\n",
    "        writer.add_scalar('student/train_acc', train_acc, epoch)\n",
    "        writer.add_scalar('student/val_loss', val_loss, epoch)\n",
    "        writer.add_scalar('student/val_acc', val_acc, epoch)\n",
    "        writer.add_scalar('student/val_f1', val_f1, epoch)\n",
    "        writer.add_scalar('student/val_ece', val_ece, epoch)\n",
    "        writer.add_scalar('student/learning_rate', current_lr, epoch)\n",
    "        \n",
    "        # Save checkpoint\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': student.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'val_f1': val_f1,\n",
    "            'val_ece': val_ece,\n",
    "            'history': history,\n",
    "            'config': config.__dict__,\n",
    "        }\n",
    "        \n",
    "        # Save latest checkpoint\n",
    "        latest_path = os.path.join(config.checkpoint_dir, f\"{model_name}_latest.pth\")\n",
    "        torch.save(checkpoint, latest_path)\n",
    "        \n",
    "        # Save best model based on validation loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_path = os.path.join(config.checkpoint_dir, f\"{model_name}_best_loss.pth\")\n",
    "            torch.save(checkpoint, best_path)\n",
    "            logger.info(f\"New best model saved (val_loss: {val_loss:.4f})\")\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "        \n",
    "        # Save best model based on validation accuracy\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_acc_path = os.path.join(config.checkpoint_dir, f\"{model_name}_best_acc.pth\")\n",
    "            torch.save(checkpoint, best_acc_path)\n",
    "            history['best_epoch'] = epoch\n",
    "            logger.info(f\"New best accuracy model saved (val_acc: {val_acc:.2f}%)\")\n",
    "        \n",
    "        # Save model at end of each phase\n",
    "        if (epoch + 1) == config.warmup_epochs or (epoch + 1) == config.total_epochs:\n",
    "            phase_name = \"warmup\" if (epoch + 1) == config.warmup_epochs else \"final\"\n",
    "            phase_path = os.path.join(config.checkpoint_dir, f\"{model_name}_{phase_name}.pth\")\n",
    "            torch.save(checkpoint, phase_path)\n",
    "            logger.info(f\"{phase} phase completed, model saved to {phase_path}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if early_stop_counter >= config.early_stop_patience:\n",
    "            logger.info(f\"Early stopping triggered after {epoch+1} epochs (no improvement for {config.early_stop_patience} epochs)\")\n",
    "            break\n",
    "        \n",
    "        # Print memory stats\n",
    "        print_gpu_memory_stats()\n",
    "    \n",
    "    # End of training\n",
    "    logger.info(f\"Training completed. Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    # Save history\n",
    "    history_path = os.path.join(config.results_dir, f\"{model_name}_history.json\")\n",
    "    with open(history_path, 'w') as f:\n",
    "        json.dump(history, f, indent=4, cls=NumpyEncoder)\n",
    "    logger.info(f\"Training history saved to {history_path}\")\n",
    "    \n",
    "    return student, history\n",
    "\n",
    "# Helper class for JSON serialization of numpy arrays\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        return super(NumpyEncoder, self).default(obj)\n",
    "\n",
    "def plot_training_history(history, config):\n",
    "    \"\"\"Plot training history with multiple metrics\"\"\"\n",
    "    plt.figure(figsize=(15, 20))\n",
    "    \n",
    "    # Set a consistent style for better visualizations\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    \n",
    "    # Create color palette for consistent coloring\n",
    "    main_colors = ['#2077B4', '#FF7F0E', '#2CA02C', '#D62728']\n",
    "    \n",
    "    # Plot training & validation loss\n",
    "    ax1 = plt.subplot(4, 1, 1)\n",
    "    ax1.plot(history['train_loss'], label='Train', color=main_colors[0], linewidth=2)\n",
    "    ax1.plot(history['val_loss'], label='Validation', color=main_colors[1], linewidth=2)\n",
    "    if 'best_epoch' in history:\n",
    "        ax1.axvline(x=history['best_epoch'], color='r', linestyle='--', label='Best Model')\n",
    "    \n",
    "    # Mark the transition from warmup to main phase if warm-up was included\n",
    "    warmup_epochs = sum(1 for phase in history['phase'] if phase == 'Warmup')\n",
    "    if warmup_epochs > 0:\n",
    "        ax1.axvline(x=warmup_epochs-1, color='g', linestyle='--', label='End of Warm-up')\n",
    "    \n",
    "    ax1.set_title('Loss Over Time', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    ax1.legend(fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot training & validation accuracy\n",
    "    ax2 = plt.subplot(4, 1, 2)\n",
    "    ax2.plot(history['train_acc'], label='Train', color=main_colors[0], linewidth=2)\n",
    "    ax2.plot(history['val_acc'], label='Validation', color=main_colors[1], linewidth=2)\n",
    "    if 'best_epoch' in history:\n",
    "        ax2.axvline(x=history['best_epoch'], color='r', linestyle='--', label='Best Model')\n",
    "    if warmup_epochs > 0:\n",
    "        ax2.axvline(x=warmup_epochs-1, color='g', linestyle='--', label='End of Warm-up')\n",
    "    ax2.set_title('Accuracy Over Time', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot ECE and F1 Score\n",
    "    ax3 = plt.subplot(4, 1, 3)\n",
    "    ax3.plot(history['val_ece'], label='ECE', linewidth=2.5, color=main_colors[0])\n",
    "    ax3.plot(history['val_f1'], label='F1 Score', linewidth=2.5, color=main_colors[1])\n",
    "    if 'best_epoch' in history:\n",
    "        ax3.axvline(x=history['best_epoch'], color='r', linestyle='--', label='Best Model')\n",
    "    if warmup_epochs > 0:\n",
    "        ax3.axvline(x=warmup_epochs-1, color='g', linestyle='--', label='End of Warm-up')\n",
    "    ax3.set_title('Calibration and F1 Score', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel('Epoch', fontsize=12)\n",
    "    ax3.set_ylabel('Value', fontsize=12)\n",
    "    ax3.legend(fontsize=10)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot per-class accuracy for latest epoch\n",
    "    if history['per_class_accuracy'] and len(history['per_class_accuracy'][-1]) > 0:\n",
    "        ax4 = plt.subplot(4, 1, 4)\n",
    "        class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "        latest_per_class = history['per_class_accuracy'][-1]\n",
    "        \n",
    "        # Bar plot of per-class accuracy\n",
    "        bars = ax4.bar(range(len(latest_per_class)), latest_per_class, color=main_colors)\n",
    "        \n",
    "        # Add value labels on top of each bar\n",
    "        for i, bar in enumerate(bars):\n",
    "            height = bar.get_height()\n",
    "            ax4.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                    f'{height:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        ax4.set_title('Per-Class Accuracy (Final Epoch)', fontsize=14, fontweight='bold')\n",
    "        ax4.set_xlabel('Class', fontsize=12)\n",
    "        ax4.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "        ax4.set_xticks(range(len(class_names)))\n",
    "        ax4.set_xticklabels(class_names, rotation=45, ha='right')\n",
    "        ax4.grid(True, alpha=0.3, axis='y')\n",
    "        ax4.set_ylim(0, 110)  # Set y-axis limit to make room for labels\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # Update title based on whether warm-up phase was included\n",
    "    title_suffix = \"with Two-Phase Training\" if warmup_epochs > 0 else \"with Single-Phase Training\"\n",
    "    plt.suptitle(f'Baseline Supervised Training of EfficientNet-B0 on CIFAR-10 {title_suffix}', \n",
    "                fontsize=18, fontweight='bold', y=0.98)\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "    \n",
    "    # Add timestamp and config info\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    phase_info = f\"Warm-up: {config.warmup_epochs} epochs, Main: {config.main_epochs} epochs\" if config.include_warmup_phase else f\"Main: {config.main_epochs} epochs (no warm-up)\"\n",
    "    info_text = f\"Generated: {timestamp}\\nLearning Rate: {config.lr}, Weight Decay: {config.weight_decay}, Batch Size: {config.batch_size}\\n{phase_info}\"\n",
    "    plt.figtext(0.01, 0.01, info_text, fontsize=8)\n",
    "    \n",
    "    # Create a filename that indicates the training configuration\n",
    "    filename_prefix = \"training_history_with_warmup\" if config.include_warmup_phase else \"training_history_no_warmup\"\n",
    "    \n",
    "    # Save figure with high quality\n",
    "    plt.savefig(os.path.join(config.results_dir, 'plots', f'{filename_prefix}.png'), dpi=300, bbox_inches='tight')\n",
    "    logger.info(f\"Training history plot saved to {os.path.join(config.results_dir, 'plots', f'{filename_prefix}.png')}\")\n",
    "    \n",
    "    # Save a separate PDF version for publications\n",
    "    plt.savefig(os.path.join(config.results_dir, 'plots', f'{filename_prefix}.pdf'), format='pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_calibration_curve(model, test_loader, config):\n",
    "    \"\"\"Plot calibration reliability diagram\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    confidences = []\n",
    "    accuracies = []\n",
    "    \n",
    "    # Compute confidences and accuracies\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader, desc=\"Computing calibration data\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu', enabled=config.use_amp):\n",
    "                outputs = model(inputs)\n",
    "            \n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            conf, pred = probs.max(1)\n",
    "            acc = (pred == targets).float()\n",
    "            \n",
    "            confidences.append(conf.cpu())\n",
    "            accuracies.append(acc.cpu())\n",
    "    \n",
    "    # Concatenate lists\n",
    "    confidences = torch.cat(confidences)\n",
    "    accuracies = torch.cat(accuracies)\n",
    "    \n",
    "    # Calculate ECE\n",
    "    n_bins = 10  # As specified in requirements\n",
    "    bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    \n",
    "    bin_confidences = []\n",
    "    bin_accuracies = []\n",
    "    bin_sizes = []\n",
    "    \n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        in_bin = (confidences >= bin_lower) & (confidences < bin_upper)\n",
    "        bin_size = in_bin.sum().item()\n",
    "        \n",
    "        if bin_size > 0:\n",
    "            bin_confidence = confidences[in_bin].mean().item()\n",
    "            bin_accuracy = accuracies[in_bin].mean().item()\n",
    "        else:\n",
    "            bin_confidence = (bin_lower + bin_upper) / 2\n",
    "            bin_accuracy = 0\n",
    "            \n",
    "        bin_confidences.append(bin_confidence)\n",
    "        bin_accuracies.append(bin_accuracy)\n",
    "        bin_sizes.append(bin_size)\n",
    "    \n",
    "    bin_sizes = np.array(bin_sizes) / sum(bin_sizes)  # Normalize sizes\n",
    "    \n",
    "    # Calculate ECE\n",
    "    ece = sum(bin_sizes[i] * abs(bin_accuracies[i] - bin_confidences[i]) for i in range(len(bin_sizes)))\n",
    "    \n",
    "    # Plot reliability diagram\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Perfect calibration line\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n",
    "    \n",
    "    # Plot bins\n",
    "    plt.bar(bin_lowers.numpy(), bin_accuracies, width=1/n_bins, align='edge', alpha=0.5, label='Accuracy in bin')\n",
    "    for i, (conf, acc) in enumerate(zip(bin_confidences, bin_accuracies)):\n",
    "        plt.plot([conf, conf], [0, acc], 'r--', alpha=0.3)\n",
    "    \n",
    "    # Add histogram of confidence distribution\n",
    "    twin_ax = plt.twinx()\n",
    "    twin_ax.bar(bin_lowers.numpy(), bin_sizes, width=1/n_bins, align='edge', alpha=0.3, color='g', label='Samples')\n",
    "    twin_ax.set_ylabel('Proportion of Samples')\n",
    "    \n",
    "    plt.title(f'Calibration Reliability Diagram (ECE = {ece:.4f})')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig(os.path.join(config.results_dir, 'plots', 'calibration_curve.png'), dpi=300)\n",
    "    logger.info(f\"Calibration curve saved to {os.path.join(config.results_dir, 'plots', 'calibration_curve.png')}\")\n",
    "    plt.close()\n",
    "    \n",
    "    return ece\n",
    "\n",
    "def test_student_model(student, test_loader, config):\n",
    "    \"\"\"Evaluate the student model on the test set and log detailed metrics\"\"\"\n",
    "    logger.info(\"Testing student model on test set...\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    metrics = validate(student, test_loader, criterion, config)\n",
    "    \n",
    "    logger.info(f\"Test Results:\")\n",
    "    logger.info(f\"Loss: {metrics['loss']:.4f}\")\n",
    "    logger.info(f\"Accuracy: {metrics['accuracy']:.2f}%\")\n",
    "    logger.info(f\"F1 Score: {metrics['f1_score']:.4f}\")\n",
    "    logger.info(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    logger.info(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    logger.info(f\"ECE: {metrics['ece']:.4f}\")\n",
    "    \n",
    "    # Log per-class accuracy\n",
    "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    logger.info(\"Per-class accuracy:\")\n",
    "    for i, acc in enumerate(metrics['per_class_accuracy']):\n",
    "        logger.info(f\"  {class_names[i]}: {acc:.2f}%\")\n",
    "    \n",
    "    # Generate classification report\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    student.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader, desc=\"Generating classification report\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass with mixed precision\n",
    "            with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu', enabled=config.use_amp):\n",
    "                outputs = student(inputs)\n",
    "            \n",
    "            _, predicted = outputs.max(1)\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    # Create classification report\n",
    "    report = classification_report(all_targets, all_predictions, target_names=class_names)\n",
    "    logger.info(f\"Classification Report:\\n{report}\")\n",
    "    \n",
    "    # Save detailed classification report\n",
    "    report_path = os.path.join(config.results_dir, 'classification_report.txt')\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    # Save metrics to JSON\n",
    "    metrics_path = os.path.join(config.results_dir, 'test_metrics.json')\n",
    "    save_metrics = {\n",
    "        'model_name': 'baseline_student',\n",
    "        'accuracy': metrics['accuracy'],\n",
    "        'f1_score': metrics['f1_score'],\n",
    "        'precision': metrics['precision'],\n",
    "        'recall': metrics['recall'],\n",
    "        'ece': metrics['ece'],\n",
    "        'per_class_accuracy': metrics['per_class_accuracy']\n",
    "    }\n",
    "    \n",
    "    with open(metrics_path, 'w') as f:\n",
    "        json.dump(save_metrics, f, indent=4, cls=NumpyEncoder)\n",
    "    \n",
    "    logger.info(f\"Test metrics saved to {metrics_path}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    try:\n",
    "        # Initialize configuration\n",
    "        config = Config()\n",
    "        \n",
    "        # Parse command line arguments\n",
    "        import argparse\n",
    "        import sys\n",
    "        \n",
    "        # Detect if running in Jupyter\n",
    "        is_jupyter = 'ipykernel' in sys.modules\n",
    "        \n",
    "        if is_jupyter:\n",
    "            # For Jupyter notebooks, use default config without parsing args\n",
    "            logger.info(\"Running in Jupyter Notebook environment\")\n",
    "            # Allow setting include_warmup through a variable in the notebook\n",
    "            # Access through `include_warmup` if it exists in globals, otherwise use default\n",
    "            config.include_warmup_phase = globals().get('include_warmup', config.include_warmup_phase)\n",
    "            logger.info(f\"Using include_warmup_phase={config.include_warmup_phase}\")\n",
    "        else:\n",
    "            # For command line, parse arguments normally\n",
    "            parser = argparse.ArgumentParser(description='Baseline training for EfficientNet-B0 on CIFAR-10')\n",
    "            parser.add_argument('--no-warmup', dest='include_warmup', action='store_false',\n",
    "                                help='Skip the warm-up phase to create the ensemble-distillation baseline (50 epochs, no warm-up)')\n",
    "            parser.set_defaults(include_warmup=True)\n",
    "            \n",
    "            # Ignore unknown arguments that might be passed by Jupyter\n",
    "            args, unknown = parser.parse_known_args()\n",
    "            if unknown:\n",
    "                logger.warning(f\"Ignoring unknown arguments: {unknown}\")\n",
    "            \n",
    "            # Update config with command line arguments\n",
    "            config.include_warmup_phase = args.include_warmup\n",
    "        \n",
    "        # Set total epochs based on the warmup configuration\n",
    "        config.total_epochs = config.warmup_epochs + config.main_epochs if config.include_warmup_phase else config.main_epochs\n",
    "        \n",
    "        # Log the configuration and training phases\n",
    "        if config.include_warmup_phase:\n",
    "            logger.info(f\"Training with two-phase schedule: {config.warmup_epochs} warm-up epochs + {config.main_epochs} main epochs\")\n",
    "            logger.info(f\"This will establish a baseline for MUTUAL LEARNING comparison\")\n",
    "        else:\n",
    "            logger.info(f\"Training with single-phase schedule: {config.main_epochs} main epochs (no warm-up)\")\n",
    "            logger.info(f\"This will establish a baseline for ENSEMBLE DISTILLATION comparison\")\n",
    "        \n",
    "        logger.info(f\"Total epochs: {config.total_epochs}\")\n",
    "        logger.info(f\"Configuration: {config}\")\n",
    "        \n",
    "        # Set seed for reproducibility\n",
    "        set_seed(config.seed)\n",
    "        \n",
    "        # Initial GPU memory stats\n",
    "        print_gpu_memory_stats()\n",
    "        \n",
    "        # Get data loaders\n",
    "        logger.info(\"Preparing data loaders...\")\n",
    "        train_loader, val_loader, test_loader = get_cifar10_loaders(config)\n",
    "        \n",
    "        # Create student model initialized with ImageNet weights\n",
    "        logger.info(\"Creating student model...\")\n",
    "        student = create_student_model(config)\n",
    "        \n",
    "        # Train student model\n",
    "        logger.info(\"Training student with baseline supervised learning...\")\n",
    "        student, history = train_student(student, train_loader, val_loader, config)\n",
    "        \n",
    "        # Plot training history\n",
    "        logger.info(\"Plotting training history...\")\n",
    "        plot_training_history(history, config)\n",
    "        \n",
    "        # Test student model\n",
    "        logger.info(\"Testing student model...\")\n",
    "        test_metrics = test_student_model(student, test_loader, config)\n",
    "        \n",
    "        # Plot calibration curve for student\n",
    "        logger.info(\"Plotting calibration curve...\")\n",
    "        ece = plot_calibration_curve(student, test_loader, config)\n",
    "        logger.info(f\"Final ECE: {ece:.4f}\")\n",
    "        \n",
    "        # Export final model with appropriate naming based on training configuration\n",
    "        logger.info(\"Exporting final model...\")\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Determine baseline type based on whether warm-up was included\n",
    "        baseline_type = \"mutual_learning\" if config.include_warmup_phase else \"ensemble_distillation\" \n",
    "        \n",
    "        # Create a specific directory for each baseline type with timestamp to avoid mixing runs\n",
    "        baseline_dir = os.path.join(config.export_dir, baseline_type)\n",
    "        os.makedirs(baseline_dir, exist_ok=True)\n",
    "        \n",
    "        # Use timestamp in directory name to keep runs separate\n",
    "        timestamped_dir = os.path.join(baseline_dir, timestamp)\n",
    "        os.makedirs(timestamped_dir, exist_ok=True)\n",
    "        \n",
    "        final_model_path = os.path.join(timestamped_dir, f\"baseline_student_{baseline_type}.pth\")\n",
    "        torch.save({\n",
    "            'model_state_dict': student.state_dict(),\n",
    "            'test_metrics': test_metrics,\n",
    "            'config': config.__dict__,\n",
    "            'ece': ece,\n",
    "            'baseline_type': baseline_type,\n",
    "            'with_warmup': config.include_warmup_phase\n",
    "        }, final_model_path)\n",
    "        logger.info(f\"Final model exported to {final_model_path}\")\n",
    "        \n",
    "        # Save metrics to a specific directory for easy comparison\n",
    "        metrics_dir = os.path.join(config.results_dir, \"baselines\", baseline_type)\n",
    "        os.makedirs(metrics_dir, exist_ok=True)\n",
    "        metrics_path = os.path.join(metrics_dir, \"metrics.json\")\n",
    "        \n",
    "        # Save baseline metrics\n",
    "        save_metrics = {\n",
    "            'model_name': f'baseline_{baseline_type}',\n",
    "            'accuracy': test_metrics['accuracy'],\n",
    "            'f1_score': test_metrics['f1_score'],\n",
    "            'precision': test_metrics['precision'],\n",
    "            'recall': test_metrics['recall'],\n",
    "            'ece': test_metrics['ece'],\n",
    "            'per_class_accuracy': test_metrics['per_class_accuracy'],\n",
    "            'baseline_type': baseline_type,\n",
    "            'with_warmup': config.include_warmup_phase,\n",
    "            'timestamp': timestamp\n",
    "        }\n",
    "        \n",
    "        with open(metrics_path, 'w') as f:\n",
    "            json.dump(save_metrics, f, indent=4, cls=NumpyEncoder)\n",
    "        \n",
    "        logger.info(f\"Baseline metrics for {baseline_type} saved to {metrics_path}\")\n",
    "        \n",
    "        # Final GPU memory stats\n",
    "        print_gpu_memory_stats()\n",
    "        \n",
    "        logger.info(f\"Baseline student training for {baseline_type.upper().replace('_', ' ')} completed successfully.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {str(e)}\")\n",
    "        logger.error(traceback.format_exc())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8714c677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-19 18:07:09,712 [INFO] - Using device: cuda\n",
      "2025-04-19 18:07:09,712 [INFO] - GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "2025-04-19 18:07:09,712 [INFO] - GPU Memory: 6.00 GB\n",
      "2025-04-19 18:07:09,712 [INFO] - CUDA Version: 12.4\n",
      "2025-04-19 18:07:09,712 [INFO] - cuDNN benchmark mode enabled\n",
      "2025-04-19 18:07:09,716 [INFO] - Running in Jupyter Notebook environment\n",
      "2025-04-19 18:07:09,716 [INFO] - Using include_warmup_phase=False\n",
      "2025-04-19 18:07:09,716 [INFO] - Training with single-phase schedule: 50 main epochs (no warm-up)\n",
      "2025-04-19 18:07:09,716 [INFO] - This will establish a baseline for ENSEMBLE DISTILLATION comparison\n",
      "2025-04-19 18:07:09,716 [INFO] - Total epochs: 50\n",
      "2025-04-19 18:07:09,716 [INFO] - Configuration: {\n",
      "    \"seed\": 42,\n",
      "    \"model_name\": \"baseline_student\",\n",
      "    \"dataset\": \"CIFAR-10\",\n",
      "    \"use_amp\": true,\n",
      "    \"prefetch_factor\": 2,\n",
      "    \"pin_memory\": true,\n",
      "    \"persistent_workers\": true,\n",
      "    \"batch_size\": 64,\n",
      "    \"gradient_accumulation_steps\": 1,\n",
      "    \"input_size\": 32,\n",
      "    \"model_input_size\": 224,\n",
      "    \"num_workers\": 4,\n",
      "    \"val_split\": 0.1,\n",
      "    \"dataset_path\": \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Dataset\",\n",
      "    \"clear_cache_every_n_epochs\": 1,\n",
      "    \"pretrained\": true,\n",
      "    \"num_classes\": 10,\n",
      "    \"include_warmup_phase\": false,\n",
      "    \"warmup_epochs\": 5,\n",
      "    \"main_epochs\": 50,\n",
      "    \"total_epochs\": 50,\n",
      "    \"lr\": 0.001,\n",
      "    \"weight_decay\": 0.0001,\n",
      "    \"early_stop_patience\": 10,\n",
      "    \"checkpoint_dir\": \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Models\\\\Baseline\\\\checkpoints\",\n",
      "    \"results_dir\": \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Results\\\\Baseline\",\n",
      "    \"export_dir\": \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Models\\\\Baseline\\\\exports\"\n",
      "}\n",
      "2025-04-19 18:07:09,726 [INFO] - Random seed set to 42\n",
      "2025-04-19 18:07:09,728 [INFO] - GPU Memory: Current=16.25MB, Peak=2894.07MB, Reserved=654.00MB\n",
      "2025-04-19 18:07:09,728 [INFO] - Preparing data loaders...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-19 18:07:11,311 [INFO] - Training samples: 45000\n",
      "2025-04-19 18:07:11,311 [INFO] - Validation samples: 5000\n",
      "2025-04-19 18:07:11,311 [INFO] - Test samples: 10000\n",
      "2025-04-19 18:07:11,311 [INFO] - Creating student model...\n",
      "2025-04-19 18:07:11,311 [INFO] - Creating EfficientNet-B0 student model with ImageNet pre-trained weights...\n",
      "2025-04-19 18:07:11,450 [INFO] - Student model created with 4.02M parameters\n",
      "2025-04-19 18:07:11,529 [INFO] - Training student with baseline supervised learning...\n",
      "2025-04-19 18:07:11,529 [INFO] - Training student model with baseline supervised learning...\n",
      "2025-04-19 18:07:11,534 [INFO] - Configuration saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline\\baseline_student_20250419_180711_config.json\n",
      "2025-04-19 18:07:11,535 [INFO] - Epoch 1/50 (Main Phase)\n",
      "2025-04-19 18:07:11,730 [INFO] - GPU cache cleared: 32.60MB → 32.60MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:39<00:00,  7.08it/s, loss=0.419, acc=85.9]\n",
      "Validating: 100%|██████████| 79/79 [00:20<00:00,  3.91it/s]\n",
      "2025-04-19 18:09:11,407 [INFO] - Epoch 1 Results - Time: 119.87s, LR: 0.000999\n",
      "2025-04-19 18:09:11,407 [INFO] - Train - Loss: 0.4185, Acc: 85.87%\n",
      "2025-04-19 18:09:11,407 [INFO] - Val - Loss: 0.2695, Acc: 90.40%, F1: 0.9022, ECE: 0.0279\n",
      "2025-04-19 18:09:11,656 [INFO] - New best model saved (val_loss: 0.2695)\n",
      "2025-04-19 18:09:11,778 [INFO] - New best accuracy model saved (val_acc: 90.40%)\n",
      "2025-04-19 18:09:11,778 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3288.00MB\n",
      "2025-04-19 18:09:11,778 [INFO] - Epoch 2/50 (Main Phase)\n",
      "2025-04-19 18:09:11,956 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:23<00:00,  8.44it/s, loss=0.245, acc=91.8]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 27.02it/s]\n",
      "2025-04-19 18:10:38,346 [INFO] - Epoch 2 Results - Time: 86.57s, LR: 0.000996\n",
      "2025-04-19 18:10:38,346 [INFO] - Train - Loss: 0.2455, Acc: 91.84%\n",
      "2025-04-19 18:10:38,350 [INFO] - Val - Loss: 0.1986, Acc: 92.96%, F1: 0.9295, ECE: 0.0089\n",
      "2025-04-19 18:10:38,614 [INFO] - New best model saved (val_loss: 0.1986)\n",
      "2025-04-19 18:10:38,735 [INFO] - New best accuracy model saved (val_acc: 92.96%)\n",
      "2025-04-19 18:10:38,736 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:10:38,737 [INFO] - Epoch 3/50 (Main Phase)\n",
      "2025-04-19 18:10:38,928 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:25<00:00,  8.24it/s, loss=0.196, acc=93.3]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.94it/s]\n",
      "2025-04-19 18:12:07,294 [INFO] - Epoch 3 Results - Time: 88.56s, LR: 0.000991\n",
      "2025-04-19 18:12:07,294 [INFO] - Train - Loss: 0.1959, Acc: 93.26%\n",
      "2025-04-19 18:12:07,295 [INFO] - Val - Loss: 0.1874, Acc: 93.62%, F1: 0.9361, ECE: 0.0098\n",
      "2025-04-19 18:12:07,558 [INFO] - New best model saved (val_loss: 0.1874)\n",
      "2025-04-19 18:12:07,676 [INFO] - New best accuracy model saved (val_acc: 93.62%)\n",
      "2025-04-19 18:12:07,676 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:12:07,676 [INFO] - Epoch 4/50 (Main Phase)\n",
      "2025-04-19 18:12:07,853 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:25<00:00,  8.22it/s, loss=0.168, acc=94.3]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 27.11it/s]\n",
      "2025-04-19 18:13:36,414 [INFO] - Epoch 4 Results - Time: 88.74s, LR: 0.000984\n",
      "2025-04-19 18:13:36,415 [INFO] - Train - Loss: 0.1681, Acc: 94.30%\n",
      "2025-04-19 18:13:36,415 [INFO] - Val - Loss: 0.1924, Acc: 93.54%, F1: 0.9349, ECE: 0.0181\n",
      "2025-04-19 18:13:36,555 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:13:36,556 [INFO] - Epoch 5/50 (Main Phase)\n",
      "2025-04-19 18:13:36,737 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:25<00:00,  8.21it/s, loss=0.146, acc=95]  \n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.93it/s]\n",
      "2025-04-19 18:15:05,431 [INFO] - Epoch 5 Results - Time: 88.88s, LR: 0.000976\n",
      "2025-04-19 18:15:05,431 [INFO] - Train - Loss: 0.1464, Acc: 94.97%\n",
      "2025-04-19 18:15:05,432 [INFO] - Val - Loss: 0.2034, Acc: 93.24%, F1: 0.9318, ECE: 0.0230\n",
      "2025-04-19 18:15:05,697 [INFO] - Main phase completed, model saved to C:\\Users\\Gading\\Downloads\\Research\\Models\\Baseline\\checkpoints\\baseline_student_20250419_180711_warmup.pth\n",
      "2025-04-19 18:15:05,698 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:15:05,698 [INFO] - Epoch 6/50 (Main Phase)\n",
      "2025-04-19 18:15:05,875 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:25<00:00,  8.22it/s, loss=0.126, acc=95.7]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 27.34it/s]\n",
      "2025-04-19 18:16:34,470 [INFO] - Epoch 6 Results - Time: 88.77s, LR: 0.000965\n",
      "2025-04-19 18:16:34,471 [INFO] - Train - Loss: 0.1255, Acc: 95.72%\n",
      "2025-04-19 18:16:34,472 [INFO] - Val - Loss: 0.1603, Acc: 94.72%, F1: 0.9469, ECE: 0.0153\n",
      "2025-04-19 18:16:34,755 [INFO] - New best model saved (val_loss: 0.1603)\n",
      "2025-04-19 18:16:34,871 [INFO] - New best accuracy model saved (val_acc: 94.72%)\n",
      "2025-04-19 18:16:34,872 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:16:34,873 [INFO] - Epoch 7/50 (Main Phase)\n",
      "2025-04-19 18:16:35,042 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:25<00:00,  8.20it/s, loss=0.116, acc=96]   \n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.82it/s]\n",
      "2025-04-19 18:18:03,824 [INFO] - Epoch 7 Results - Time: 88.95s, LR: 0.000952\n",
      "2025-04-19 18:18:03,825 [INFO] - Train - Loss: 0.1164, Acc: 95.96%\n",
      "2025-04-19 18:18:03,825 [INFO] - Val - Loss: 0.1617, Acc: 94.66%, F1: 0.9462, ECE: 0.0107\n",
      "2025-04-19 18:18:03,964 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:18:03,964 [INFO] - Epoch 8/50 (Main Phase)\n",
      "2025-04-19 18:18:04,147 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:25<00:00,  8.23it/s, loss=0.105, acc=96.4] \n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.90it/s]\n",
      "2025-04-19 18:19:32,702 [INFO] - Epoch 8 Results - Time: 88.74s, LR: 0.000938\n",
      "2025-04-19 18:19:32,702 [INFO] - Train - Loss: 0.1051, Acc: 96.37%\n",
      "2025-04-19 18:19:32,704 [INFO] - Val - Loss: 0.1708, Acc: 94.66%, F1: 0.9462, ECE: 0.0206\n",
      "2025-04-19 18:19:32,859 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:19:32,859 [INFO] - Epoch 9/50 (Main Phase)\n",
      "2025-04-19 18:19:33,040 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:25<00:00,  8.24it/s, loss=0.0928, acc=96.7]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 27.05it/s]\n",
      "2025-04-19 18:21:01,428 [INFO] - Epoch 9 Results - Time: 88.57s, LR: 0.000922\n",
      "2025-04-19 18:21:01,428 [INFO] - Train - Loss: 0.0928, Acc: 96.74%\n",
      "2025-04-19 18:21:01,429 [INFO] - Val - Loss: 0.1601, Acc: 95.14%, F1: 0.9509, ECE: 0.0139\n",
      "2025-04-19 18:21:01,699 [INFO] - New best model saved (val_loss: 0.1601)\n",
      "2025-04-19 18:21:01,817 [INFO] - New best accuracy model saved (val_acc: 95.14%)\n",
      "2025-04-19 18:21:01,817 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:21:01,817 [INFO] - Epoch 10/50 (Main Phase)\n",
      "2025-04-19 18:21:01,991 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:25<00:00,  8.22it/s, loss=0.0845, acc=97]  \n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 27.27it/s]\n",
      "2025-04-19 18:22:30,554 [INFO] - Epoch 10 Results - Time: 88.74s, LR: 0.000905\n",
      "2025-04-19 18:22:30,555 [INFO] - Train - Loss: 0.0845, Acc: 97.02%\n",
      "2025-04-19 18:22:30,555 [INFO] - Val - Loss: 0.1678, Acc: 94.94%, F1: 0.9492, ECE: 0.0204\n",
      "2025-04-19 18:22:30,699 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:22:30,699 [INFO] - Epoch 11/50 (Main Phase)\n",
      "2025-04-19 18:22:30,879 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:26<00:00,  8.18it/s, loss=0.0799, acc=97.3]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.88it/s]\n",
      "2025-04-19 18:23:59,922 [INFO] - Epoch 11 Results - Time: 89.22s, LR: 0.000885\n",
      "2025-04-19 18:23:59,923 [INFO] - Train - Loss: 0.0799, Acc: 97.28%\n",
      "2025-04-19 18:23:59,923 [INFO] - Val - Loss: 0.1663, Acc: 94.80%, F1: 0.9480, ECE: 0.0229\n",
      "2025-04-19 18:24:00,058 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:24:00,058 [INFO] - Epoch 12/50 (Main Phase)\n",
      "2025-04-19 18:24:00,238 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:26<00:00,  8.14it/s, loss=0.072, acc=97.5] \n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.53it/s]\n",
      "2025-04-19 18:25:29,679 [INFO] - Epoch 12 Results - Time: 89.62s, LR: 0.000864\n",
      "2025-04-19 18:25:29,679 [INFO] - Train - Loss: 0.0720, Acc: 97.49%\n",
      "2025-04-19 18:25:29,679 [INFO] - Val - Loss: 0.1576, Acc: 95.66%, F1: 0.9564, ECE: 0.0166\n",
      "2025-04-19 18:25:29,949 [INFO] - New best model saved (val_loss: 0.1576)\n",
      "2025-04-19 18:25:30,070 [INFO] - New best accuracy model saved (val_acc: 95.66%)\n",
      "2025-04-19 18:25:30,071 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:25:30,072 [INFO] - Epoch 13/50 (Main Phase)\n",
      "2025-04-19 18:25:30,245 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:26<00:00,  8.12it/s, loss=0.0622, acc=97.8]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.70it/s]\n",
      "2025-04-19 18:26:59,948 [INFO] - Epoch 13 Results - Time: 89.88s, LR: 0.000842\n",
      "2025-04-19 18:26:59,949 [INFO] - Train - Loss: 0.0622, Acc: 97.82%\n",
      "2025-04-19 18:26:59,949 [INFO] - Val - Loss: 0.1778, Acc: 95.36%, F1: 0.9534, ECE: 0.0197\n",
      "2025-04-19 18:27:00,099 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:27:00,099 [INFO] - Epoch 14/50 (Main Phase)\n",
      "2025-04-19 18:27:00,279 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:26<00:00,  8.10it/s, loss=0.0608, acc=97.9]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.83it/s]\n",
      "2025-04-19 18:28:30,211 [INFO] - Epoch 14 Results - Time: 90.11s, LR: 0.000819\n",
      "2025-04-19 18:28:30,211 [INFO] - Train - Loss: 0.0608, Acc: 97.90%\n",
      "2025-04-19 18:28:30,211 [INFO] - Val - Loss: 0.1656, Acc: 95.50%, F1: 0.9549, ECE: 0.0194\n",
      "2025-04-19 18:28:30,362 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:28:30,362 [INFO] - Epoch 15/50 (Main Phase)\n",
      "2025-04-19 18:28:30,549 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:27<00:00,  8.08it/s, loss=0.0533, acc=98.1]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.53it/s]\n",
      "2025-04-19 18:30:00,730 [INFO] - Epoch 15 Results - Time: 90.37s, LR: 0.000794\n",
      "2025-04-19 18:30:00,730 [INFO] - Train - Loss: 0.0533, Acc: 98.14%\n",
      "2025-04-19 18:30:00,731 [INFO] - Val - Loss: 0.1888, Acc: 94.78%, F1: 0.9477, ECE: 0.0252\n",
      "2025-04-19 18:30:00,875 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:30:00,875 [INFO] - Epoch 16/50 (Main Phase)\n",
      "2025-04-19 18:30:01,064 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:27<00:00,  8.06it/s, loss=0.045, acc=98.5] \n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.71it/s]\n",
      "2025-04-19 18:31:31,356 [INFO] - Epoch 16 Results - Time: 90.48s, LR: 0.000768\n",
      "2025-04-19 18:31:31,357 [INFO] - Train - Loss: 0.0450, Acc: 98.48%\n",
      "2025-04-19 18:31:31,357 [INFO] - Val - Loss: 0.1849, Acc: 95.36%, F1: 0.9535, ECE: 0.0237\n",
      "2025-04-19 18:31:31,499 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:31:31,506 [INFO] - Epoch 17/50 (Main Phase)\n",
      "2025-04-19 18:31:31,687 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:27<00:00,  8.04it/s, loss=0.047, acc=98.4] \n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 26.27it/s]\n",
      "2025-04-19 18:33:02,330 [INFO] - Epoch 17 Results - Time: 90.82s, LR: 0.000741\n",
      "2025-04-19 18:33:02,330 [INFO] - Train - Loss: 0.0470, Acc: 98.36%\n",
      "2025-04-19 18:33:02,331 [INFO] - Val - Loss: 0.1751, Acc: 95.44%, F1: 0.9542, ECE: 0.0217\n",
      "2025-04-19 18:33:02,487 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:33:02,488 [INFO] - Epoch 18/50 (Main Phase)\n",
      "2025-04-19 18:33:02,679 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:27<00:00,  8.03it/s, loss=0.0425, acc=98.5]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 26.25it/s]\n",
      "2025-04-19 18:34:33,451 [INFO] - Epoch 18 Results - Time: 90.96s, LR: 0.000713\n",
      "2025-04-19 18:34:33,453 [INFO] - Train - Loss: 0.0425, Acc: 98.55%\n",
      "2025-04-19 18:34:33,454 [INFO] - Val - Loss: 0.1733, Acc: 95.48%, F1: 0.9546, ECE: 0.0213\n",
      "2025-04-19 18:34:33,588 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:34:33,595 [INFO] - Epoch 19/50 (Main Phase)\n",
      "2025-04-19 18:34:33,776 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:27<00:00,  8.02it/s, loss=0.0353, acc=98.9]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 26.29it/s]\n",
      "2025-04-19 18:36:04,604 [INFO] - Epoch 19 Results - Time: 91.01s, LR: 0.000684\n",
      "2025-04-19 18:36:04,605 [INFO] - Train - Loss: 0.0353, Acc: 98.86%\n",
      "2025-04-19 18:36:04,605 [INFO] - Val - Loss: 0.1515, Acc: 96.14%, F1: 0.9612, ECE: 0.0176\n",
      "2025-04-19 18:36:04,893 [INFO] - New best model saved (val_loss: 0.1515)\n",
      "2025-04-19 18:36:05,011 [INFO] - New best accuracy model saved (val_acc: 96.14%)\n",
      "2025-04-19 18:36:05,011 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:36:05,011 [INFO] - Epoch 20/50 (Main Phase)\n",
      "2025-04-19 18:36:05,187 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:27<00:00,  8.01it/s, loss=0.035, acc=98.9] \n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.63it/s]\n",
      "2025-04-19 18:37:36,078 [INFO] - Epoch 20 Results - Time: 91.07s, LR: 0.000655\n",
      "2025-04-19 18:37:36,078 [INFO] - Train - Loss: 0.0350, Acc: 98.87%\n",
      "2025-04-19 18:37:36,079 [INFO] - Val - Loss: 0.1510, Acc: 95.86%, F1: 0.9584, ECE: 0.0236\n",
      "2025-04-19 18:37:36,343 [INFO] - New best model saved (val_loss: 0.1510)\n",
      "2025-04-19 18:37:36,345 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:37:36,345 [INFO] - Epoch 21/50 (Main Phase)\n",
      "2025-04-19 18:37:36,518 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:28<00:00,  8.00it/s, loss=0.0297, acc=99]  \n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 26.03it/s]\n",
      "2025-04-19 18:39:07,602 [INFO] - Epoch 21 Results - Time: 91.26s, LR: 0.000624\n",
      "2025-04-19 18:39:07,604 [INFO] - Train - Loss: 0.0297, Acc: 99.05%\n",
      "2025-04-19 18:39:07,604 [INFO] - Val - Loss: 0.1700, Acc: 95.64%, F1: 0.9562, ECE: 0.0235\n",
      "2025-04-19 18:39:07,766 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:39:07,766 [INFO] - Epoch 22/50 (Main Phase)\n",
      "2025-04-19 18:39:07,946 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:28<00:00,  7.98it/s, loss=0.0282, acc=99.1]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.63it/s]\n",
      "2025-04-19 18:40:39,208 [INFO] - Epoch 22 Results - Time: 91.44s, LR: 0.000594\n",
      "2025-04-19 18:40:39,209 [INFO] - Train - Loss: 0.0282, Acc: 99.11%\n",
      "2025-04-19 18:40:39,209 [INFO] - Val - Loss: 0.1553, Acc: 95.70%, F1: 0.9570, ECE: 0.0227\n",
      "2025-04-19 18:40:39,353 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:40:39,353 [INFO] - Epoch 23/50 (Main Phase)\n",
      "2025-04-19 18:40:39,536 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:28<00:00,  7.96it/s, loss=0.0264, acc=99.1]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.40it/s]\n",
      "2025-04-19 18:42:10,957 [INFO] - Epoch 23 Results - Time: 91.60s, LR: 0.000563\n",
      "2025-04-19 18:42:10,958 [INFO] - Train - Loss: 0.0264, Acc: 99.06%\n",
      "2025-04-19 18:42:10,959 [INFO] - Val - Loss: 0.1738, Acc: 95.80%, F1: 0.9578, ECE: 0.0221\n",
      "2025-04-19 18:42:11,107 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:42:11,107 [INFO] - Epoch 24/50 (Main Phase)\n",
      "2025-04-19 18:42:11,290 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:28<00:00,  7.98it/s, loss=0.0247, acc=99.2]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.55it/s]\n",
      "2025-04-19 18:43:42,495 [INFO] - Epoch 24 Results - Time: 91.39s, LR: 0.000531\n",
      "2025-04-19 18:43:42,496 [INFO] - Train - Loss: 0.0247, Acc: 99.19%\n",
      "2025-04-19 18:43:42,496 [INFO] - Val - Loss: 0.1659, Acc: 95.92%, F1: 0.9589, ECE: 0.0217\n",
      "2025-04-19 18:43:42,653 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:43:42,654 [INFO] - Epoch 25/50 (Main Phase)\n",
      "2025-04-19 18:43:42,834 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:28<00:00,  7.97it/s, loss=0.0192, acc=99.4]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.35it/s]\n",
      "2025-04-19 18:45:14,148 [INFO] - Epoch 25 Results - Time: 91.49s, LR: 0.000500\n",
      "2025-04-19 18:45:14,149 [INFO] - Train - Loss: 0.0192, Acc: 99.38%\n",
      "2025-04-19 18:45:14,150 [INFO] - Val - Loss: 0.1517, Acc: 96.24%, F1: 0.9623, ECE: 0.0200\n",
      "2025-04-19 18:45:14,407 [INFO] - New best accuracy model saved (val_acc: 96.24%)\n",
      "2025-04-19 18:45:14,408 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:45:14,409 [INFO] - Epoch 26/50 (Main Phase)\n",
      "2025-04-19 18:45:14,582 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:28<00:00,  7.96it/s, loss=0.014, acc=99.5] \n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 25.76it/s]\n",
      "2025-04-19 18:46:46,116 [INFO] - Epoch 26 Results - Time: 91.71s, LR: 0.000469\n",
      "2025-04-19 18:46:46,116 [INFO] - Train - Loss: 0.0140, Acc: 99.51%\n",
      "2025-04-19 18:46:46,116 [INFO] - Val - Loss: 0.1792, Acc: 95.76%, F1: 0.9573, ECE: 0.0262\n",
      "2025-04-19 18:46:46,262 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:46:46,262 [INFO] - Epoch 27/50 (Main Phase)\n",
      "2025-04-19 18:46:46,447 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:28<00:00,  7.97it/s, loss=0.019, acc=99.4] \n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 26.19it/s]\n",
      "2025-04-19 18:48:17,857 [INFO] - Epoch 27 Results - Time: 91.60s, LR: 0.000437\n",
      "2025-04-19 18:48:17,858 [INFO] - Train - Loss: 0.0190, Acc: 99.38%\n",
      "2025-04-19 18:48:17,858 [INFO] - Val - Loss: 0.1718, Acc: 96.16%, F1: 0.9613, ECE: 0.0204\n",
      "2025-04-19 18:48:18,005 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:48:18,006 [INFO] - Epoch 28/50 (Main Phase)\n",
      "2025-04-19 18:48:18,187 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:28<00:00,  7.95it/s, loss=0.0134, acc=99.6]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.76it/s]\n",
      "2025-04-19 18:49:49,776 [INFO] - Epoch 28 Results - Time: 91.77s, LR: 0.000406\n",
      "2025-04-19 18:49:49,776 [INFO] - Train - Loss: 0.0134, Acc: 99.55%\n",
      "2025-04-19 18:49:49,781 [INFO] - Val - Loss: 0.1799, Acc: 95.94%, F1: 0.9593, ECE: 0.0222\n",
      "2025-04-19 18:49:49,931 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:49:49,932 [INFO] - Epoch 29/50 (Main Phase)\n",
      "2025-04-19 18:49:50,115 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:28<00:00,  7.95it/s, loss=0.0155, acc=99.5]\n",
      "Validating: 100%|██████████| 79/79 [00:03<00:00, 25.95it/s]\n",
      "2025-04-19 18:51:21,759 [INFO] - Epoch 29 Results - Time: 91.83s, LR: 0.000376\n",
      "2025-04-19 18:51:21,759 [INFO] - Train - Loss: 0.0155, Acc: 99.46%\n",
      "2025-04-19 18:51:21,761 [INFO] - Val - Loss: 0.1809, Acc: 96.10%, F1: 0.9607, ECE: 0.0224\n",
      "2025-04-19 18:51:21,904 [INFO] - GPU Memory: Current=84.22MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:51:21,906 [INFO] - Epoch 30/50 (Main Phase)\n",
      "2025-04-19 18:51:22,087 [INFO] - GPU cache cleared: 84.22MB → 84.22MB (freed 0.00MB)\n",
      "Training (Main Phase): 100%|██████████| 704/704 [01:28<00:00,  7.95it/s, loss=0.0107, acc=99.6]\n",
      "Validating: 100%|██████████| 79/79 [00:02<00:00, 26.54it/s]\n",
      "2025-04-19 18:52:53,673 [INFO] - Epoch 30 Results - Time: 91.77s, LR: 0.000345\n",
      "2025-04-19 18:52:53,674 [INFO] - Train - Loss: 0.0107, Acc: 99.65%\n",
      "2025-04-19 18:52:53,675 [INFO] - Val - Loss: 0.1712, Acc: 96.24%, F1: 0.9622, ECE: 0.0224\n",
      "2025-04-19 18:52:53,823 [INFO] - Early stopping triggered after 30 epochs (no improvement for 10 epochs)\n",
      "2025-04-19 18:52:53,824 [INFO] - Training completed. Best validation accuracy: 96.24%\n",
      "2025-04-19 18:52:53,826 [INFO] - Training history saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline\\baseline_student_20250419_180711_history.json\n",
      "2025-04-19 18:52:53,829 [INFO] - Plotting training history...\n",
      "2025-04-19 18:52:55,736 [INFO] - Training history plot saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline\\plots\\training_history_no_warmup.png\n",
      "2025-04-19 18:52:56,206 [INFO] - Testing student model...\n",
      "2025-04-19 18:52:56,207 [INFO] - Testing student model on test set...\n",
      "Validating: 100%|██████████| 157/157 [00:21<00:00,  7.31it/s]\n",
      "2025-04-19 18:53:17,750 [INFO] - Test Results:\n",
      "2025-04-19 18:53:17,752 [INFO] - Loss: 0.1871\n",
      "2025-04-19 18:53:17,752 [INFO] - Accuracy: 96.09%\n",
      "2025-04-19 18:53:17,753 [INFO] - F1 Score: 0.9610\n",
      "2025-04-19 18:53:17,754 [INFO] - Precision: 0.9611\n",
      "2025-04-19 18:53:17,755 [INFO] - Recall: 0.9609\n",
      "2025-04-19 18:53:17,756 [INFO] - ECE: 0.0218\n",
      "2025-04-19 18:53:17,756 [INFO] - Per-class accuracy:\n",
      "2025-04-19 18:53:17,757 [INFO] -   airplane: 97.00%\n",
      "2025-04-19 18:53:17,758 [INFO] -   automobile: 98.20%\n",
      "2025-04-19 18:53:17,758 [INFO] -   bird: 94.90%\n",
      "2025-04-19 18:53:17,758 [INFO] -   cat: 93.70%\n",
      "2025-04-19 18:53:17,760 [INFO] -   deer: 95.60%\n",
      "2025-04-19 18:53:17,761 [INFO] -   dog: 93.00%\n",
      "2025-04-19 18:53:17,761 [INFO] -   frog: 96.80%\n",
      "2025-04-19 18:53:17,762 [INFO] -   horse: 97.40%\n",
      "2025-04-19 18:53:17,762 [INFO] -   ship: 97.90%\n",
      "2025-04-19 18:53:17,762 [INFO] -   truck: 96.40%\n",
      "Generating classification report: 100%|██████████| 157/157 [00:05<00:00, 28.70it/s]\n",
      "2025-04-19 18:53:23,256 [INFO] - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.97      0.97      0.97      1000\n",
      "  automobile       0.97      0.98      0.97      1000\n",
      "        bird       0.96      0.95      0.96      1000\n",
      "         cat       0.90      0.94      0.92      1000\n",
      "        deer       0.97      0.96      0.96      1000\n",
      "         dog       0.93      0.93      0.93      1000\n",
      "        frog       0.98      0.97      0.98      1000\n",
      "       horse       0.98      0.97      0.98      1000\n",
      "        ship       0.97      0.98      0.98      1000\n",
      "       truck       0.97      0.96      0.97      1000\n",
      "\n",
      "    accuracy                           0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "2025-04-19 18:53:23,258 [INFO] - Test metrics saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline\\test_metrics.json\n",
      "2025-04-19 18:53:23,258 [INFO] - Plotting calibration curve...\n",
      "Computing calibration data: 100%|██████████| 157/157 [00:05<00:00, 28.31it/s]\n",
      "2025-04-19 18:53:29,261 [INFO] - Calibration curve saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline\\plots\\calibration_curve.png\n",
      "2025-04-19 18:53:29,263 [INFO] - Final ECE: 0.1435\n",
      "2025-04-19 18:53:29,263 [INFO] - Exporting final model...\n",
      "2025-04-19 18:53:29,307 [INFO] - Final model exported to C:\\Users\\Gading\\Downloads\\Research\\Models\\Baseline\\exports\\ensemble_distillation\\20250419_185329\\baseline_student_ensemble_distillation.pth\n",
      "2025-04-19 18:53:29,307 [INFO] - Baseline metrics for ensemble_distillation saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline\\baselines\\ensemble_distillation\\metrics.json\n",
      "2025-04-19 18:53:29,307 [INFO] - GPU Memory: Current=48.89MB, Peak=2894.07MB, Reserved=3294.00MB\n",
      "2025-04-19 18:53:29,307 [INFO] - Baseline student training for ENSEMBLE DISTILLATION completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import traceback\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "# Define base paths\n",
    "BASE_PATH = \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\"\n",
    "DATASET_PATH = os.path.join(BASE_PATH, \"Dataset\")\n",
    "RESULTS_PATH = os.path.join(BASE_PATH, \"Results\")\n",
    "MODELS_PATH = os.path.join(BASE_PATH, \"Models\")\n",
    "SCRIPTS_PATH = os.path.join(BASE_PATH, \"Scripts\")\n",
    "\n",
    "# Create model-specific paths\n",
    "MODEL_NAME = \"Baseline\"\n",
    "MODEL_RESULTS_PATH = os.path.join(RESULTS_PATH, MODEL_NAME)\n",
    "MODEL_CHECKPOINT_PATH = os.path.join(MODELS_PATH, MODEL_NAME, \"checkpoints\")\n",
    "MODEL_EXPORT_PATH = os.path.join(MODELS_PATH, MODEL_NAME, \"exports\")\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(DATASET_PATH, exist_ok=True)\n",
    "os.makedirs(MODEL_RESULTS_PATH, exist_ok=True)\n",
    "os.makedirs(MODEL_CHECKPOINT_PATH, exist_ok=True)\n",
    "os.makedirs(MODEL_EXPORT_PATH, exist_ok=True)\n",
    "os.makedirs(SCRIPTS_PATH, exist_ok=True)\n",
    "os.makedirs(os.path.join(MODEL_RESULTS_PATH, \"logs\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(MODEL_RESULTS_PATH, \"plots\"), exist_ok=True)\n",
    "\n",
    "# Setup logging\n",
    "log_file = os.path.join(MODEL_RESULTS_PATH, \"logs\", \"baseline_student.log\")\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s [%(levelname)s] - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Set up tensorboard writer\n",
    "writer = SummaryWriter(log_dir=os.path.join(MODEL_RESULTS_PATH, \"logs\"))\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    logger.info(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    logger.info(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    logger.info(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    # Enable cuDNN benchmark for optimal performance\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    logger.info(\"cuDNN benchmark mode enabled\")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False  # Slightly faster with False\n",
    "    logger.info(f\"Random seed set to {seed}\")\n",
    "\n",
    "# Hyperparameters and configuration\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # General settings\n",
    "        self.seed = 42\n",
    "        self.model_name = \"baseline_student\"\n",
    "        self.dataset = \"CIFAR-10\"\n",
    "        \n",
    "        # Hardware-specific optimizations - FIXED VALUES for RTX 3060 Laptop (6GB)\n",
    "        self.use_amp = True  # Automatic Mixed Precision\n",
    "        self.prefetch_factor = 2  # DataLoader prefetch factor\n",
    "        self.pin_memory = True  # Pin memory for faster CPU->GPU transfers\n",
    "        self.persistent_workers = True  # Keep workers alive between epochs\n",
    "        \n",
    "        # RTX 3060 Laptop specific fixes\n",
    "        self.batch_size = 64  # As specified in the requirements\n",
    "        self.gradient_accumulation_steps = 1  # No gradient accumulation for baseline\n",
    "        \n",
    "        # Data settings\n",
    "        self.input_size = 32  # Original CIFAR-10 image size\n",
    "        self.model_input_size = 224  # Required size for pretrained models\n",
    "        self.num_workers = 4  # For data loading\n",
    "        self.val_split = 0.1  # 10% validation split\n",
    "        self.dataset_path = DATASET_PATH\n",
    "        \n",
    "        # GPU cache clearing settings\n",
    "        self.clear_cache_every_n_epochs = 1  # Clear cache every epoch\n",
    "        \n",
    "        # Model settings\n",
    "        self.pretrained = True  # Use pretrained models\n",
    "        self.num_classes = 10  # CIFAR-10 has 10 classes\n",
    "                \n",
    "        # Training settings\n",
    "        self.include_warmup_phase = False  # Whether to include the warm-up phase\n",
    "        self.warmup_epochs = 5  # Phase 1: Warm-up epochs (if include_warmup_phase is True)\n",
    "        self.main_epochs = 50  # Phase 2: Main training epochs\n",
    "        self.total_epochs = self.warmup_epochs + self.main_epochs if self.include_warmup_phase else self.main_epochs  # Total training epochs\n",
    "        self.lr = 1e-3  # Learning rate (AdamW)\n",
    "        self.weight_decay = 1e-4  # Weight decay\n",
    "        self.early_stop_patience = 10  # Early stopping patience\n",
    "        \n",
    "        # Output settings\n",
    "        self.checkpoint_dir = MODEL_CHECKPOINT_PATH\n",
    "        self.results_dir = MODEL_RESULTS_PATH\n",
    "        self.export_dir = MODEL_EXPORT_PATH\n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"String representation of the configuration\"\"\"\n",
    "        return json.dumps(self.__dict__, indent=4)\n",
    "    \n",
    "    def save(self, path):\n",
    "        \"\"\"Save configuration to a JSON file\"\"\"\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(self.__dict__, f, indent=4)\n",
    "\n",
    "# Memory utilities\n",
    "def print_gpu_memory_stats():\n",
    "    \"\"\"Print GPU memory usage statistics\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        current_mem = torch.cuda.memory_allocated() / 1024**2\n",
    "        max_mem = torch.cuda.max_memory_allocated() / 1024**2\n",
    "        reserved_mem = torch.cuda.memory_reserved() / 1024**2\n",
    "        logger.info(f\"GPU Memory: Current={current_mem:.2f}MB, Peak={max_mem:.2f}MB, Reserved={reserved_mem:.2f}MB\")\n",
    "\n",
    "def clear_gpu_cache():\n",
    "    \"\"\"Clear GPU cache to free up memory\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        before_mem = torch.cuda.memory_allocated() / 1024**2\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()  # Explicit garbage collection\n",
    "        after_mem = torch.cuda.memory_allocated() / 1024**2\n",
    "        logger.info(f\"GPU cache cleared: {before_mem:.2f}MB → {after_mem:.2f}MB (freed {before_mem-after_mem:.2f}MB)\")\n",
    "\n",
    "# Calibration Metrics\n",
    "class CalibrationMetrics:\n",
    "    @staticmethod\n",
    "    def compute_ece(probs, targets, n_bins=10):\n",
    "        \"\"\"Compute Expected Calibration Error (ECE)\"\"\"\n",
    "        # Get the confidence (max probability) and predictions\n",
    "        confidences, predictions = torch.max(probs, dim=1)\n",
    "        accuracies = (predictions == targets).float()\n",
    "        \n",
    "        # Sort by confidence\n",
    "        sorted_indices = torch.argsort(confidences)\n",
    "        sorted_confidences = confidences[sorted_indices]\n",
    "        sorted_accuracies = accuracies[sorted_indices]\n",
    "        \n",
    "        # Create bins\n",
    "        bin_size = 1.0 / n_bins\n",
    "        bins = torch.linspace(0, 1.0, n_bins+1)\n",
    "        ece = 0.0\n",
    "        \n",
    "        for i in range(n_bins):\n",
    "            # Find samples in this bin\n",
    "            bin_start, bin_end = bins[i], bins[i+1]\n",
    "            in_bin = (sorted_confidences >= bin_start) & (sorted_confidences < bin_end)\n",
    "            bin_count = in_bin.sum().item()\n",
    "            \n",
    "            if bin_count > 0:\n",
    "                bin_confidence = sorted_confidences[in_bin].mean().item()\n",
    "                bin_accuracy = sorted_accuracies[in_bin].mean().item()\n",
    "                # Weight ECE contribution by bin size\n",
    "                ece += bin_count * abs(bin_confidence - bin_accuracy)\n",
    "        \n",
    "        # Normalize by total samples\n",
    "        ece = ece / len(probs)\n",
    "        \n",
    "        # Return as Python float instead of tensor to avoid .item() issues\n",
    "        return float(ece)\n",
    "\n",
    "# Data Preparation\n",
    "def get_cifar10_loaders(config):\n",
    "    \"\"\"Prepare CIFAR-10 dataset and dataloaders\"\"\"\n",
    "    # For pretrained models, we need to use ImageNet normalization\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    # Transform for training with data augmentation - as specified in requirements\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Resize(config.model_input_size, antialias=True),  # Moved Resize before ToTensor/Normalize\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "    \n",
    "    # Transform for validation/test (no augmentation)\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize(config.model_input_size, antialias=True),  # Moved Resize before ToTensor/Normalize\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "    \n",
    "    # Set CIFAR-10 dataset path\n",
    "    cifar10_path = os.path.join(config.dataset_path, \"CIFAR-10\")\n",
    "    \n",
    "    # Load CIFAR-10 dataset\n",
    "    full_train_dataset = datasets.CIFAR10(\n",
    "        root=cifar10_path, train=True, download=True, transform=train_transform\n",
    "    )\n",
    "    test_dataset = datasets.CIFAR10(\n",
    "        root=cifar10_path, train=False, download=True, transform=test_transform\n",
    "    )\n",
    "    \n",
    "    # Split training set into train and validation\n",
    "    val_size = int(len(full_train_dataset) * config.val_split)\n",
    "    train_size = len(full_train_dataset) - val_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        full_train_dataset, [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(config.seed)\n",
    "    )\n",
    "    \n",
    "    # Create a custom dataset for validation to apply the test transform\n",
    "    val_dataset_with_transform = torch.utils.data.Subset(\n",
    "        datasets.CIFAR10(\n",
    "            root=cifar10_path, train=True, download=False, transform=test_transform\n",
    "        ),\n",
    "        val_dataset.indices\n",
    "    )\n",
    "    \n",
    "    # Create data loaders with optimized settings for RTX 3060\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=config.num_workers, \n",
    "        pin_memory=config.pin_memory,\n",
    "        persistent_workers=config.persistent_workers if config.num_workers > 0 else False,\n",
    "        prefetch_factor=config.prefetch_factor if config.num_workers > 0 else None\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset_with_transform, \n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False, \n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=config.pin_memory,\n",
    "        persistent_workers=config.persistent_workers if config.num_workers > 0 else False,\n",
    "        prefetch_factor=config.prefetch_factor if config.num_workers > 0 else None\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False, \n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=config.pin_memory,\n",
    "        persistent_workers=config.persistent_workers if config.num_workers > 0 else False,\n",
    "        prefetch_factor=config.prefetch_factor if config.num_workers > 0 else None\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Training samples: {len(train_dataset)}\")\n",
    "    logger.info(f\"Validation samples: {len(val_dataset)}\")\n",
    "    logger.info(f\"Test samples: {len(test_dataset)}\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# Create student model\n",
    "def create_student_model(config):\n",
    "    \"\"\"Create a student model based on EfficientNetB0\"\"\"\n",
    "    logger.info(f\"Creating EfficientNet-B0 student model with ImageNet pre-trained weights...\")\n",
    "    \n",
    "    # Initialize the model with ImageNet weights\n",
    "    model = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "    \n",
    "    # Modify the classifier for our number of classes\n",
    "    if hasattr(model, 'classifier'):\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, config.num_classes)\n",
    "    \n",
    "    # Log model parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    logger.info(f\"Student model created with {total_params/1e6:.2f}M parameters\")\n",
    "    \n",
    "    return model.to(device)\n",
    "\n",
    "def validate(model, val_loader, criterion, config):\n",
    "    \"\"\"Validate the model and compute metrics\"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(val_loader, desc=\"Validating\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass with mixed precision\n",
    "            with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu', enabled=config.use_amp):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Update statistics\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            # Store for metrics calculation\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_probs.append(F.softmax(outputs, dim=1).cpu())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    all_probs = torch.cat(all_probs, dim=0)\n",
    "    all_targets_tensor = torch.tensor(all_targets)\n",
    "    \n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    f1 = f1_score(all_targets, all_predictions, average='macro')\n",
    "    ece = CalibrationMetrics.compute_ece(all_probs, all_targets_tensor)\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    precision = precision_score(all_targets, all_predictions, average='macro')\n",
    "    recall = recall_score(all_targets, all_predictions, average='macro')\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    per_class_accuracy = []\n",
    "    for class_idx in range(config.num_classes):\n",
    "        class_indices = [i for i, target in enumerate(all_targets) if target == class_idx]\n",
    "        if len(class_indices) > 0:\n",
    "            class_correct = sum(all_predictions[i] == all_targets[i] for i in class_indices)\n",
    "            per_class_accuracy.append(100. * class_correct / len(class_indices))\n",
    "        else:\n",
    "            per_class_accuracy.append(0.0)\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': val_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'ece': ece,\n",
    "        'per_class_accuracy': per_class_accuracy\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def train_student(student, train_loader, val_loader, config):\n",
    "    \"\"\"Train the student model with two-phase training\"\"\"\n",
    "    logger.info(\"Training student model with baseline supervised learning...\")\n",
    "    \n",
    "    # Cross-entropy loss (no distillation, no mutual learning, no calibration)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Optimizer - AdamW as specified\n",
    "    optimizer = optim.AdamW(student.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    \n",
    "    # Scheduler - CosineAnnealingLR over the full training period (warmup + main)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=config.total_epochs)\n",
    "    \n",
    "    # Mixed precision training\n",
    "    scaler = GradScaler() if config.use_amp else None\n",
    "    \n",
    "    # Initialize tracking variables\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_acc = 0.0\n",
    "    early_stop_counter = 0\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [], \n",
    "        'val_loss': [], 'val_acc': [], 'val_ece': [], 'val_f1': [],\n",
    "        'best_epoch': 0,\n",
    "        'per_class_accuracy': [],\n",
    "        'phase': []  # Track which phase we're in (warmup or main)\n",
    "    }\n",
    "    \n",
    "    # Get timestamp for model naming\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_name = f\"{config.model_name}_{timestamp}\"\n",
    "    \n",
    "    # Save configuration\n",
    "    config_path = os.path.join(config.results_dir, f\"{model_name}_config.json\")\n",
    "    config.save(config_path)\n",
    "    logger.info(f\"Configuration saved to {config_path}\")\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(config.total_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        # Determine which phase we're in\n",
    "        phase = \"Warmup\" if config.include_warmup_phase and epoch < config.warmup_epochs else \"Main\"\n",
    "        history['phase'].append(phase)\n",
    "        \n",
    "        logger.info(f\"Epoch {epoch+1}/{config.total_epochs} ({phase} Phase)\")\n",
    "        \n",
    "        # Clear GPU cache\n",
    "        clear_gpu_cache()\n",
    "        \n",
    "        # Set model to training mode\n",
    "        student.train()\n",
    "        \n",
    "        # Training phase\n",
    "        train_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Training ({phase} Phase)\")\n",
    "        for batch_idx, (inputs, labels) in enumerate(pbar):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass with mixed precision\n",
    "            with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu', enabled=config.use_amp):\n",
    "                outputs = student(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass with mixed precision\n",
    "            if config.use_amp:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            # Update statistics\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': train_loss / (batch_idx + 1),\n",
    "                'acc': 100. * correct / total\n",
    "            })\n",
    "        \n",
    "        # Calculate epoch statistics\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_acc = 100. * correct / total\n",
    "        \n",
    "        # Validation phase\n",
    "        student.eval()\n",
    "        val_metrics = validate(student, val_loader, criterion, config)\n",
    "        \n",
    "        val_loss = val_metrics['loss']\n",
    "        val_acc = val_metrics['accuracy']\n",
    "        val_f1 = val_metrics['f1_score']\n",
    "        val_ece = val_metrics['ece']\n",
    "        per_class_acc = val_metrics['per_class_accuracy']\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        \n",
    "        # Calculate epoch time\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        \n",
    "        # Log results\n",
    "        logger.info(f\"Epoch {epoch+1} Results - Time: {epoch_time:.2f}s, LR: {current_lr:.6f}\")\n",
    "        logger.info(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%\")\n",
    "        logger.info(f\"Val - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%, F1: {val_f1:.4f}, ECE: {val_ece:.4f}\")\n",
    "        \n",
    "        # Save to history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        history['val_ece'].append(val_ece)\n",
    "        history['per_class_accuracy'].append(per_class_acc)\n",
    "        \n",
    "        # Log to tensorboard\n",
    "        writer.add_scalar('student/train_loss', train_loss, epoch)\n",
    "        writer.add_scalar('student/train_acc', train_acc, epoch)\n",
    "        writer.add_scalar('student/val_loss', val_loss, epoch)\n",
    "        writer.add_scalar('student/val_acc', val_acc, epoch)\n",
    "        writer.add_scalar('student/val_f1', val_f1, epoch)\n",
    "        writer.add_scalar('student/val_ece', val_ece, epoch)\n",
    "        writer.add_scalar('student/learning_rate', current_lr, epoch)\n",
    "        \n",
    "        # Save checkpoint\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': student.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'val_f1': val_f1,\n",
    "            'val_ece': val_ece,\n",
    "            'history': history,\n",
    "            'config': config.__dict__,\n",
    "        }\n",
    "        \n",
    "        # Save latest checkpoint\n",
    "        latest_path = os.path.join(config.checkpoint_dir, f\"{model_name}_latest.pth\")\n",
    "        torch.save(checkpoint, latest_path)\n",
    "        \n",
    "        # Save best model based on validation loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_path = os.path.join(config.checkpoint_dir, f\"{model_name}_best_loss.pth\")\n",
    "            torch.save(checkpoint, best_path)\n",
    "            logger.info(f\"New best model saved (val_loss: {val_loss:.4f})\")\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "        \n",
    "        # Save best model based on validation accuracy\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_acc_path = os.path.join(config.checkpoint_dir, f\"{model_name}_best_acc.pth\")\n",
    "            torch.save(checkpoint, best_acc_path)\n",
    "            history['best_epoch'] = epoch\n",
    "            logger.info(f\"New best accuracy model saved (val_acc: {val_acc:.2f}%)\")\n",
    "        \n",
    "        # Save model at end of each phase\n",
    "        if (epoch + 1) == config.warmup_epochs or (epoch + 1) == config.total_epochs:\n",
    "            phase_name = \"warmup\" if (epoch + 1) == config.warmup_epochs else \"final\"\n",
    "            phase_path = os.path.join(config.checkpoint_dir, f\"{model_name}_{phase_name}.pth\")\n",
    "            torch.save(checkpoint, phase_path)\n",
    "            logger.info(f\"{phase} phase completed, model saved to {phase_path}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if early_stop_counter >= config.early_stop_patience:\n",
    "            logger.info(f\"Early stopping triggered after {epoch+1} epochs (no improvement for {config.early_stop_patience} epochs)\")\n",
    "            break\n",
    "        \n",
    "        # Print memory stats\n",
    "        print_gpu_memory_stats()\n",
    "    \n",
    "    # End of training\n",
    "    logger.info(f\"Training completed. Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    # Save history\n",
    "    history_path = os.path.join(config.results_dir, f\"{model_name}_history.json\")\n",
    "    with open(history_path, 'w') as f:\n",
    "        json.dump(history, f, indent=4, cls=NumpyEncoder)\n",
    "    logger.info(f\"Training history saved to {history_path}\")\n",
    "    \n",
    "    return student, history\n",
    "\n",
    "# Helper class for JSON serialization of numpy arrays\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        return super(NumpyEncoder, self).default(obj)\n",
    "\n",
    "def plot_training_history(history, config):\n",
    "    \"\"\"Plot training history with multiple metrics\"\"\"\n",
    "    plt.figure(figsize=(15, 20))\n",
    "    \n",
    "    # Set a consistent style for better visualizations\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    \n",
    "    # Create color palette for consistent coloring\n",
    "    main_colors = ['#2077B4', '#FF7F0E', '#2CA02C', '#D62728']\n",
    "    \n",
    "    # Plot training & validation loss\n",
    "    ax1 = plt.subplot(4, 1, 1)\n",
    "    ax1.plot(history['train_loss'], label='Train', color=main_colors[0], linewidth=2)\n",
    "    ax1.plot(history['val_loss'], label='Validation', color=main_colors[1], linewidth=2)\n",
    "    if 'best_epoch' in history:\n",
    "        ax1.axvline(x=history['best_epoch'], color='r', linestyle='--', label='Best Model')\n",
    "    \n",
    "    # Mark the transition from warmup to main phase if warm-up was included\n",
    "    warmup_epochs = sum(1 for phase in history['phase'] if phase == 'Warmup')\n",
    "    if warmup_epochs > 0:\n",
    "        ax1.axvline(x=warmup_epochs-1, color='g', linestyle='--', label='End of Warm-up')\n",
    "    \n",
    "    ax1.set_title('Loss Over Time', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    ax1.legend(fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot training & validation accuracy\n",
    "    ax2 = plt.subplot(4, 1, 2)\n",
    "    ax2.plot(history['train_acc'], label='Train', color=main_colors[0], linewidth=2)\n",
    "    ax2.plot(history['val_acc'], label='Validation', color=main_colors[1], linewidth=2)\n",
    "    if 'best_epoch' in history:\n",
    "        ax2.axvline(x=history['best_epoch'], color='r', linestyle='--', label='Best Model')\n",
    "    if warmup_epochs > 0:\n",
    "        ax2.axvline(x=warmup_epochs-1, color='g', linestyle='--', label='End of Warm-up')\n",
    "    ax2.set_title('Accuracy Over Time', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot ECE and F1 Score\n",
    "    ax3 = plt.subplot(4, 1, 3)\n",
    "    ax3.plot(history['val_ece'], label='ECE', linewidth=2.5, color=main_colors[0])\n",
    "    ax3.plot(history['val_f1'], label='F1 Score', linewidth=2.5, color=main_colors[1])\n",
    "    if 'best_epoch' in history:\n",
    "        ax3.axvline(x=history['best_epoch'], color='r', linestyle='--', label='Best Model')\n",
    "    if warmup_epochs > 0:\n",
    "        ax3.axvline(x=warmup_epochs-1, color='g', linestyle='--', label='End of Warm-up')\n",
    "    ax3.set_title('Calibration and F1 Score', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel('Epoch', fontsize=12)\n",
    "    ax3.set_ylabel('Value', fontsize=12)\n",
    "    ax3.legend(fontsize=10)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot per-class accuracy for latest epoch\n",
    "    if history['per_class_accuracy'] and len(history['per_class_accuracy'][-1]) > 0:\n",
    "        ax4 = plt.subplot(4, 1, 4)\n",
    "        class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "        latest_per_class = history['per_class_accuracy'][-1]\n",
    "        \n",
    "        # Bar plot of per-class accuracy\n",
    "        bars = ax4.bar(range(len(latest_per_class)), latest_per_class, color=main_colors)\n",
    "        \n",
    "        # Add value labels on top of each bar\n",
    "        for i, bar in enumerate(bars):\n",
    "            height = bar.get_height()\n",
    "            ax4.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                    f'{height:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        ax4.set_title('Per-Class Accuracy (Final Epoch)', fontsize=14, fontweight='bold')\n",
    "        ax4.set_xlabel('Class', fontsize=12)\n",
    "        ax4.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "        ax4.set_xticks(range(len(class_names)))\n",
    "        ax4.set_xticklabels(class_names, rotation=45, ha='right')\n",
    "        ax4.grid(True, alpha=0.3, axis='y')\n",
    "        ax4.set_ylim(0, 110)  # Set y-axis limit to make room for labels\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # Update title based on whether warm-up phase was included\n",
    "    title_suffix = \"with Two-Phase Training\" if warmup_epochs > 0 else \"with Single-Phase Training\"\n",
    "    plt.suptitle(f'Baseline Supervised Training of EfficientNet-B0 on CIFAR-10 {title_suffix}', \n",
    "                fontsize=18, fontweight='bold', y=0.98)\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "    \n",
    "    # Add timestamp and config info\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    phase_info = f\"Warm-up: {config.warmup_epochs} epochs, Main: {config.main_epochs} epochs\" if config.include_warmup_phase else f\"Main: {config.main_epochs} epochs (no warm-up)\"\n",
    "    info_text = f\"Generated: {timestamp}\\nLearning Rate: {config.lr}, Weight Decay: {config.weight_decay}, Batch Size: {config.batch_size}\\n{phase_info}\"\n",
    "    plt.figtext(0.01, 0.01, info_text, fontsize=8)\n",
    "    \n",
    "    # Create a filename that indicates the training configuration\n",
    "    filename_prefix = \"training_history_with_warmup\" if config.include_warmup_phase else \"training_history_no_warmup\"\n",
    "    \n",
    "    # Save figure with high quality\n",
    "    plt.savefig(os.path.join(config.results_dir, 'plots', f'{filename_prefix}.png'), dpi=300, bbox_inches='tight')\n",
    "    logger.info(f\"Training history plot saved to {os.path.join(config.results_dir, 'plots', f'{filename_prefix}.png')}\")\n",
    "    \n",
    "    # Save a separate PDF version for publications\n",
    "    plt.savefig(os.path.join(config.results_dir, 'plots', f'{filename_prefix}.pdf'), format='pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_calibration_curve(model, test_loader, config):\n",
    "    \"\"\"Plot calibration reliability diagram\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    confidences = []\n",
    "    accuracies = []\n",
    "    \n",
    "    # Compute confidences and accuracies\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader, desc=\"Computing calibration data\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu', enabled=config.use_amp):\n",
    "                outputs = model(inputs)\n",
    "            \n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            conf, pred = probs.max(1)\n",
    "            acc = (pred == targets).float()\n",
    "            \n",
    "            confidences.append(conf.cpu())\n",
    "            accuracies.append(acc.cpu())\n",
    "    \n",
    "    # Concatenate lists\n",
    "    confidences = torch.cat(confidences)\n",
    "    accuracies = torch.cat(accuracies)\n",
    "    \n",
    "    # Calculate ECE\n",
    "    n_bins = 10  # As specified in requirements\n",
    "    bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    \n",
    "    bin_confidences = []\n",
    "    bin_accuracies = []\n",
    "    bin_sizes = []\n",
    "    \n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        in_bin = (confidences >= bin_lower) & (confidences < bin_upper)\n",
    "        bin_size = in_bin.sum().item()\n",
    "        \n",
    "        if bin_size > 0:\n",
    "            bin_confidence = confidences[in_bin].mean().item()\n",
    "            bin_accuracy = accuracies[in_bin].mean().item()\n",
    "        else:\n",
    "            bin_confidence = (bin_lower + bin_upper) / 2\n",
    "            bin_accuracy = 0\n",
    "            \n",
    "        bin_confidences.append(bin_confidence)\n",
    "        bin_accuracies.append(bin_accuracy)\n",
    "        bin_sizes.append(bin_size)\n",
    "    \n",
    "    bin_sizes = np.array(bin_sizes) / sum(bin_sizes)  # Normalize sizes\n",
    "    \n",
    "    # Calculate ECE\n",
    "    ece = sum(bin_sizes[i] * abs(bin_accuracies[i] - bin_confidences[i]) for i in range(len(bin_sizes)))\n",
    "    \n",
    "    # Plot reliability diagram\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Perfect calibration line\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n",
    "    \n",
    "    # Plot bins\n",
    "    plt.bar(bin_lowers.numpy(), bin_accuracies, width=1/n_bins, align='edge', alpha=0.5, label='Accuracy in bin')\n",
    "    for i, (conf, acc) in enumerate(zip(bin_confidences, bin_accuracies)):\n",
    "        plt.plot([conf, conf], [0, acc], 'r--', alpha=0.3)\n",
    "    \n",
    "    # Add histogram of confidence distribution\n",
    "    twin_ax = plt.twinx()\n",
    "    twin_ax.bar(bin_lowers.numpy(), bin_sizes, width=1/n_bins, align='edge', alpha=0.3, color='g', label='Samples')\n",
    "    twin_ax.set_ylabel('Proportion of Samples')\n",
    "    \n",
    "    plt.title(f'Calibration Reliability Diagram (ECE = {ece:.4f})')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig(os.path.join(config.results_dir, 'plots', 'calibration_curve.png'), dpi=300)\n",
    "    logger.info(f\"Calibration curve saved to {os.path.join(config.results_dir, 'plots', 'calibration_curve.png')}\")\n",
    "    plt.close()\n",
    "    \n",
    "    return ece\n",
    "\n",
    "def test_student_model(student, test_loader, config):\n",
    "    \"\"\"Evaluate the student model on the test set and log detailed metrics\"\"\"\n",
    "    logger.info(\"Testing student model on test set...\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    metrics = validate(student, test_loader, criterion, config)\n",
    "    \n",
    "    logger.info(f\"Test Results:\")\n",
    "    logger.info(f\"Loss: {metrics['loss']:.4f}\")\n",
    "    logger.info(f\"Accuracy: {metrics['accuracy']:.2f}%\")\n",
    "    logger.info(f\"F1 Score: {metrics['f1_score']:.4f}\")\n",
    "    logger.info(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    logger.info(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    logger.info(f\"ECE: {metrics['ece']:.4f}\")\n",
    "    \n",
    "    # Log per-class accuracy\n",
    "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    logger.info(\"Per-class accuracy:\")\n",
    "    for i, acc in enumerate(metrics['per_class_accuracy']):\n",
    "        logger.info(f\"  {class_names[i]}: {acc:.2f}%\")\n",
    "    \n",
    "    # Generate classification report\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    student.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader, desc=\"Generating classification report\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass with mixed precision\n",
    "            with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu', enabled=config.use_amp):\n",
    "                outputs = student(inputs)\n",
    "            \n",
    "            _, predicted = outputs.max(1)\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    # Create classification report\n",
    "    report = classification_report(all_targets, all_predictions, target_names=class_names)\n",
    "    logger.info(f\"Classification Report:\\n{report}\")\n",
    "    \n",
    "    # Save detailed classification report\n",
    "    report_path = os.path.join(config.results_dir, 'classification_report.txt')\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    # Save metrics to JSON\n",
    "    metrics_path = os.path.join(config.results_dir, 'test_metrics.json')\n",
    "    save_metrics = {\n",
    "        'model_name': 'baseline_student',\n",
    "        'accuracy': metrics['accuracy'],\n",
    "        'f1_score': metrics['f1_score'],\n",
    "        'precision': metrics['precision'],\n",
    "        'recall': metrics['recall'],\n",
    "        'ece': metrics['ece'],\n",
    "        'per_class_accuracy': metrics['per_class_accuracy']\n",
    "    }\n",
    "    \n",
    "    with open(metrics_path, 'w') as f:\n",
    "        json.dump(save_metrics, f, indent=4, cls=NumpyEncoder)\n",
    "    \n",
    "    logger.info(f\"Test metrics saved to {metrics_path}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    try:\n",
    "        # Initialize configuration\n",
    "        config = Config()\n",
    "        \n",
    "        # Parse command line arguments\n",
    "        import argparse\n",
    "        import sys\n",
    "        \n",
    "        # Detect if running in Jupyter\n",
    "        is_jupyter = 'ipykernel' in sys.modules\n",
    "        \n",
    "        if is_jupyter:\n",
    "            # For Jupyter notebooks, use default config without parsing args\n",
    "            logger.info(\"Running in Jupyter Notebook environment\")\n",
    "            # Allow setting include_warmup through a variable in the notebook\n",
    "            # Access through `include_warmup` if it exists in globals, otherwise use default\n",
    "            config.include_warmup_phase = globals().get('include_warmup', config.include_warmup_phase)\n",
    "            logger.info(f\"Using include_warmup_phase={config.include_warmup_phase}\")\n",
    "        else:\n",
    "            # For command line, parse arguments normally\n",
    "            parser = argparse.ArgumentParser(description='Baseline training for EfficientNet-B0 on CIFAR-10')\n",
    "            parser.add_argument('--no-warmup', dest='include_warmup', action='store_false',\n",
    "                                help='Skip the warm-up phase to create the ensemble-distillation baseline (50 epochs, no warm-up)')\n",
    "            parser.set_defaults(include_warmup=True)\n",
    "            \n",
    "            # Ignore unknown arguments that might be passed by Jupyter\n",
    "            args, unknown = parser.parse_known_args()\n",
    "            if unknown:\n",
    "                logger.warning(f\"Ignoring unknown arguments: {unknown}\")\n",
    "            \n",
    "            # Update config with command line arguments\n",
    "            config.include_warmup_phase = args.include_warmup\n",
    "        \n",
    "        # Set total epochs based on the warmup configuration\n",
    "        config.total_epochs = config.warmup_epochs + config.main_epochs if config.include_warmup_phase else config.main_epochs\n",
    "        \n",
    "        # Log the configuration and training phases\n",
    "        if config.include_warmup_phase:\n",
    "            logger.info(f\"Training with two-phase schedule: {config.warmup_epochs} warm-up epochs + {config.main_epochs} main epochs\")\n",
    "            logger.info(f\"This will establish a baseline for MUTUAL LEARNING comparison\")\n",
    "        else:\n",
    "            logger.info(f\"Training with single-phase schedule: {config.main_epochs} main epochs (no warm-up)\")\n",
    "            logger.info(f\"This will establish a baseline for ENSEMBLE DISTILLATION comparison\")\n",
    "        \n",
    "        logger.info(f\"Total epochs: {config.total_epochs}\")\n",
    "        logger.info(f\"Configuration: {config}\")\n",
    "        \n",
    "        # Set seed for reproducibility\n",
    "        set_seed(config.seed)\n",
    "        \n",
    "        # Initial GPU memory stats\n",
    "        print_gpu_memory_stats()\n",
    "        \n",
    "        # Get data loaders\n",
    "        logger.info(\"Preparing data loaders...\")\n",
    "        train_loader, val_loader, test_loader = get_cifar10_loaders(config)\n",
    "        \n",
    "        # Create student model initialized with ImageNet weights\n",
    "        logger.info(\"Creating student model...\")\n",
    "        student = create_student_model(config)\n",
    "        \n",
    "        # Train student model\n",
    "        logger.info(\"Training student with baseline supervised learning...\")\n",
    "        student, history = train_student(student, train_loader, val_loader, config)\n",
    "        \n",
    "        # Plot training history\n",
    "        logger.info(\"Plotting training history...\")\n",
    "        plot_training_history(history, config)\n",
    "        \n",
    "        # Test student model\n",
    "        logger.info(\"Testing student model...\")\n",
    "        test_metrics = test_student_model(student, test_loader, config)\n",
    "        \n",
    "        # Plot calibration curve for student\n",
    "        logger.info(\"Plotting calibration curve...\")\n",
    "        ece = plot_calibration_curve(student, test_loader, config)\n",
    "        logger.info(f\"Final ECE: {ece:.4f}\")\n",
    "        \n",
    "        # Export final model with appropriate naming based on training configuration\n",
    "        logger.info(\"Exporting final model...\")\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Determine baseline type based on whether warm-up was included\n",
    "        baseline_type = \"mutual_learning\" if config.include_warmup_phase else \"ensemble_distillation\" \n",
    "        \n",
    "        # Create a specific directory for each baseline type with timestamp to avoid mixing runs\n",
    "        baseline_dir = os.path.join(config.export_dir, baseline_type)\n",
    "        os.makedirs(baseline_dir, exist_ok=True)\n",
    "        \n",
    "        # Use timestamp in directory name to keep runs separate\n",
    "        timestamped_dir = os.path.join(baseline_dir, timestamp)\n",
    "        os.makedirs(timestamped_dir, exist_ok=True)\n",
    "        \n",
    "        final_model_path = os.path.join(timestamped_dir, f\"baseline_student_{baseline_type}.pth\")\n",
    "        torch.save({\n",
    "            'model_state_dict': student.state_dict(),\n",
    "            'test_metrics': test_metrics,\n",
    "            'config': config.__dict__,\n",
    "            'ece': ece,\n",
    "            'baseline_type': baseline_type,\n",
    "            'with_warmup': config.include_warmup_phase\n",
    "        }, final_model_path)\n",
    "        logger.info(f\"Final model exported to {final_model_path}\")\n",
    "        \n",
    "        # Save metrics to a specific directory for easy comparison\n",
    "        metrics_dir = os.path.join(config.results_dir, \"baselines\", baseline_type)\n",
    "        os.makedirs(metrics_dir, exist_ok=True)\n",
    "        metrics_path = os.path.join(metrics_dir, \"metrics.json\")\n",
    "        \n",
    "        # Save baseline metrics\n",
    "        save_metrics = {\n",
    "            'model_name': f'baseline_{baseline_type}',\n",
    "            'accuracy': test_metrics['accuracy'],\n",
    "            'f1_score': test_metrics['f1_score'],\n",
    "            'precision': test_metrics['precision'],\n",
    "            'recall': test_metrics['recall'],\n",
    "            'ece': test_metrics['ece'],\n",
    "            'per_class_accuracy': test_metrics['per_class_accuracy'],\n",
    "            'baseline_type': baseline_type,\n",
    "            'with_warmup': config.include_warmup_phase,\n",
    "            'timestamp': timestamp\n",
    "        }\n",
    "        \n",
    "        with open(metrics_path, 'w') as f:\n",
    "            json.dump(save_metrics, f, indent=4, cls=NumpyEncoder)\n",
    "        \n",
    "        logger.info(f\"Baseline metrics for {baseline_type} saved to {metrics_path}\")\n",
    "        \n",
    "        # Final GPU memory stats\n",
    "        print_gpu_memory_stats()\n",
    "        \n",
    "        logger.info(f\"Baseline student training for {baseline_type.upper().replace('_', ' ')} completed successfully.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {str(e)}\")\n",
    "        logger.error(traceback.format_exc())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f12b399",
   "metadata": {},
   "source": [
    "Baseline Model Evaluation Script for CIFAR-10\n",
    "\n",
    "This script evaluates baseline EfficientNet-B0 models trained with standard cross-entropy loss \n",
    "on the CIFAR-10 dataset. It loads and tests models from two approaches:\n",
    "1. Ensemble Distillation Baseline (no warm-up, 50 epochs)\n",
    "2. Mutual Learning Baseline (with warm-up, 5+50 epochs)\n",
    "\n",
    "The script generates comprehensive visualizations for model accuracy, calibration metrics,\n",
    "confusion matrices, and sample predictions.\n",
    "\n",
    "Part of the research: \n",
    "\"Comparative Analysis of Ensemble Distillation and Mutual Learning: \n",
    "A Unified Framework for Uncertainty-Calibrated Vision Systems\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaaacfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 13:51:14,013 [INFO] - Using device: cuda\n",
      "2025-04-20 13:51:14,013 [INFO] - GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "2025-04-20 13:51:14,013 [INFO] - Available memory: 6.44 GB\n",
      "2025-04-20 13:51:14,017 [INFO] - Starting baseline evaluation...\n",
      "2025-04-20 13:51:14,029 [INFO] - Loading model from: C:\\Users\\Gading\\Downloads\\Research\\Models\\Baseline\\exports\\ensemble_distillation\\20250419_185329\\baseline_student_ensemble_distillation.pth\n",
      "C:\\Users\\Gading\\AppData\\Local\\Temp\\ipykernel_29260\\3791505337.py:293: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Baseline Models Evaluation Pipeline\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 13:51:14,542 [INFO] - Model loaded successfully and set to evaluation mode\n",
      "2025-04-20 13:51:14,542 [INFO] - Loading model from: C:\\Users\\Gading\\Downloads\\Research\\Models\\Baseline\\exports\\mutual_learning\\20250419_174414\\baseline_student_mutual_learning.pth\n",
      "2025-04-20 13:51:14,764 [INFO] - Model loaded successfully and set to evaluation mode\n",
      "2025-04-20 13:51:14,764 [INFO] - Ensemble Distillation Baseline Metadata: {'baseline_type': 'ensemble_distillation', 'with_warmup': False, 'test_metrics': {'loss': 0.18705307144173391, 'accuracy': 96.09, 'f1_score': 0.9609655751744507, 'precision': 0.9611344699520588, 'recall': 0.9609, 'ece': 0.021773903426527977, 'per_class_accuracy': [97.0, 98.2, 94.9, 93.7, 95.6, 93.0, 96.8, 97.4, 97.9, 96.4]}, 'ece': tensor(0.1435, device='cuda:0'), 'config': {'seed': 42, 'model_name': 'baseline_student', 'dataset': 'CIFAR-10', 'use_amp': True, 'prefetch_factor': 2, 'pin_memory': True, 'persistent_workers': True, 'batch_size': 64, 'gradient_accumulation_steps': 1, 'input_size': 32, 'model_input_size': 224, 'num_workers': 4, 'val_split': 0.1, 'dataset_path': 'C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Dataset', 'clear_cache_every_n_epochs': 1, 'pretrained': True, 'num_classes': 10, 'include_warmup_phase': False, 'warmup_epochs': 5, 'main_epochs': 50, 'total_epochs': 50, 'lr': 0.001, 'weight_decay': 0.0001, 'early_stop_patience': 10, 'checkpoint_dir': 'C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Models\\\\Baseline\\\\checkpoints', 'results_dir': 'C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Results\\\\Baseline', 'export_dir': 'C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Models\\\\Baseline\\\\exports'}}\n",
      "2025-04-20 13:51:14,764 [INFO] - Mutual Learning Baseline Metadata: {'baseline_type': 'mutual_learning', 'with_warmup': True, 'test_metrics': {'loss': 0.2008631713451094, 'accuracy': 96.06, 'f1_score': 0.9606898227930444, 'precision': 0.9609758525464003, 'recall': 0.9606, 'ece': 0.023542599388957024, 'per_class_accuracy': [96.8, 97.1, 94.9, 93.5, 97.2, 92.4, 96.9, 97.3, 97.3, 97.2]}, 'ece': tensor(0.1628, device='cuda:0'), 'config': {'seed': 42, 'model_name': 'baseline_student', 'dataset': 'CIFAR-10', 'use_amp': True, 'prefetch_factor': 2, 'pin_memory': True, 'persistent_workers': True, 'batch_size': 64, 'gradient_accumulation_steps': 1, 'input_size': 32, 'model_input_size': 224, 'num_workers': 4, 'val_split': 0.1, 'dataset_path': 'C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Dataset', 'clear_cache_every_n_epochs': 1, 'pretrained': True, 'num_classes': 10, 'include_warmup_phase': True, 'warmup_epochs': 5, 'main_epochs': 50, 'total_epochs': 55, 'lr': 0.001, 'weight_decay': 0.0001, 'early_stop_patience': 10, 'checkpoint_dir': 'C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Models\\\\Baseline\\\\checkpoints', 'results_dir': 'C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Results\\\\Baseline', 'export_dir': 'C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Models\\\\Baseline\\\\exports'}}\n",
      "2025-04-20 13:51:14,764 [INFO] - Preparing test dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 13:51:15,309 [INFO] - Test dataset loaded with 10000 samples\n",
      "2025-04-20 13:51:15,309 [INFO] - Creating DataLoader with batch size 64...\n",
      "2025-04-20 13:51:15,309 [INFO] - Evaluating Ensemble Distillation baseline model...\n",
      "2025-04-20 13:51:15,309 [INFO] - Running inference...\n",
      "2025-04-20 13:51:15,470 [INFO] - GPU cache cleared: 78.82MB → 78.82MB (freed 0.00MB)\n",
      "Evaluating: 100%|██████████| 157/157 [00:20<00:00,  7.54it/s]\n",
      "2025-04-20 13:51:36,294 [INFO] - Inference complete on 10000 samples\n",
      "2025-04-20 13:51:36,295 [INFO] - Analyzing baseline_ed model performance...\n",
      "2025-04-20 13:51:36,296 [INFO] - [baseline_ed] Test Accuracy: 96.09%\n",
      "2025-04-20 13:51:36,304 [INFO] - [baseline_ed] F1 Score (macro): 96.10%\n",
      "2025-04-20 13:51:36,304 [INFO] - [baseline_ed] Precision (macro): 96.11%\n",
      "2025-04-20 13:51:36,304 [INFO] - [baseline_ed] Recall (macro): 96.09%\n",
      "2025-04-20 13:51:36,308 [INFO] - [baseline_ed] Expected Calibration Error (ECE): 0.0218\n",
      "2025-04-20 13:51:36,309 [INFO] - [baseline_ed] Maximum Calibration Error (MCE): 0.2598\n",
      "2025-04-20 13:51:36,309 [INFO] - [baseline_ed] Average Calibration Error (ACE): 0.1491\n",
      "2025-04-20 13:51:36,310 [INFO] - [baseline_ed] Root Mean Squared Cal. Error (RMSCE): 0.0591\n",
      "2025-04-20 13:51:37,094 [INFO] - \n",
      "[baseline_ed] Classification Report:\n",
      "2025-04-20 13:51:37,095 [INFO] -               precision    recall  f1-score   support\n",
      "\n",
      "    airplane      0.970     0.970     0.970      1000\n",
      "  automobile      0.967     0.982     0.975      1000\n",
      "        bird      0.961     0.949     0.955      1000\n",
      "         cat      0.904     0.937     0.920      1000\n",
      "        deer      0.968     0.956     0.962      1000\n",
      "         dog      0.935     0.930     0.932      1000\n",
      "        frog      0.984     0.968     0.976      1000\n",
      "       horse      0.980     0.974     0.977      1000\n",
      "        ship      0.972     0.979     0.976      1000\n",
      "       truck      0.970     0.964     0.967      1000\n",
      "\n",
      "    accuracy                          0.961     10000\n",
      "   macro avg      0.961     0.961     0.961     10000\n",
      "weighted avg      0.961     0.961     0.961     10000\n",
      "\n",
      "2025-04-20 13:51:38,172 [INFO] - [baseline_ed] Evaluation results saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline\\baseline_ed\n",
      "2025-04-20 13:51:38,172 [INFO] - Generating prediction visualizations for baseline_ed...\n",
      "C:\\Users\\Gading\\AppData\\Local\\Temp\\ipykernel_29260\\3791505337.py:955: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n",
      "2025-04-20 13:51:39,900 [INFO] - Prediction visualizations saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline\\baseline_ed/prediction_examples.png\n",
      "2025-04-20 13:51:39,901 [INFO] - Generating GradCAM visualizations for baseline_ed...\n",
      "Finding class samples:   0%|          | 25/10000 [00:00<00:10, 929.33it/s]\n",
      "2025-04-20 13:51:39,930 [INFO] - Generating GradCAM for class 'airplane'\n",
      "2025-04-20 13:51:40,297 [INFO] - Generating GradCAM for class 'automobile'\n",
      "2025-04-20 13:51:40,640 [INFO] - Generating GradCAM for class 'bird'\n",
      "2025-04-20 13:51:41,013 [INFO] - Generating GradCAM for class 'cat'\n",
      "2025-04-20 13:51:41,390 [INFO] - Generating GradCAM for class 'deer'\n",
      "2025-04-20 13:51:41,747 [INFO] - Generating GradCAM for class 'dog'\n",
      "2025-04-20 13:51:42,103 [INFO] - Generating GradCAM for class 'frog'\n",
      "2025-04-20 13:51:42,480 [INFO] - Generating GradCAM for class 'horse'\n",
      "2025-04-20 13:51:42,850 [INFO] - Generating GradCAM for class 'ship'\n",
      "2025-04-20 13:51:43,202 [INFO] - Generating GradCAM for class 'truck'\n",
      "C:\\Users\\Gading\\AppData\\Local\\Temp\\ipykernel_29260\\3791505337.py:1139: UserWarning: This figure was using a layout engine that is incompatible with subplots_adjust and/or tight_layout; not calling subplots_adjust.\n",
      "  fig.subplots_adjust(right=0.9, top=0.95, bottom=0.05, wspace=0.3, hspace=0.3)\n",
      "2025-04-20 13:51:46,118 [INFO] - GradCAM visualizations saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline\\baseline_ed/gradcam_visualization.png\n",
      "2025-04-20 13:51:46,118 [INFO] - Evaluating Mutual Learning baseline model...\n",
      "2025-04-20 13:51:46,118 [INFO] - Running inference...\n",
      "2025-04-20 13:51:46,319 [INFO] - GPU cache cleared: 94.67MB → 94.67MB (freed 0.00MB)\n",
      "Evaluating: 100%|██████████| 157/157 [00:20<00:00,  7.58it/s]\n",
      "2025-04-20 13:52:07,030 [INFO] - Inference complete on 10000 samples\n",
      "2025-04-20 13:52:07,031 [INFO] - Analyzing baseline_ml model performance...\n",
      "2025-04-20 13:52:07,033 [INFO] - [baseline_ml] Test Accuracy: 96.06%\n",
      "2025-04-20 13:52:07,041 [INFO] - [baseline_ml] F1 Score (macro): 96.07%\n",
      "2025-04-20 13:52:07,042 [INFO] - [baseline_ml] Precision (macro): 96.10%\n",
      "2025-04-20 13:52:07,043 [INFO] - [baseline_ml] Recall (macro): 96.06%\n",
      "2025-04-20 13:52:07,046 [INFO] - [baseline_ml] Expected Calibration Error (ECE): 0.0235\n",
      "2025-04-20 13:52:07,046 [INFO] - [baseline_ml] Maximum Calibration Error (MCE): 0.7075\n",
      "2025-04-20 13:52:07,047 [INFO] - [baseline_ml] Average Calibration Error (ACE): 0.2593\n",
      "2025-04-20 13:52:07,047 [INFO] - [baseline_ml] Root Mean Squared Cal. Error (RMSCE): 0.0647\n",
      "2025-04-20 13:52:07,796 [INFO] - \n",
      "[baseline_ml] Classification Report:\n",
      "2025-04-20 13:52:07,800 [INFO] -               precision    recall  f1-score   support\n",
      "\n",
      "    airplane      0.955     0.968     0.961      1000\n",
      "  automobile      0.976     0.971     0.973      1000\n",
      "        bird      0.977     0.949     0.963      1000\n",
      "         cat      0.895     0.935     0.914      1000\n",
      "        deer      0.970     0.972     0.971      1000\n",
      "         dog      0.948     0.924     0.936      1000\n",
      "        frog      0.983     0.969     0.976      1000\n",
      "       horse      0.979     0.973     0.976      1000\n",
      "        ship      0.972     0.973     0.973      1000\n",
      "       truck      0.956     0.972     0.964      1000\n",
      "\n",
      "    accuracy                          0.961     10000\n",
      "   macro avg      0.961     0.961     0.961     10000\n",
      "weighted avg      0.961     0.961     0.961     10000\n",
      "\n",
      "2025-04-20 13:52:08,879 [INFO] - [baseline_ml] Evaluation results saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline\\baseline_ml\n",
      "2025-04-20 13:52:08,881 [INFO] - Generating prediction visualizations for baseline_ml...\n",
      "C:\\Users\\Gading\\AppData\\Local\\Temp\\ipykernel_29260\\3791505337.py:955: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n",
      "2025-04-20 13:52:10,713 [INFO] - Prediction visualizations saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline\\baseline_ml/prediction_examples.png\n",
      "2025-04-20 13:52:10,713 [INFO] - Generating GradCAM visualizations for baseline_ml...\n",
      "Finding class samples:   0%|          | 25/10000 [00:00<00:09, 1042.83it/s]\n",
      "2025-04-20 13:52:10,745 [INFO] - Generating GradCAM for class 'airplane'\n",
      "2025-04-20 13:52:11,094 [INFO] - Generating GradCAM for class 'automobile'\n",
      "2025-04-20 13:52:11,428 [INFO] - Generating GradCAM for class 'bird'\n",
      "2025-04-20 13:52:11,796 [INFO] - Generating GradCAM for class 'cat'\n",
      "2025-04-20 13:52:12,157 [INFO] - Generating GradCAM for class 'deer'\n",
      "2025-04-20 13:52:12,544 [INFO] - Generating GradCAM for class 'dog'\n",
      "2025-04-20 13:52:12,907 [INFO] - Generating GradCAM for class 'frog'\n",
      "2025-04-20 13:52:13,282 [INFO] - Generating GradCAM for class 'horse'\n",
      "2025-04-20 13:52:13,657 [INFO] - Generating GradCAM for class 'ship'\n",
      "2025-04-20 13:52:14,037 [INFO] - Generating GradCAM for class 'truck'\n",
      "C:\\Users\\Gading\\AppData\\Local\\Temp\\ipykernel_29260\\3791505337.py:1139: UserWarning: This figure was using a layout engine that is incompatible with subplots_adjust and/or tight_layout; not calling subplots_adjust.\n",
      "  fig.subplots_adjust(right=0.9, top=0.95, bottom=0.05, wspace=0.3, hspace=0.3)\n",
      "2025-04-20 13:52:16,852 [INFO] - GradCAM visualizations saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline\\baseline_ml/gradcam_visualization.png\n",
      "2025-04-20 13:52:16,859 [INFO] - Generating model comparison visualizations...\n",
      "C:\\Users\\Gading\\AppData\\Local\\Temp\\ipykernel_29260\\3791505337.py:644: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Gading\\AppData\\Local\\Temp\\ipykernel_29260\\3791505337.py:664: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Gading\\AppData\\Local\\Temp\\ipykernel_29260\\3791505337.py:717: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Gading\\AppData\\Local\\Temp\\ipykernel_29260\\3791505337.py:765: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n",
      "2025-04-20 13:52:18,907 [INFO] - Generating combined calibration curve comparison...\n",
      "2025-04-20 13:52:18,914 [INFO] - Preparing test dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 13:52:19,457 [INFO] - Test dataset loaded with 10000 samples\n",
      "2025-04-20 13:52:19,457 [INFO] - Creating DataLoader with batch size 64...\n",
      "2025-04-20 13:52:19,457 [INFO] - Loading model from: C:\\Users\\Gading\\Downloads\\Research\\Models\\Baseline\\exports\\ensemble_distillation\\20250419_185329\\baseline_student_ensemble_distillation.pth\n",
      "C:\\Users\\Gading\\AppData\\Local\\Temp\\ipykernel_29260\\3791505337.py:293: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n",
      "2025-04-20 13:52:19,721 [INFO] - Model loaded successfully and set to evaluation mode\n",
      "2025-04-20 13:52:19,723 [INFO] - Running inference...\n",
      "2025-04-20 13:52:20,012 [INFO] - GPU cache cleared: 126.09MB → 126.09MB (freed 0.00MB)\n",
      "Evaluating: 100%|██████████| 157/157 [00:21<00:00,  7.45it/s]\n",
      "2025-04-20 13:52:41,086 [INFO] - Inference complete on 10000 samples\n",
      "2025-04-20 13:52:41,091 [INFO] - Preparing test dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 13:52:41,677 [INFO] - Test dataset loaded with 10000 samples\n",
      "2025-04-20 13:52:41,677 [INFO] - Creating DataLoader with batch size 64...\n",
      "2025-04-20 13:52:41,677 [INFO] - Loading model from: C:\\Users\\Gading\\Downloads\\Research\\Models\\Baseline\\exports\\mutual_learning\\20250419_174414\\baseline_student_mutual_learning.pth\n",
      "2025-04-20 13:52:41,837 [INFO] - Model loaded successfully and set to evaluation mode\n",
      "2025-04-20 13:52:41,837 [INFO] - Running inference...\n",
      "2025-04-20 13:52:42,098 [INFO] - GPU cache cleared: 126.80MB → 126.80MB (freed 0.00MB)\n",
      "Evaluating: 100%|██████████| 157/157 [00:21<00:00,  7.45it/s]\n",
      "2025-04-20 13:53:03,172 [INFO] - Inference complete on 10000 samples\n",
      "C:\\Users\\Gading\\AppData\\Local\\Temp\\ipykernel_29260\\3791505337.py:849: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n",
      "2025-04-20 13:53:03,781 [INFO] - Calibration curve comparison saved successfully\n",
      "2025-04-20 13:53:03,781 [INFO] - Model comparison visualizations saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline\n",
      "2025-04-20 13:53:03,781 [INFO] - Generating confidence distribution visualization...\n",
      "C:\\Users\\Gading\\AppData\\Local\\Temp\\ipykernel_29260\\3791505337.py:1232: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n",
      "2025-04-20 13:53:04,555 [INFO] - Confidence distribution visualization saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline/confidence_distribution.png\n",
      "2025-04-20 13:53:04,555 [INFO] - Generating detailed calibration visualization...\n",
      "C:\\Users\\Gading\\AppData\\Local\\Temp\\ipykernel_29260\\3791505337.py:1316: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n",
      "2025-04-20 13:53:05,216 [INFO] - Detailed calibration visualization saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline/calibration_detailed.png\n",
      "2025-04-20 13:53:05,216 [INFO] - Analyzing prediction overlap between models...\n",
      "C:\\Users\\Gading\\AppData\\Local\\Temp\\ipykernel_29260\\3791505337.py:1405: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n",
      "2025-04-20 13:53:05,767 [INFO] - Prediction overlap analysis saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline/prediction_overlap.png\n",
      "2025-04-20 13:53:05,777 [INFO] - Analyzing misclassifications...\n",
      "C:\\Users\\Gading\\AppData\\Local\\Temp\\ipykernel_29260\\3791505337.py:1525: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n",
      "2025-04-20 13:53:08,406 [INFO] - Misclassification analysis saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline/common_misclassifications.png\n",
      "2025-04-20 13:53:08,416 [INFO] - ==================================================\n",
      "2025-04-20 13:53:08,416 [INFO] - Baseline models evaluation completed successfully!\n",
      "2025-04-20 13:53:08,416 [INFO] - All results saved to 'C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline' directory\n",
      "2025-04-20 13:53:08,416 [INFO] - ==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Evaluation Complete! Results saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\Baseline\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Baseline Model Evaluation Script for CIFAR-10\n",
    "\n",
    "This script evaluates baseline EfficientNet-B0 models trained with standard cross-entropy loss \n",
    "on the CIFAR-10 dataset. It loads and tests models from two approaches:\n",
    "1. Ensemble Distillation Baseline (no warm-up, 50 epochs)\n",
    "2. Mutual Learning Baseline (with warm-up, 5+50 epochs)\n",
    "\n",
    "The script generates comprehensive visualizations for model accuracy, calibration metrics,\n",
    "confusion matrices, and sample predictions.\n",
    "\n",
    "Part of the research: \n",
    "\"Comparative Analysis of Ensemble Distillation and Mutual Learning: \n",
    "A Unified Framework for Uncertainty-Calibrated Vision Systems\"\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import logging\n",
    "import traceback\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.amp import autocast\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set base paths\n",
    "BASE_PATH = r\"C:\\Users\\Gading\\Downloads\\Research\"\n",
    "DATASET_PATH = os.path.join(BASE_PATH, \"Dataset\")\n",
    "RESULTS_PATH = os.path.join(BASE_PATH, \"Results\")\n",
    "MODELS_PATH = os.path.join(BASE_PATH, \"Models\")\n",
    "\n",
    "# Specific paths for baseline models\n",
    "MODEL_RESULTS_PATH = os.path.join(RESULTS_PATH, \"Baseline\")\n",
    "MODEL_EXPORTS_PATH = os.path.join(MODELS_PATH, \"Baseline\", \"exports\")\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(os.path.join(MODEL_RESULTS_PATH, \"logs\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(MODEL_RESULTS_PATH, \"plots\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(MODEL_RESULTS_PATH, \"plots_dml\"), exist_ok=True)\n",
    "\n",
    "# Setup logging\n",
    "log_file = os.path.join(MODEL_RESULTS_PATH, \"logs\", \"baseline_evaluation.log\")\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s [%(levelname)s] - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Utility: Convert numpy types to native Python types for JSON serialization\n",
    "def to_serializable(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [to_serializable(v) for v in obj]\n",
    "    elif isinstance(obj, tuple):\n",
    "        return tuple(to_serializable(v) for v in obj)\n",
    "    elif hasattr(obj, 'tolist'):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, (np.generic,)):\n",
    "        return obj.item()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# Set environment variables for better performance\n",
    "os.environ['OMP_NUM_THREADS'] = '4'  # Optimize CPU threading\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'  # Limit memory fragmentation\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    logger.info(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    logger.info(f\"Available memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "####################################\n",
    "# 1. Configuration Class\n",
    "####################################\n",
    "class BaselineEvalConfig:\n",
    "    def __init__(self):\n",
    "        # Base paths\n",
    "        self.base_path = BASE_PATH\n",
    "        \n",
    "        # Dataset path\n",
    "        self.dataset_path = os.path.join(self.base_path, \"Dataset\", \"CIFAR-10\")\n",
    "        \n",
    "        # Model paths\n",
    "        self.models_base_path = os.path.join(self.base_path, \"Models\", \"Baseline\")\n",
    "        \n",
    "        # Model checkpoint paths - these are the exported models for evaluation\n",
    "        self.ed_model_path = os.path.join(\n",
    "            self.models_base_path, \"exports\", \"ensemble_distillation\", \n",
    "            \"20250419_185329\", \"baseline_student_ensemble_distillation.pth\"\n",
    "        )\n",
    "        \n",
    "        self.ml_model_path = os.path.join(\n",
    "            self.models_base_path, \"exports\", \"mutual_learning\", \n",
    "            \"20250419_174414\", \"baseline_student_mutual_learning.pth\"\n",
    "        )\n",
    "        \n",
    "        # Output directory for evaluation results\n",
    "        self.output_dir = os.path.join(self.base_path, \"Results\", \"Baseline\")\n",
    "        \n",
    "        # Hardware settings\n",
    "        self.batch_size = 64\n",
    "        self.num_workers = 4\n",
    "        self.use_amp = True\n",
    "        self.pin_memory = True\n",
    "        \n",
    "        # CIFAR-10 classes\n",
    "        self.classes = ('airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "                        'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "        \n",
    "        # ImageNet normalization (used by pretrained models)\n",
    "        self.mean = [0.485, 0.456, 0.406]\n",
    "        self.std = [0.229, 0.224, 0.225]\n",
    "        \n",
    "        # Input size for model\n",
    "        self.input_size = 224\n",
    "        \n",
    "        # Calibration metrics\n",
    "        self.n_bins_calibration = 10\n",
    "        \n",
    "        # Plot configuration\n",
    "        self.plot_dpi = 300\n",
    "        self.plot_format = 'png'\n",
    "        self.ieee_style = True\n",
    "        \n",
    "        # Seed for reproducibility\n",
    "        self.seed = 42\n",
    "\n",
    "####################################\n",
    "# 2. Utilities\n",
    "####################################\n",
    "def setup_environment():\n",
    "    \"\"\"Setup environment and return config\"\"\"\n",
    "    config = BaselineEvalConfig()\n",
    "    \n",
    "    # Set seed for reproducibility\n",
    "    torch.manual_seed(config.seed)\n",
    "    np.random.seed(config.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(config.seed)\n",
    "        torch.cuda.manual_seed_all(config.seed)\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(config.output_dir, exist_ok=True)\n",
    "    \n",
    "    # Set ieee style for plots if requested\n",
    "    if config.ieee_style:\n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "        plt.rcParams.update({\n",
    "            'font.family': 'serif',\n",
    "            'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "            'font.size': 10,\n",
    "            'axes.titlesize': 11,\n",
    "            'axes.labelsize': 10,\n",
    "            'xtick.labelsize': 9,\n",
    "            'ytick.labelsize': 9,\n",
    "            'legend.fontsize': 9,\n",
    "            'figure.dpi': 300,\n",
    "            'savefig.dpi': 300,\n",
    "            'savefig.bbox': 'tight',\n",
    "            'savefig.pad_inches': 0.05,\n",
    "            'figure.figsize': (8, 6),\n",
    "            'figure.constrained_layout.use': True,\n",
    "            'axes.grid': True,\n",
    "            'grid.alpha': 0.3,\n",
    "            'lines.markersize': 5,\n",
    "            'lines.linewidth': 1.5,\n",
    "        })\n",
    "    \n",
    "    return config\n",
    "\n",
    "def clear_gpu_cache():\n",
    "    \"\"\"Clear GPU cache to free up memory\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        before_mem = torch.cuda.memory_allocated() / 1024**2\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        after_mem = torch.cuda.memory_allocated() / 1024**2\n",
    "        logger.info(f\"GPU cache cleared: {before_mem:.2f}MB → {after_mem:.2f}MB (freed {before_mem-after_mem:.2f}MB)\")\n",
    "\n",
    "####################################\n",
    "# 3. Dataset and DataLoader\n",
    "####################################\n",
    "def get_transform(config):\n",
    "    \"\"\"Get transforms for CIFAR-10 test dataset\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(config.input_size, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=config.mean, std=config.std),\n",
    "    ])\n",
    "    \n",
    "    return transform\n",
    "\n",
    "def get_test_dataset(config):\n",
    "    \"\"\"Create a CIFAR-10 test dataset with appropriate transformations\"\"\"\n",
    "    logger.info(\"Preparing test dataset...\")\n",
    "    \n",
    "    transform = get_transform(config)\n",
    "    \n",
    "    # Load the dataset\n",
    "    try:\n",
    "        test_dataset = datasets.CIFAR10(\n",
    "            root=config.dataset_path,\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=transform\n",
    "        )\n",
    "        logger.info(f\"Test dataset loaded with {len(test_dataset)} samples\")\n",
    "        return test_dataset\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load dataset: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def get_original_images(config, indices):\n",
    "    \"\"\"Get original 32x32 images without transformations for display purposes\"\"\"\n",
    "    # Load dataset without transformations\n",
    "    orig_dataset = datasets.CIFAR10(\n",
    "        root=config.dataset_path,\n",
    "        train=False,\n",
    "        download=False\n",
    "    )\n",
    "    \n",
    "    originals = []\n",
    "    labels = []\n",
    "    \n",
    "    for idx in indices:\n",
    "        img, label = orig_dataset[idx]\n",
    "        # Handle the case where img is already a PIL Image\n",
    "        if isinstance(img, Image.Image):\n",
    "            # Just convert PIL Image to tensor directly\n",
    "            img_tensor = transforms.ToTensor()(img)\n",
    "        else:\n",
    "            # For numpy array format (older torchvision versions)\n",
    "            img = Image.fromarray(img)\n",
    "            img_tensor = transforms.ToTensor()(img)\n",
    "            \n",
    "        originals.append(img_tensor)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return originals, labels\n",
    "\n",
    "def create_data_loader(dataset, config):\n",
    "    \"\"\"Create a DataLoader with optimized settings\"\"\"\n",
    "    logger.info(f\"Creating DataLoader with batch size {config.batch_size}...\")\n",
    "    \n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=config.pin_memory,\n",
    "        persistent_workers=False,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    return loader\n",
    "\n",
    "####################################\n",
    "# 4. Model Loading\n",
    "####################################\n",
    "def load_model(config, model_path):\n",
    "    \"\"\"Load a baseline model from checkpoint\"\"\"\n",
    "    logger.info(f\"Loading model from: {model_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Create EfficientNet-B0 model architecture\n",
    "        model = models.efficientnet_b0(weights=None)\n",
    "        \n",
    "        # Modify classifier for CIFAR-10 (10 classes)\n",
    "        if hasattr(model, 'classifier'):\n",
    "            in_features = model.classifier[1].in_features\n",
    "            model.classifier[1] = torch.nn.Linear(in_features, 10)\n",
    "        \n",
    "        # Load checkpoint\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        \n",
    "        # Handle different checkpoint formats\n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint)\n",
    "        \n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        logger.info(f\"Model loaded successfully and set to evaluation mode\")\n",
    "        \n",
    "        # Extract model metadata if available\n",
    "        metadata = {}\n",
    "        if isinstance(checkpoint, dict):\n",
    "            if 'baseline_type' in checkpoint:\n",
    "                metadata['baseline_type'] = checkpoint['baseline_type']\n",
    "            if 'with_warmup' in checkpoint:\n",
    "                metadata['with_warmup'] = checkpoint['with_warmup']\n",
    "            if 'test_metrics' in checkpoint:\n",
    "                metadata['test_metrics'] = checkpoint['test_metrics']\n",
    "            if 'ece' in checkpoint:\n",
    "                metadata['ece'] = checkpoint['ece']\n",
    "            if 'config' in checkpoint:\n",
    "                metadata['config'] = checkpoint['config']\n",
    "        \n",
    "        return model, metadata\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load model: {str(e)}\")\n",
    "        logger.error(traceback.format_exc())\n",
    "        return None, {}\n",
    "\n",
    "####################################\n",
    "# 5. Inference\n",
    "####################################\n",
    "def run_inference(model, loader, config):\n",
    "    \"\"\"Run inference on the test set\"\"\"\n",
    "    logger.info(f\"Running inference...\")\n",
    "    \n",
    "    # Store predictions, targets and probabilities\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    clear_gpu_cache()\n",
    "    \n",
    "    # Disable gradient computation for inference\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(loader, desc=f\"Evaluating\"):\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            \n",
    "            # Use mixed precision if enabled\n",
    "            if config.use_amp and device.type == 'cuda':\n",
    "                with autocast(device_type='cuda'):\n",
    "                    outputs = model(images)\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "                \n",
    "            # Get probabilities and predictions\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(probs, dim=1)\n",
    "            \n",
    "            # Store results\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_probs = np.concatenate(all_probs)\n",
    "    \n",
    "    logger.info(f\"Inference complete on {len(all_targets)} samples\")\n",
    "    return all_targets, all_preds, all_probs\n",
    "\n",
    "####################################\n",
    "# 6. Evaluation Metrics\n",
    "####################################\n",
    "def compute_ece(probs, targets, n_bins=10):\n",
    "    \"\"\"Compute Expected Calibration Error (ECE)\"\"\"\n",
    "    # Get the predicted class and its confidence\n",
    "    confidences = np.max(probs, axis=1)\n",
    "    predictions = np.argmax(probs, axis=1)\n",
    "    accuracies = (predictions == targets).astype(np.float32)\n",
    "    \n",
    "    # Sort by confidence\n",
    "    sorted_indices = np.argsort(confidences)\n",
    "    sorted_confidences = confidences[sorted_indices]\n",
    "    sorted_accuracies = accuracies[sorted_indices]\n",
    "    \n",
    "    # Create bins\n",
    "    bin_size = 1.0 / n_bins\n",
    "    bins = np.linspace(0, 1.0, n_bins+1)\n",
    "    ece = 0.0\n",
    "    \n",
    "    bin_confidences = []\n",
    "    bin_accuracies = []\n",
    "    bin_counts = []\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        # Determine bin boundaries\n",
    "        bin_start = bins[i]\n",
    "        bin_end = bins[i+1]\n",
    "        \n",
    "        # Find samples in bin\n",
    "        in_bin = (sorted_confidences >= bin_start) & (sorted_confidences < bin_end)\n",
    "        bin_count = np.sum(in_bin)\n",
    "        bin_counts.append(bin_count)\n",
    "        \n",
    "        if bin_count > 0:\n",
    "            bin_confidence = np.mean(sorted_confidences[in_bin])\n",
    "            bin_accuracy = np.mean(sorted_accuracies[in_bin])\n",
    "            \n",
    "            # Weight ECE contribution by bin size\n",
    "            ece += (bin_count / len(probs)) * np.abs(bin_accuracy - bin_confidence)\n",
    "            \n",
    "            bin_confidences.append(bin_confidence)\n",
    "            bin_accuracies.append(bin_accuracy)\n",
    "        else:\n",
    "            # For empty bins, use bin center as confidence and 0 as accuracy\n",
    "            bin_confidences.append((bin_start + bin_end) / 2)\n",
    "            bin_accuracies.append(0)\n",
    "    \n",
    "    return ece, bin_confidences, bin_accuracies, bin_counts\n",
    "\n",
    "def compute_extended_calibration_metrics(probs, targets, n_bins=10):\n",
    "    \"\"\"\n",
    "    Compute comprehensive calibration metrics:\n",
    "    - ECE: Expected Calibration Error\n",
    "    - MCE: Maximum Calibration Error\n",
    "    - ACE: Average Calibration Error \n",
    "    - RMSCE: Root Mean Squared Calibration Error\n",
    "    \"\"\"\n",
    "    confidences = np.max(probs, axis=1)\n",
    "    predictions = np.argmax(probs, axis=1)\n",
    "    accuracies = (predictions == targets).astype(np.float32)\n",
    "    \n",
    "    # Create bins\n",
    "    bins = np.linspace(0, 1.0, n_bins+1)\n",
    "    bin_errors = []\n",
    "    bin_weights = []\n",
    "    \n",
    "    # Calculate per-bin metrics\n",
    "    for i in range(n_bins):\n",
    "        bin_start = bins[i]\n",
    "        bin_end = bins[i+1]\n",
    "        \n",
    "        in_bin = (confidences >= bin_start) & (confidences < bin_end)\n",
    "        bin_count = np.sum(in_bin)\n",
    "        \n",
    "        if bin_count > 0:\n",
    "            bin_accuracy = np.mean(accuracies[in_bin])\n",
    "            bin_confidence = np.mean(confidences[in_bin])\n",
    "            \n",
    "            bin_error = np.abs(bin_accuracy - bin_confidence)\n",
    "            bin_weight = bin_count / len(probs)\n",
    "            \n",
    "            bin_errors.append(bin_error)\n",
    "            bin_weights.append(bin_weight)\n",
    "        else:\n",
    "            bin_errors.append(0)\n",
    "            bin_weights.append(0)\n",
    "    \n",
    "    # Calculate ECE (Expected Calibration Error)\n",
    "    ece = np.sum(np.array(bin_errors) * np.array(bin_weights))\n",
    "    \n",
    "    # Calculate MCE (Maximum Calibration Error)\n",
    "    mce = np.max(bin_errors) if bin_errors else 0.0\n",
    "    \n",
    "    # Calculate ACE (Average Calibration Error)\n",
    "    non_empty_bins = [i for i, w in enumerate(bin_weights) if w > 0]\n",
    "    ace = np.mean([bin_errors[i] for i in non_empty_bins]) if non_empty_bins else 0.0\n",
    "    \n",
    "    # Calculate RMSCE (Root Mean Squared Calibration Error)\n",
    "    rmsce = np.sqrt(np.sum(np.array(bin_weights) * np.array(bin_errors) ** 2))\n",
    "    \n",
    "    return {\n",
    "        'ece': ece,\n",
    "        'mce': mce,\n",
    "        'ace': ace,\n",
    "        'rmsce': rmsce,\n",
    "        'bin_errors': bin_errors,\n",
    "        'bin_weights': bin_weights\n",
    "    }\n",
    "\n",
    "def analyze_results(y_true, y_pred, y_probs, class_names, config, model_name=\"baseline\"):\n",
    "    \"\"\"Generate and save evaluation metrics\"\"\"\n",
    "    logger.info(f\"Analyzing {model_name} model performance...\")\n",
    "    \n",
    "    # Create output directory for this model\n",
    "    model_output_dir = os.path.join(config.output_dir, model_name)\n",
    "    os.makedirs(model_output_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Calculate and print accuracy\n",
    "    accuracy = np.mean(y_true == y_pred) * 100\n",
    "    logger.info(f\"[{model_name}] Test Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    # 2. Calculate F1 score, precision, and recall\n",
    "    f1 = f1_score(y_true, y_pred, average='macro') * 100\n",
    "    precision = precision_score(y_true, y_pred, average='macro') * 100\n",
    "    recall = recall_score(y_true, y_pred, average='macro') * 100\n",
    "    logger.info(f\"[{model_name}] F1 Score (macro): {f1:.2f}%\")\n",
    "    logger.info(f\"[{model_name}] Precision (macro): {precision:.2f}%\")\n",
    "    logger.info(f\"[{model_name}] Recall (macro): {recall:.2f}%\")\n",
    "    \n",
    "    # 3. Calculate Extended Calibration Metrics\n",
    "    cal_metrics = compute_extended_calibration_metrics(y_probs, y_true, n_bins=config.n_bins_calibration)\n",
    "    logger.info(f\"[{model_name}] Expected Calibration Error (ECE): {cal_metrics['ece']:.4f}\")\n",
    "    logger.info(f\"[{model_name}] Maximum Calibration Error (MCE): {cal_metrics['mce']:.4f}\")\n",
    "    logger.info(f\"[{model_name}] Average Calibration Error (ACE): {cal_metrics['ace']:.4f}\")\n",
    "    logger.info(f\"[{model_name}] Root Mean Squared Cal. Error (RMSCE): {cal_metrics['rmsce']:.4f}\")\n",
    "    \n",
    "    # 4. Generate confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f\"Confusion Matrix - {model_name} (Accuracy: {accuracy:.2f}%)\")\n",
    "    plt.xlabel(\"Predicted Class\")\n",
    "    plt.ylabel(\"True Class\")\n",
    "    plt.savefig(f\"{model_output_dir}/confusion_matrix.png\", dpi=config.plot_dpi)\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. Generate classification report\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names, digits=3)\n",
    "    logger.info(f\"\\n[{model_name}] Classification Report:\")\n",
    "    logger.info(report)\n",
    "    \n",
    "    # Save report to file\n",
    "    with open(f\"{model_output_dir}/classification_report.txt\", \"w\") as f:\n",
    "        f.write(f\"Model: {model_name}\\n\")\n",
    "        f.write(f\"Test Accuracy: {accuracy:.2f}%\\n\")\n",
    "        f.write(f\"F1 Score (macro): {f1:.2f}%\\n\")\n",
    "        f.write(f\"Precision (macro): {precision:.2f}%\\n\")\n",
    "        f.write(f\"Recall (macro): {recall:.2f}%\\n\")\n",
    "        f.write(f\"Expected Calibration Error: {cal_metrics['ece']:.4f}\\n\")\n",
    "        f.write(f\"Maximum Calibration Error: {cal_metrics['mce']:.4f}\\n\")\n",
    "        f.write(f\"Average Calibration Error: {cal_metrics['ace']:.4f}\\n\")\n",
    "        f.write(f\"Root Mean Squared Cal. Error: {cal_metrics['rmsce']:.4f}\\n\\n\")\n",
    "        f.write(report)\n",
    "    \n",
    "    # 6. Per-class accuracy\n",
    "    class_acc = cm.diagonal() / cm.sum(axis=1) * 100\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(x=list(class_names), y=class_acc)\n",
    "    \n",
    "    # Add value labels on top of bars\n",
    "    for i, v in enumerate(class_acc):\n",
    "        ax.text(i, v + 1, f\"{v:.1f}%\", ha='center', fontsize=9)\n",
    "        \n",
    "    plt.title(f\"{model_name}: Per-Class Accuracy\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.ylim(0, 105)  # Add space for labels\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.savefig(f\"{model_output_dir}/per_class_accuracy.png\", dpi=config.plot_dpi)\n",
    "    plt.close()\n",
    "    \n",
    "    # 7. Plot calibration reliability diagram\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Plot perfect calibration line\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n",
    "    \n",
    "    # Get calibration data\n",
    "    ece, bin_confs, bin_accs, bin_counts = compute_ece(y_probs, y_true, n_bins=config.n_bins_calibration)\n",
    "    \n",
    "    # Plot bins with their accuracies\n",
    "    bin_edges = np.linspace(0, 1, config.n_bins_calibration + 1)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    bin_counts_norm = np.array(bin_counts) / sum(bin_counts)\n",
    "    \n",
    "    plt.bar(bin_centers, bin_accs, width=1/config.n_bins_calibration, alpha=0.3, label='Accuracy in bin')\n",
    "    \n",
    "    # Create a twin axis plot for sample distribution\n",
    "    twin_ax = plt.twinx()\n",
    "    twin_ax.bar(bin_centers, bin_counts_norm, width=1/config.n_bins_calibration, alpha=0.2, color='g', label='Proportion of samples')\n",
    "    twin_ax.set_ylabel('Proportion of Samples')\n",
    "    \n",
    "    # Connect actual calibration points\n",
    "    plt.plot(bin_confs, bin_accs, 'ro-', label=f'Actual Calibration (ECE={ece:.4f})')\n",
    "    \n",
    "    plt.title(f'{model_name} - Calibration Reliability Diagram')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.savefig(f\"{model_output_dir}/calibration_curve.png\", dpi=config.plot_dpi)\n",
    "    plt.close()\n",
    "    \n",
    "    # 8. Save all metrics as a dictionary\n",
    "    metrics = {\n",
    "        'model_name': model_name,\n",
    "        'accuracy': float(accuracy),\n",
    "        'f1_score': float(f1),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'ece': float(cal_metrics['ece']),\n",
    "        'mce': float(cal_metrics['mce']),\n",
    "        'ace': float(cal_metrics['ace']),\n",
    "        'rmsce': float(cal_metrics['rmsce']),\n",
    "        'per_class_accuracy': [float(acc) for acc in class_acc.tolist()]\n",
    "    }\n",
    "    \n",
    "    # Save metrics as JSON\n",
    "    with open(f\"{model_output_dir}/metrics.json\", \"w\") as f:\n",
    "        json.dump(to_serializable(metrics), f, indent=4)\n",
    "    \n",
    "    logger.info(f\"[{model_name}] Evaluation results saved to {model_output_dir}\")\n",
    "    return metrics\n",
    "\n",
    "def compare_models(all_metrics, config):\n",
    "    \"\"\"Create comparison visualizations between the two baseline approaches\"\"\"\n",
    "    logger.info(\"Generating model comparison visualizations...\")\n",
    "    \n",
    "    if len(all_metrics) <= 1:\n",
    "        logger.info(\"Not enough models to compare.\")\n",
    "        return\n",
    "    \n",
    "    # Extract model names and metrics\n",
    "    model_names = [metrics['model_name'] for metrics in all_metrics]\n",
    "    accuracies = [metrics['accuracy'] for metrics in all_metrics]\n",
    "    f1_scores = [metrics['f1_score'] for metrics in all_metrics]\n",
    "    precisions = [metrics['precision'] for metrics in all_metrics]\n",
    "    recalls = [metrics['recall'] for metrics in all_metrics]\n",
    "    eces = [metrics['ece'] for metrics in all_metrics]\n",
    "    \n",
    "    # Advanced calibration metrics\n",
    "    mces = [metrics['mce'] if 'mce' in metrics else 0 for metrics in all_metrics]\n",
    "    aces = [metrics['ace'] if 'ace' in metrics else 0 for metrics in all_metrics]\n",
    "    rmsces = [metrics['rmsce'] if 'rmsce' in metrics else 0 for metrics in all_metrics]\n",
    "    \n",
    "    # Set colors for models\n",
    "    colors = ['#1f77b4', '#ff7f0e']  # Blue and orange for ML and ED baselines\n",
    "    \n",
    "    # 1. Accuracy comparison\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = plt.subplot(111)\n",
    "    bars = ax.bar(model_names, accuracies, color=colors)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f\"{height:.2f}%\", ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.title('Accuracy Comparison of Baseline Approaches')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.ylim(0, max(accuracies) + 5)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{config.output_dir}/accuracy_comparison.png\", dpi=config.plot_dpi)\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. F1, Precision, Recall comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(model_names))\n",
    "    width = 0.25\n",
    "    \n",
    "    ax = plt.subplot(111)\n",
    "    bars1 = ax.bar(x - width, f1_scores, width, label='F1 Score', alpha=0.7)\n",
    "    bars2 = ax.bar(x, precisions, width, label='Precision', alpha=0.7)\n",
    "    bars3 = ax.bar(x + width, recalls, width, label='Recall', alpha=0.7)\n",
    "    \n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(model_names)\n",
    "    ax.set_ylabel('Score (%)')\n",
    "    ax.set_title('F1, Precision, and Recall Comparison')\n",
    "    ax.legend()\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{config.output_dir}/f1_precision_recall_comparison.png\", dpi=config.plot_dpi)\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Calibration metrics comparison (lower is better)\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Create subplots for different calibration metrics\n",
    "    plt.subplot(2, 2, 1)\n",
    "    bars = plt.bar(model_names, eces, color=colors)\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.0005,\n",
    "                f\"{height:.4f}\", ha='center', va='bottom', fontsize=9)\n",
    "    plt.title('Expected Calibration Error (ECE)')\n",
    "    plt.ylabel('Error (lower is better)')\n",
    "    plt.ylim(0, max(eces) * 1.2)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    bars = plt.bar(model_names, mces, color=colors)\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.0005,\n",
    "                f\"{height:.4f}\", ha='center', va='bottom', fontsize=9)\n",
    "    plt.title('Maximum Calibration Error (MCE)')\n",
    "    plt.ylabel('Error (lower is better)')\n",
    "    plt.ylim(0, max(mces) * 1.2)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    bars = plt.bar(model_names, aces, color=colors)\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.0005,\n",
    "                f\"{height:.4f}\", ha='center', va='bottom', fontsize=9)\n",
    "    plt.title('Average Calibration Error (ACE)')\n",
    "    plt.ylabel('Error (lower is better)')\n",
    "    plt.ylim(0, max(aces) * 1.2)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    bars = plt.bar(model_names, rmsces, color=colors)\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.0005,\n",
    "                f\"{height:.4f}\", ha='center', va='bottom', fontsize=9)\n",
    "    plt.title('Root Mean Squared Calibration Error (RMSCE)')\n",
    "    plt.ylabel('Error (lower is better)')\n",
    "    plt.ylim(0, max(rmsces) * 1.2)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Calibration Metrics Comparison (Lower is Better)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.savefig(f\"{config.output_dir}/calibration_metrics_comparison.png\", dpi=config.plot_dpi)\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Radar chart for all metrics\n",
    "    metrics_names = ['Accuracy', 'F1 Score', 'Precision', 'Recall', \n",
    "                    'Calibration (1-ECE)', 'Calibration (1-MCE)']\n",
    "    \n",
    "    # Normalize metrics to 0-1 range\n",
    "    norm_accuracies = [acc/100 for acc in accuracies]\n",
    "    norm_f1s = [f1/100 for f1 in f1_scores]\n",
    "    norm_precisions = [prec/100 for prec in precisions]\n",
    "    norm_recalls = [rec/100 for rec in recalls]\n",
    "    \n",
    "    # Invert calibration metrics (so higher is better)\n",
    "    norm_eces = [1 - min(ece, 1.0) for ece in eces]\n",
    "    norm_mces = [1 - min(mce, 1.0) for mce in mces]\n",
    "    \n",
    "    # Create radar chart\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, polar=True)\n",
    "    \n",
    "    # Set angles for radar chart\n",
    "    angles = np.linspace(0, 2*np.pi, len(metrics_names), endpoint=False).tolist()\n",
    "    angles += angles[:1]  # Close the loop\n",
    "    \n",
    "    # Plot each model's metrics\n",
    "    for i, model_name in enumerate(model_names):\n",
    "        values = [norm_accuracies[i], norm_f1s[i], norm_precisions[i], \n",
    "                 norm_recalls[i], norm_eces[i], norm_mces[i]]\n",
    "        values += values[:1]  # Close the loop\n",
    "        \n",
    "        ax.plot(angles, values, 'o-', linewidth=2, \n",
    "               label=model_name, color=colors[i])\n",
    "        ax.fill(angles, values, alpha=0.1, color=colors[i])\n",
    "    \n",
    "    # Set chart properties\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(metrics_names)\n",
    "    ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'])\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # Add legend and title\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "    plt.title(\"Baseline Approaches Performance Comparison\", size=15, pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{config.output_dir}/radar_chart_comparison.png\", dpi=config.plot_dpi)\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. Calibration curve comparison\n",
    "    plot_calibration_curves_comparison(all_metrics, config)\n",
    "    \n",
    "    # Save comparison metrics as JSON\n",
    "    comparison = {\n",
    "        'models': model_names,\n",
    "        'accuracy': accuracies,\n",
    "        'f1_score': f1_scores,\n",
    "        'precision': precisions,\n",
    "        'recall': recalls,\n",
    "        'ece': eces,\n",
    "        'mce': mces, \n",
    "        'ace': aces,\n",
    "        'rmsce': rmsces\n",
    "    }\n",
    "    \n",
    "    with open(f\"{config.output_dir}/model_comparison.json\", \"w\") as f:\n",
    "        json.dump(to_serializable(comparison), f, indent=4)\n",
    "    \n",
    "    logger.info(f\"Model comparison visualizations saved to {config.output_dir}\")\n",
    "\n",
    "def plot_calibration_curves_comparison(all_metrics, config):\n",
    "    \"\"\"Plot calibration curves for the two baseline approaches in one figure\"\"\"\n",
    "    logger.info(\"Generating combined calibration curve comparison...\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Perfect calibration line\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n",
    "    \n",
    "    # Define colors\n",
    "    colors = ['#1f77b4', '#ff7f0e']  # Blue and orange\n",
    "    \n",
    "    # For each model, get the probabilities and targets, then plot calibration curve\n",
    "    for i, metrics in enumerate(all_metrics):\n",
    "        model_name = metrics['model_name']\n",
    "        model_path = os.path.join(config.output_dir, model_name)\n",
    "        \n",
    "        # Load the calibration data\n",
    "        try:\n",
    "            with open(f\"{model_path}/metrics.json\", 'r') as f:\n",
    "                data = json.load(f)\n",
    "                ece = data['ece']\n",
    "        except:\n",
    "            ece = metrics['ece']\n",
    "        \n",
    "        # Load pre-computed calibration curve data if available\n",
    "        curve_file = os.path.join(model_path, \"calibration_data.json\")\n",
    "        if os.path.exists(curve_file):\n",
    "            with open(curve_file, 'r') as f:\n",
    "                cal_data = json.load(f)\n",
    "                bin_confs = cal_data['bin_confidences']\n",
    "                bin_accs = cal_data['bin_accuracies']\n",
    "        else:\n",
    "            # Otherwise load from the model directly\n",
    "            test_dataset = get_test_dataset(config)\n",
    "            test_loader = create_data_loader(test_dataset, config)\n",
    "            \n",
    "            if model_name == \"baseline_ed\":\n",
    "                model, _ = load_model(config, config.ed_model_path)\n",
    "            else:\n",
    "                model, _ = load_model(config, config.ml_model_path)\n",
    "                \n",
    "            all_targets, all_preds, all_probs = run_inference(model, test_loader, config)\n",
    "            ece, bin_confs, bin_accs, _ = compute_ece(all_probs, all_targets, n_bins=config.n_bins_calibration)\n",
    "        \n",
    "        # Plot calibration points\n",
    "        plt.plot(bin_confs, bin_accs, 'o-', linewidth=2,\n",
    "                label=f'{model_name} (ECE={ece:.4f})', color=colors[i])\n",
    "    \n",
    "    # Add legend, labels, and grid\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Calibration Reliability Comparison')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{config.output_dir}/calibration_curves_comparison.png\", dpi=config.plot_dpi)\n",
    "    plt.savefig(f\"{config.output_dir}/calibration_curves_comparison.pdf\", format='pdf')\n",
    "    plt.close()\n",
    "    \n",
    "    logger.info(\"Calibration curve comparison saved successfully\")\n",
    "\n",
    "####################################\n",
    "# 7. Visualization Helpers\n",
    "####################################\n",
    "def visualize_predictions(model, test_dataset, config, model_name=\"baseline\"):\n",
    "    \"\"\"Visualize random predictions with original CIFAR-10 images\"\"\"\n",
    "    logger.info(f\"Generating prediction visualizations for {model_name}...\")\n",
    "    \n",
    "    # Use a professional style\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'sans-serif',\n",
    "        'font.sans-serif': ['Arial', 'Helvetica', 'DejaVu Sans'],\n",
    "        'font.size': 9,\n",
    "        'axes.titlesize': 10,\n",
    "        'axes.labelsize': 9\n",
    "    })\n",
    "    \n",
    "    # Define colors for correct and incorrect predictions\n",
    "    correct_color = '#1f77b4'  # Professional blue\n",
    "    incorrect_color = '#d62728'  # Professional red\n",
    "    \n",
    "    # Number of examples per class to show\n",
    "    num_examples = 3\n",
    "    \n",
    "    # Select random indices\n",
    "    indices = np.random.choice(len(test_dataset), size=num_examples*len(config.classes), replace=False)\n",
    "    \n",
    "    # Get original images and labels\n",
    "    originals, true_labels = get_original_images(config, indices)\n",
    "    \n",
    "    # Prepare a batch of transformed images for the model\n",
    "    batch_images = torch.stack([test_dataset[idx][0] for idx in indices]).to(device)\n",
    "    \n",
    "    # Get predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if config.use_amp and device.type == 'cuda':\n",
    "            with autocast(device_type='cuda'):\n",
    "                outputs = model(batch_images)\n",
    "        else:\n",
    "            outputs = model(batch_images)\n",
    "    \n",
    "    # Get prediction probabilities and classes\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    pred_scores, pred_labels = torch.max(probs, dim=1)\n",
    "    \n",
    "    # Convert to numpy\n",
    "    pred_labels = pred_labels.cpu().numpy()\n",
    "    pred_scores = pred_scores.cpu().numpy()\n",
    "    true_labels = np.array(true_labels)\n",
    "    \n",
    "    # Plot results\n",
    "    fig, axes = plt.subplots(len(config.classes), num_examples, figsize=(num_examples*2.5, len(config.classes)*2))\n",
    "    fig.suptitle(f\"CIFAR-10 Prediction Examples ({model_name})\", fontsize=14, y=0.98)\n",
    "    \n",
    "    # Group samples by true class\n",
    "    class_indices = {i: [] for i in range(len(config.classes))}\n",
    "    for i, label in enumerate(true_labels):\n",
    "        if len(class_indices[label]) < num_examples:\n",
    "            class_indices[label].append(i)\n",
    "    \n",
    "    # Plot examples\n",
    "    for class_idx in range(len(config.classes)):\n",
    "        for example_idx in range(num_examples):\n",
    "            if example_idx < len(class_indices[class_idx]):\n",
    "                idx = class_indices[class_idx][example_idx]\n",
    "                \n",
    "                # Get original image\n",
    "                img = originals[idx].permute(1, 2, 0).numpy()\n",
    "                \n",
    "                # Get true and predicted labels\n",
    "                true_label = true_labels[idx]\n",
    "                pred_label = pred_labels[idx]\n",
    "                conf = pred_scores[idx] * 100\n",
    "                \n",
    "                # Determine if prediction is correct\n",
    "                is_correct = (true_label == pred_label)\n",
    "                title_color = correct_color if is_correct else incorrect_color\n",
    "                \n",
    "                # Plot image\n",
    "                ax = axes[class_idx, example_idx]\n",
    "                ax.imshow(img)\n",
    "                ax.set_title(f\"True: {config.classes[true_label]}\\nPred: {config.classes[pred_label]} ({conf:.1f}%)\", \n",
    "                             color=title_color, fontsize=8)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "            else:\n",
    "                # Hide empty subplot\n",
    "                axes[class_idx, example_idx].axis('off')\n",
    "    \n",
    "    # Add row labels on the left\n",
    "    for class_idx in range(len(config.classes)):\n",
    "        axes[class_idx, 0].set_ylabel(config.classes[class_idx], rotation=45, fontsize=10)\n",
    "    \n",
    "    # Add a footer with model information\n",
    "    plt.figtext(0.5, 0.01, \n",
    "               f\"Baseline EfficientNetB0 model ({model_name}) evaluation on CIFAR-10 test set\", \n",
    "               ha=\"center\", fontsize=10, style='italic')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.95, bottom=0.05)\n",
    "    \n",
    "    # Save the figure\n",
    "    output_dir = os.path.join(config.output_dir, model_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.savefig(f\"{output_dir}/prediction_examples.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    logger.info(f\"Prediction visualizations saved to {output_dir}/prediction_examples.png\")\n",
    "\n",
    "####################################\n",
    "# 8. GradCAM Implementation\n",
    "####################################\n",
    "class GradCAM:\n",
    "    \"\"\"Gradient-weighted Class Activation Mapping\"\"\"\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.activations = None\n",
    "        self.gradients = None\n",
    "        self.hook_handles = []\n",
    "        self._register_hooks()\n",
    "    \n",
    "    def _register_hooks(self):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output\n",
    "        \n",
    "        def backward_hook(module, grad_input, grad_output):\n",
    "            self.gradients = grad_output[0]\n",
    "        \n",
    "        # Register hooks\n",
    "        self.hook_handles.append(self.target_layer.register_forward_hook(forward_hook))\n",
    "        self.hook_handles.append(self.target_layer.register_full_backward_hook(backward_hook))\n",
    "    \n",
    "    def generate_cam(self, input_tensor, target_class=None):\n",
    "        # Forward pass\n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        # Get prediction if target class not specified\n",
    "        if target_class is None:\n",
    "            output = self.model(input_tensor)\n",
    "            target_class = torch.argmax(output, dim=1).item()\n",
    "        \n",
    "        # Forward pass with gradients\n",
    "        output = self.model(input_tensor)\n",
    "        loss = output[:, target_class].sum()\n",
    "        \n",
    "        # Backward pass\n",
    "        self.model.zero_grad()\n",
    "        loss.backward(retain_graph=False)\n",
    "        \n",
    "        # Generate CAM\n",
    "        weights = self.gradients.mean(dim=(2, 3), keepdim=True)\n",
    "        cam = (weights * self.activations).sum(dim=1, keepdim=True)\n",
    "        cam = torch.relu(cam)\n",
    "        \n",
    "        # Upsample CAM to input size\n",
    "        cam = torch.nn.functional.interpolate(\n",
    "            cam, \n",
    "            size=input_tensor.shape[2:], \n",
    "            mode='bilinear', \n",
    "            align_corners=False\n",
    "        )\n",
    "        \n",
    "        # Normalize CAM\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
    "        \n",
    "        return cam\n",
    "    \n",
    "    def remove_hooks(self):\n",
    "        for handle in self.hook_handles:\n",
    "            handle.remove()\n",
    "        self.hook_handles = []\n",
    "\n",
    "def visualize_gradcam(model, test_dataset, config, device, model_name=\"baseline\"):\n",
    "    \"\"\"Create GradCAM visualizations for each class with improved scientific appearance\"\"\"\n",
    "    logger.info(f\"Generating GradCAM visualizations for {model_name}...\")\n",
    "    \n",
    "    # Set scientific plotting style\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'sans-serif',\n",
    "        'font.sans-serif': ['Arial', 'Helvetica', 'DejaVu Sans'],\n",
    "        'font.size': 10,\n",
    "        'axes.titlesize': 11,\n",
    "        'axes.labelsize': 10\n",
    "    })\n",
    "    \n",
    "    # Find one sample per class\n",
    "    samples_by_class = {c: None for c in range(len(config.classes))}\n",
    "    indices_by_class = {c: None for c in range(len(config.classes))}\n",
    "    \n",
    "    for idx in tqdm(range(len(test_dataset)), desc=\"Finding class samples\"):\n",
    "        _, label = test_dataset[idx]\n",
    "        if samples_by_class[label] is None:\n",
    "            samples_by_class[label] = test_dataset[idx][0].unsqueeze(0)\n",
    "            indices_by_class[label] = idx\n",
    "        if all(v is not None for v in samples_by_class.values()):\n",
    "            break\n",
    "    \n",
    "    # Initialize GradCAM with the appropriate layer for EfficientNetB0\n",
    "    # For EfficientNetB0, we target the last feature block\n",
    "    target_layer = model.features[-1]\n",
    "    grad_cam = GradCAM(model, target_layer)\n",
    "    \n",
    "    # Use a scientific colormap\n",
    "    cmap = 'inferno'  # Scientific colormap that works well for heatmaps\n",
    "    \n",
    "    # Create a figure without tight_layout to avoid colorbar layout issues\n",
    "    fig = plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # Create GridSpec for better layout control\n",
    "    gs = fig.add_gridspec(4, 6)\n",
    "    \n",
    "    # Add title\n",
    "    fig.suptitle(f\"GradCAM Visualizations for CIFAR-10 Classes ({model_name})\", \n",
    "                fontsize=14, y=0.98)\n",
    "    \n",
    "    # Create a mapping for 2x5 grid with proper organization\n",
    "    class_to_position = {\n",
    "        0: (0, 0),  # airplane\n",
    "        1: (0, 1),  # automobile\n",
    "        2: (0, 2),  # bird\n",
    "        3: (0, 3),  # cat\n",
    "        4: (0, 4),  # deer\n",
    "        5: (2, 0),  # dog\n",
    "        6: (2, 1),  # frog\n",
    "        7: (2, 2),  # horse\n",
    "        8: (2, 3),  # ship\n",
    "        9: (2, 4),  # truck\n",
    "    }\n",
    "    \n",
    "    # Variable to store the last heatmap for colorbar reference\n",
    "    last_heatmap = None\n",
    "    \n",
    "    for class_idx in range(len(config.classes)):\n",
    "        logger.info(f\"Generating GradCAM for class '{config.classes[class_idx]}'\")\n",
    "        \n",
    "        # Get the sample\n",
    "        input_tensor = samples_by_class[class_idx].to(device)\n",
    "        \n",
    "        # Generate CAM\n",
    "        cam = grad_cam.generate_cam(input_tensor, target_class=class_idx)\n",
    "        # Use detach() before converting to numpy to avoid gradient error\n",
    "        cam = cam.detach().cpu().numpy()[0, 0]\n",
    "        \n",
    "        # Get original image\n",
    "        orig_imgs, _ = get_original_images(config, [indices_by_class[class_idx]])\n",
    "        orig_img = orig_imgs[0].permute(1, 2, 0).numpy()\n",
    "        \n",
    "        # Upsample original image to match model input size (224x224)\n",
    "        img_upsampled = transforms.Resize(config.input_size)(orig_imgs[0])\n",
    "        img_upsampled = img_upsampled.permute(1, 2, 0).numpy()\n",
    "        \n",
    "        # Get row, col position\n",
    "        row, col = class_to_position[class_idx]\n",
    "        \n",
    "        # Plot original image\n",
    "        ax_orig = fig.add_subplot(gs[row, col])\n",
    "        ax_orig.imshow(img_upsampled)\n",
    "        ax_orig.set_title(f\"{config.classes[class_idx]} (Original)\", fontsize=11)\n",
    "        ax_orig.set_xticks([])\n",
    "        ax_orig.set_yticks([])\n",
    "        \n",
    "        # Plot heatmap overlay\n",
    "        ax_overlay = fig.add_subplot(gs[row+1, col])\n",
    "        ax_overlay.imshow(img_upsampled)\n",
    "        last_heatmap = ax_overlay.imshow(cam, cmap=cmap, alpha=0.6)\n",
    "        ax_overlay.set_title(f\"{config.classes[class_idx]} (GradCAM)\", fontsize=11)\n",
    "        ax_overlay.set_xticks([])\n",
    "        ax_overlay.set_yticks([])\n",
    "    \n",
    "    # Add a colorbar for the heatmap - use a specific position that won't conflict\n",
    "    cax = fig.add_subplot(gs[:, 5])  # Use the last column for colorbar\n",
    "    cbar = fig.colorbar(last_heatmap, cax=cax)\n",
    "    cbar.set_label('Activation Strength', fontsize=10)\n",
    "    \n",
    "    # Add a footer with model information\n",
    "    fig.text(0.5, 0.01, \n",
    "                \"GradCAM visualizations show regions the model focuses on when classifying each category\",\n",
    "                ha=\"center\", fontsize=10, style='italic')\n",
    "    \n",
    "    # Adjust spacing - don't use tight_layout here\n",
    "    fig.subplots_adjust(right=0.9, top=0.95, bottom=0.05, wspace=0.3, hspace=0.3)\n",
    "    \n",
    "    # Save figure\n",
    "    output_dir = os.path.join(config.output_dir, model_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.savefig(f\"{output_dir}/gradcam_visualization.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Clean up\n",
    "    grad_cam.remove_hooks()\n",
    "    \n",
    "    logger.info(f\"GradCAM visualizations saved to {output_dir}/gradcam_visualization.png\")\n",
    "\n",
    "####################################\n",
    "# 9. Advanced Visualization Helpers\n",
    "####################################\n",
    "def visualize_confidence_distribution(all_probs, all_targets, model_names, config):\n",
    "    \"\"\"Visualize confidence distributions across models\"\"\"\n",
    "    logger.info(\"Generating confidence distribution visualization...\")\n",
    "    \n",
    "    # Set IEEE style for better plots\n",
    "    if config.ieee_style:\n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "        plt.rcParams.update({\n",
    "            'font.family': 'serif',\n",
    "            'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "            'font.size': 10,\n",
    "            'axes.titlesize': 11,\n",
    "            'axes.labelsize': 10,\n",
    "            'xtick.labelsize': 9,\n",
    "            'ytick.labelsize': 9,\n",
    "            'legend.fontsize': 9,\n",
    "        })\n",
    "    \n",
    "    # Create figure with 2 subplots: histogram and violin plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Define colors for models\n",
    "    colors = {'baseline_ed': '#1f77b4', 'baseline_ml': '#ff7f0e'}\n",
    "    \n",
    "    # 1. Histogram plot\n",
    "    for i, (probs, name) in enumerate(zip(all_probs, model_names)):\n",
    "        # Get confidences (max probability for each prediction)\n",
    "        confidences = np.max(probs, axis=1)\n",
    "        \n",
    "        # Plot histogram\n",
    "        ax1.hist(confidences, bins=20, alpha=0.7, density=True, \n",
    "               label=f\"{name}\", color=colors.get(name, f'C{i}'))\n",
    "    \n",
    "    ax1.set_title('Confidence Distribution Histogram')\n",
    "    ax1.set_xlabel('Confidence')\n",
    "    ax1.set_ylabel('Density')\n",
    "    ax1.legend()\n",
    "    ax1.grid(alpha=0.3)\n",
    "    \n",
    "    # 2. Violin plot with Seaborn\n",
    "    confidence_data = []\n",
    "    \n",
    "    for i, (probs, targets, name) in enumerate(zip(all_probs, all_targets, model_names)):\n",
    "        # Get confidences\n",
    "        confidences = np.max(probs, axis=1) * 100\n",
    "        \n",
    "        # Check if predictions are correct\n",
    "        predictions = np.argmax(probs, axis=1)\n",
    "        is_correct = predictions == targets\n",
    "        \n",
    "        # Add each data point to the DataFrame\n",
    "        for conf, correct in zip(confidences, is_correct):\n",
    "            confidence_data.append({\n",
    "                'Model': name,\n",
    "                'Confidence (%)': conf,\n",
    "                'Correctness': 'Correct' if correct else 'Incorrect'\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    confidence_df = pd.DataFrame(confidence_data)\n",
    "    \n",
    "    # Create violin plot using Seaborn for better control\n",
    "    sns.violinplot(\n",
    "        x='Model', \n",
    "        y='Confidence (%)', \n",
    "        hue='Correctness',\n",
    "        data=confidence_df,\n",
    "        split=True,\n",
    "        inner='quartile',\n",
    "        ax=ax2,\n",
    "        palette={'Correct': '#2ca02c', 'Incorrect': '#d62728'}\n",
    "    )\n",
    "    \n",
    "    ax2.set_title('Confidence Distribution by Correctness')\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{config.output_dir}/confidence_distribution.png\", dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    logger.info(f\"Confidence distribution visualization saved to {config.output_dir}/confidence_distribution.png\")\n",
    "\n",
    "def visualize_calibration_details(all_probs, all_targets, model_names, config):\n",
    "    \"\"\"Create detailed calibration visualization with shaded error regions\"\"\"\n",
    "    logger.info(\"Generating detailed calibration visualization...\")\n",
    "    \n",
    "    # Set style for better scientific plots\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Colors\n",
    "    colors = {'baseline_ed': '#1f77b4', 'baseline_ml': '#ff7f0e'}\n",
    "    \n",
    "    # 1. Reliability diagram with shaded regions\n",
    "    ax1.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n",
    "    \n",
    "    for i, (probs, targets, name) in enumerate(zip(all_probs, model_names, model_names)):\n",
    "        # Calculate calibration data\n",
    "        ece, bin_confs, bin_accs, bin_counts = compute_ece(probs, targets, n_bins=config.n_bins_calibration)\n",
    "        \n",
    "        # Plot with shaded region for confidence\n",
    "        bin_confs = np.array(bin_confs)\n",
    "        bin_accs = np.array(bin_accs)\n",
    "        \n",
    "        color = colors.get(name, f'C{i}')\n",
    "        ax1.plot(bin_confs, bin_accs, 'o-', linewidth=2,\n",
    "               label=f'{name} (ECE={ece:.4f})', color=color)\n",
    "        \n",
    "        # Calculate standard error from binomial distribution\n",
    "        # Using confidence interval for classification accuracy\n",
    "        bin_counts = np.array(bin_counts)\n",
    "        non_empty_bins = bin_counts > 0\n",
    "        \n",
    "        if np.any(non_empty_bins):\n",
    "            # Standard error = sqrt(p*(1-p)/n) where p is accuracy\n",
    "            std_errors = np.zeros_like(bin_accs)\n",
    "            std_errors[non_empty_bins] = np.sqrt(\n",
    "                bin_accs[non_empty_bins] * (1 - bin_accs[non_empty_bins]) / bin_counts[non_empty_bins]\n",
    "            )\n",
    "            \n",
    "            # Plot shaded confidence region (95% confidence interval)\n",
    "            upper_bound = np.clip(bin_accs + 1.96 * std_errors, 0, 1)\n",
    "            lower_bound = np.clip(bin_accs - 1.96 * std_errors, 0, 1)\n",
    "            \n",
    "            ax1.fill_between(\n",
    "                bin_confs, lower_bound, upper_bound,\n",
    "                alpha=0.2, color=color\n",
    "            )\n",
    "    \n",
    "    ax1.set_title('Calibration Reliability Diagram with Confidence Intervals')\n",
    "    ax1.set_xlabel('Confidence')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlim(0, 1)\n",
    "    ax1.set_ylim(0, 1)\n",
    "    ax1.legend(loc='lower right')\n",
    "    ax1.grid(alpha=0.3)\n",
    "    \n",
    "    # 2. Calibration error bars\n",
    "    for i, (probs, targets, name) in enumerate(zip(all_probs, model_names, model_names)):\n",
    "        # Calculate calibration data\n",
    "        ece, bin_confs, bin_accs, bin_counts = compute_ece(probs, targets, n_bins=config.n_bins_calibration)\n",
    "        \n",
    "        # Calculate calibration error at each bin\n",
    "        bin_confs = np.array(bin_confs)\n",
    "        bin_accs = np.array(bin_accs)\n",
    "        cal_errors = np.abs(bin_confs - bin_accs)\n",
    "        \n",
    "        color = colors.get(name, f'C{i}')\n",
    "        ax2.bar(np.arange(len(bin_confs)) + (0.4 * i - 0.2), cal_errors, \n",
    "              width=0.4, alpha=0.7, label=name, color=color)\n",
    "    \n",
    "    ax2.set_title('Calibration Error by Confidence Bin')\n",
    "    ax2.set_xlabel('Confidence Bin')\n",
    "    ax2.set_ylabel('|Accuracy - Confidence|')\n",
    "    ax2.set_xticks(np.arange(len(bin_confs)))\n",
    "    ax2.set_xticklabels([f'{b:.1f}' for b in np.linspace(0.05, 0.95, config.n_bins_calibration)])\n",
    "    ax2.legend()\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{config.output_dir}/calibration_detailed.png\", dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    logger.info(f\"Detailed calibration visualization saved to {config.output_dir}/calibration_detailed.png\")\n",
    "\n",
    "def analyze_prediction_overlap(all_preds, all_targets, model_names, config):\n",
    "    \"\"\"Analyze and visualize prediction overlap between models\"\"\"\n",
    "    logger.info(\"Analyzing prediction overlap between models...\")\n",
    "    \n",
    "    # Only proceed if we have exactly 2 models (ED and ML)\n",
    "    if len(model_names) != 2:\n",
    "        logger.warning(f\"Expected 2 models, but got {len(model_names)}. Skipping prediction overlap analysis.\")\n",
    "        return\n",
    "    \n",
    "    # Extract data\n",
    "    ed_preds = all_preds[0]\n",
    "    ml_preds = all_preds[1]\n",
    "    targets = all_targets[0]  # Assuming all targets are the same\n",
    "    \n",
    "    # Calculate agreement\n",
    "    agreement = ed_preds == ml_preds\n",
    "    agreement_rate = np.mean(agreement) * 100\n",
    "    \n",
    "    # Calculate correctness for both models\n",
    "    ed_correct = ed_preds == targets\n",
    "    ml_correct = ml_preds == targets\n",
    "    \n",
    "    # Calculate statistics\n",
    "    both_correct = np.logical_and(ed_correct, ml_correct)\n",
    "    both_wrong = np.logical_and(~ed_correct, ~ml_correct)\n",
    "    ed_only_correct = np.logical_and(ed_correct, ~ml_correct)\n",
    "    ml_only_correct = np.logical_and(~ed_correct, ml_correct)\n",
    "    \n",
    "    # Calculate percentages\n",
    "    total = len(targets)\n",
    "    both_correct_pct = np.sum(both_correct) / total * 100\n",
    "    both_wrong_pct = np.sum(both_wrong) / total * 100\n",
    "    ed_only_correct_pct = np.sum(ed_only_correct) / total * 100\n",
    "    ml_only_correct_pct = np.sum(ml_only_correct) / total * 100\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # 1. Agreement pie chart\n",
    "    plt.subplot(1, 2, 1)\n",
    "    agreement_labels = ['Both Correct', 'Both Wrong', 'Only ED Correct', 'Only ML Correct']\n",
    "    agreement_values = [both_correct_pct, both_wrong_pct, ed_only_correct_pct, ml_only_correct_pct]\n",
    "    agreement_colors = ['#2ca02c', '#d62728', '#1f77b4', '#ff7f0e'] # green, red, blue, orange\n",
    "    \n",
    "    plt.pie(\n",
    "        agreement_values, \n",
    "        labels=agreement_labels,\n",
    "        autopct='%1.1f%%',\n",
    "        startangle=90,\n",
    "        colors=agreement_colors,\n",
    "        wedgeprops={'edgecolor': 'w', 'linewidth': 1}\n",
    "    )\n",
    "    plt.title('Prediction Agreement Analysis')\n",
    "    \n",
    "    # 2. Per-class agreement barplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    class_agreement = {}\n",
    "    \n",
    "    for c in range(len(config.classes)):\n",
    "        # Filter by class\n",
    "        class_indices = targets == c\n",
    "        if not np.any(class_indices):\n",
    "            class_agreement[c] = 0\n",
    "            continue\n",
    "            \n",
    "        # Calculate agreement for this class\n",
    "        class_agreement[c] = np.mean(agreement[class_indices]) * 100\n",
    "    \n",
    "    # Create bar plot\n",
    "    plt.bar(\n",
    "        [config.classes[c] for c in range(len(config.classes))],\n",
    "        [class_agreement[c] for c in range(len(config.classes))],\n",
    "        color='#1f77b4'\n",
    "    )\n",
    "    plt.title('Model Agreement by Class')\n",
    "    plt.ylabel('Agreement (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 100)\n",
    "    \n",
    "    # Add overall agreement rate as red line\n",
    "    plt.axhline(agreement_rate, color='r', linestyle='--', label=f'Overall: {agreement_rate:.1f}%')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{config.output_dir}/prediction_overlap.png\", dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Create text summary\n",
    "    summary = (\n",
    "        f\"Prediction Overlap Analysis\\n\"\n",
    "        f\"===========================\\n\"\n",
    "        f\"Overall agreement rate: {agreement_rate:.2f}%\\n\\n\"\n",
    "        f\"Both models correct: {both_correct_pct:.2f}%\\n\"\n",
    "        f\"Both models wrong: {both_wrong_pct:.2f}%\\n\"\n",
    "        f\"Only Ensemble Distillation correct: {ed_only_correct_pct:.2f}%\\n\"\n",
    "        f\"Only Mutual Learning correct: {ml_only_correct_pct:.2f}%\\n\\n\"\n",
    "        f\"Per-class agreement rates:\\n\"\n",
    "    )\n",
    "    \n",
    "    for c in range(len(config.classes)):\n",
    "        summary += f\"  {config.classes[c]}: {class_agreement[c]:.2f}%\\n\"\n",
    "    \n",
    "    with open(f\"{config.output_dir}/prediction_overlap.txt\", 'w') as f:\n",
    "        f.write(summary)\n",
    "    \n",
    "    logger.info(f\"Prediction overlap analysis saved to {config.output_dir}/prediction_overlap.png\")\n",
    "\n",
    "def analyze_misclassifications(all_probs, all_preds, all_targets, model_names, test_dataset, config):\n",
    "    \"\"\"Analyze most common misclassifications\"\"\"\n",
    "    logger.info(\"Analyzing misclassifications...\")\n",
    "    \n",
    "    # Create dataframes for misclassifications\n",
    "    misclass_dfs = []\n",
    "    \n",
    "    for i, (preds, targets, name) in enumerate(zip(all_preds, all_targets, model_names)):\n",
    "        # Find misclassifications\n",
    "        misclass_indices = np.where(preds != targets)[0]\n",
    "        \n",
    "        # Create dataframe\n",
    "        misclass_df = pd.DataFrame({\n",
    "            'model': name,\n",
    "            'index': misclass_indices,\n",
    "            'true_class': targets[misclass_indices],\n",
    "            'pred_class': preds[misclass_indices]\n",
    "        })\n",
    "        \n",
    "        misclass_dfs.append(misclass_df)\n",
    "    \n",
    "    # Combine dataframes\n",
    "    all_misclass = pd.concat(misclass_dfs)\n",
    "    \n",
    "    # Create confusion heatmaps for each model\n",
    "    for i, name in enumerate(model_names):\n",
    "        model_misclass = all_misclass[all_misclass['model'] == name]\n",
    "        \n",
    "        # Create confusion matrix\n",
    "        cm = confusion_matrix(\n",
    "            model_misclass['true_class'], \n",
    "            model_misclass['pred_class'], \n",
    "            labels=range(len(config.classes))\n",
    "        )\n",
    "        \n",
    "        # Normalize to get conditional probabilities\n",
    "        cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm_norm = np.nan_to_num(cm_norm)  # Replace NaNs with 0\n",
    "        \n",
    "        # Create heatmap\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(\n",
    "            cm_norm, \n",
    "            annot=True, \n",
    "            fmt='.2f', \n",
    "            cmap='YlOrRd',\n",
    "            xticklabels=config.classes,\n",
    "            yticklabels=config.classes\n",
    "        )\n",
    "        plt.title(f'{name}: Misclassification Matrix\\n(Given true class Y, probability of predicting class X)')\n",
    "        plt.xlabel('Predicted Class')\n",
    "        plt.ylabel('True Class')\n",
    "        \n",
    "        # Save figure\n",
    "        output_dir = os.path.join(config.output_dir, name)\n",
    "        plt.savefig(f\"{output_dir}/misclassification_heatmap.png\", dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    # Find top 5 most common misclassifications across all models\n",
    "    misclass_pairs = all_misclass.groupby(['true_class', 'pred_class']).size().reset_index(name='count')\n",
    "    misclass_pairs = misclass_pairs.sort_values('count', ascending=False).head(5)\n",
    "    \n",
    "    # Create visualization of example misclassifications\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i, row in enumerate(misclass_pairs.itertuples()):\n",
    "        true_class = row.true_class\n",
    "        pred_class = row.pred_class\n",
    "        count = row.count\n",
    "        \n",
    "        # Find an example of this misclassification for each model\n",
    "        for j, (name, preds, targets) in enumerate(zip(model_names, all_preds, all_targets)):\n",
    "            # Find indices where this misclassification occurs\n",
    "            indices = np.where((preds == pred_class) & (targets == true_class))[0]\n",
    "            \n",
    "            if len(indices) > 0:\n",
    "                # Pick the first example\n",
    "                idx = indices[0]\n",
    "                \n",
    "                # Get the image\n",
    "                img, _ = test_dataset[idx]\n",
    "                img = img.permute(1, 2, 0).cpu().numpy()\n",
    "                \n",
    "                # Add normalization back to make image more viewable\n",
    "                mean = np.array(config.mean).reshape(1, 1, 3)\n",
    "                std = np.array(config.std).reshape(1, 1, 3)\n",
    "                img = img * std + mean\n",
    "                img = np.clip(img, 0, 1)\n",
    "                \n",
    "                # Plot the image\n",
    "                plt.subplot(5, len(model_names), i*len(model_names) + j + 1)\n",
    "                plt.imshow(img)\n",
    "                plt.title(f\"{name}\\nTrue: {config.classes[true_class]}\\nPred: {config.classes[pred_class]}\")\n",
    "                plt.axis('off')\n",
    "    \n",
    "    plt.suptitle('Examples of Top 5 Most Common Misclassifications', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.savefig(f\"{config.output_dir}/common_misclassifications.png\", dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    logger.info(f\"Misclassification analysis saved to {config.output_dir}/common_misclassifications.png\")\n",
    "\n",
    "####################################\n",
    "# 10. Main Evaluation Function\n",
    "####################################\n",
    "def main():\n",
    "    \"\"\"Main evaluation pipeline for baseline models\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Baseline Models Evaluation Pipeline\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Setup environment\n",
    "    config = setup_environment()\n",
    "    \n",
    "    try:\n",
    "        logger.info(\"Starting baseline evaluation...\")\n",
    "        \n",
    "        # Load the ensemble distillation baseline model\n",
    "        ed_model, ed_metadata = load_model(config, config.ed_model_path)\n",
    "        if ed_model is None:\n",
    "            logger.error(\"Failed to load Ensemble Distillation baseline model\")\n",
    "            return 1\n",
    "        \n",
    "        # Load the mutual learning baseline model\n",
    "        ml_model, ml_metadata = load_model(config, config.ml_model_path)\n",
    "        if ml_model is None:\n",
    "            logger.error(\"Failed to load Mutual Learning baseline model\")\n",
    "            return 1\n",
    "        \n",
    "        # Get model names\n",
    "        ed_name = \"baseline_ed\"\n",
    "        ml_name = \"baseline_ml\"\n",
    "        \n",
    "        # Log metadata\n",
    "        logger.info(f\"Ensemble Distillation Baseline Metadata: {ed_metadata}\")\n",
    "        logger.info(f\"Mutual Learning Baseline Metadata: {ml_metadata}\")\n",
    "        \n",
    "        # Prepare dataset and dataloader\n",
    "        test_dataset = get_test_dataset(config)\n",
    "        test_loader = create_data_loader(test_dataset, config)\n",
    "        \n",
    "        # Store metrics for comparison\n",
    "        all_metrics = []\n",
    "        all_probs = []\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        \n",
    "        # Evaluate the Ensemble Distillation baseline model\n",
    "        logger.info(\"Evaluating Ensemble Distillation baseline model...\")\n",
    "        ed_targets, ed_predictions, ed_probabilities = run_inference(ed_model, test_loader, config)\n",
    "        ed_metrics = analyze_results(ed_targets, ed_predictions, ed_probabilities, config.classes, config, ed_name)\n",
    "        all_metrics.append(ed_metrics)\n",
    "        all_probs.append(ed_probabilities)\n",
    "        all_preds.append(ed_predictions)\n",
    "        all_targets.append(ed_targets)\n",
    "        \n",
    "        # Visualize predictions\n",
    "        visualize_predictions(ed_model, test_dataset, config, ed_name)\n",
    "        \n",
    "        # Generate GradCAM visualizations\n",
    "        visualize_gradcam(ed_model, test_dataset, config, device, ed_name)\n",
    "        \n",
    "        # Evaluate the Mutual Learning baseline model\n",
    "        logger.info(\"Evaluating Mutual Learning baseline model...\")\n",
    "        ml_targets, ml_predictions, ml_probabilities = run_inference(ml_model, test_loader, config)\n",
    "        ml_metrics = analyze_results(ml_targets, ml_predictions, ml_probabilities, config.classes, config, ml_name)\n",
    "        all_metrics.append(ml_metrics)\n",
    "        all_probs.append(ml_probabilities)\n",
    "        all_preds.append(ml_predictions)\n",
    "        all_targets.append(ml_targets)\n",
    "        \n",
    "        # Visualize predictions\n",
    "        visualize_predictions(ml_model, test_dataset, config, ml_name)\n",
    "        \n",
    "        # Generate GradCAM visualizations\n",
    "        visualize_gradcam(ml_model, test_dataset, config, device, ml_name)\n",
    "        \n",
    "        # Compare models with visualizations\n",
    "        compare_models(all_metrics, config)\n",
    "        \n",
    "        # Advanced visualizations\n",
    "        visualize_confidence_distribution(all_probs, all_targets, [ed_name, ml_name], config)\n",
    "        visualize_calibration_details(all_probs, all_targets, [ed_name, ml_name], config)\n",
    "        analyze_prediction_overlap(all_preds, all_targets, [ed_name, ml_name], config)\n",
    "        analyze_misclassifications(all_probs, all_preds, all_targets, [ed_name, ml_name], test_dataset, config)\n",
    "        \n",
    "        logger.info(\"=\" * 50)\n",
    "        logger.info(\"Baseline models evaluation completed successfully!\")\n",
    "        logger.info(f\"All results saved to '{config.output_dir}' directory\")\n",
    "        logger.info(\"=\" * 50)\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Evaluation Complete! Results saved to {config.output_dir}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during evaluation: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
