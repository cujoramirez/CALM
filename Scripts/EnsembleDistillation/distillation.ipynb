{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 15:45:34,159 [INFO] - Using device: cuda\n",
      "2025-05-07 15:45:34,385 [INFO] - GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "2025-05-07 15:45:34,386 [INFO] - GPU Memory: 6.00 GB\n",
      "2025-05-07 15:45:34,387 [INFO] - CUDA Version: 11.8\n",
      "2025-05-07 15:45:34,387 [INFO] - cuDNN benchmark mode enabled\n",
      "2025-05-07 15:45:34,397 [INFO] - Configuration: {\n",
      "    \"seed\": 42,\n",
      "    \"model_name\": \"ensemble_distillation\",\n",
      "    \"dataset\": \"CIFAR-10\",\n",
      "    \"use_amp\": true,\n",
      "    \"memory_efficient_attention\": true,\n",
      "    \"prefetch_factor\": 2,\n",
      "    \"pin_memory\": true,\n",
      "    \"persistent_workers\": true,\n",
      "    \"batch_size\": 64,\n",
      "    \"gradient_accumulation_steps\": 8,\n",
      "    \"find_batch_size\": false,\n",
      "    \"gpu_memory_fraction\": 0.75,\n",
      "    \"input_size\": 32,\n",
      "    \"model_input_size\": 224,\n",
      "    \"num_workers\": 4,\n",
      "    \"val_split\": 0.1,\n",
      "    \"dataset_path\": \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Dataset\",\n",
      "    \"clear_cache_every_n_epochs\": 1,\n",
      "    \"pretrained\": true,\n",
      "    \"num_classes\": 10,\n",
      "    \"teacher_models\": [\n",
      "        \"vit\",\n",
      "        \"efficientnet\",\n",
      "        \"inception\",\n",
      "        \"mobilenet\",\n",
      "        \"resnet\",\n",
      "        \"densenet\"\n",
      "    ],\n",
      "    \"teacher_finetune_epochs\": 5,\n",
      "    \"freeze_teacher_backbones\": true,\n",
      "    \"teacher_model_paths\": {\n",
      "        \"vit\": \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Models\\\\ViT\\\\checkpoints\\\\vit_b16_teacher_20250321_053628_best.pth\",\n",
      "        \"efficientnet\": \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Models\\\\EfficientNetB0\\\\checkpoints\\\\efficientnet_b0_teacher_20250325_132652_best.pth\",\n",
      "        \"inception\": \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Models\\\\InceptionV3\\\\checkpoints\\\\inception_v3_teacher_20250428_140923_best.pth\",\n",
      "        \"mobilenet\": \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Models\\\\MobileNetV3\\\\checkpoints\\\\mobilenetv3_20250326_035725_best.pth\",\n",
      "        \"resnet\": \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Models\\\\ResNet50\\\\checkpoints\\\\resnet50_teacher_20250322_225032_best.pth\",\n",
      "        \"densenet\": \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Models\\\\DenseNet121\\\\checkpoints\\\\densenet121_teacher_20250325_160534_best.pth\"\n",
      "    },\n",
      "    \"use_pretrained_teachers\": true,\n",
      "    \"teacher_accuracies\": {\n",
      "        \"densenet\": 95.07,\n",
      "        \"efficientnet\": 94.94,\n",
      "        \"inception\": 83.17,\n",
      "        \"mobilenet\": 94.98,\n",
      "        \"resnet\": 94.08,\n",
      "        \"vit\": 93.89\n",
      "    },\n",
      "    \"teacher_init_weights\": {\n",
      "        \"densenet\": 1.0,\n",
      "        \"efficientnet\": 1.0,\n",
      "        \"inception\": 0.7,\n",
      "        \"mobilenet\": 1.0,\n",
      "        \"resnet\": 1.0,\n",
      "        \"vit\": 1.0\n",
      "    },\n",
      "    \"use_adaptive_temperature\": true,\n",
      "    \"teacher_temperatures\": {\n",
      "        \"densenet\": 4.0,\n",
      "        \"efficientnet\": 4.0,\n",
      "        \"inception\": 5.0,\n",
      "        \"mobilenet\": 4.0,\n",
      "        \"resnet\": 4.0,\n",
      "        \"vit\": 4.0\n",
      "    },\n",
      "    \"learn_temperatures\": true,\n",
      "    \"use_teacher_gating\": true,\n",
      "    \"gating_threshold\": 0.2,\n",
      "    \"dynamic_weight_update\": true,\n",
      "    \"weighting_scheme\": \"adaptive\",\n",
      "    \"weight_update_interval\": 5,\n",
      "    \"soft_target_temp\": 4.0,\n",
      "    \"epochs\": 50,\n",
      "    \"lr\": 0.001,\n",
      "    \"weight_decay\": 1e-05,\n",
      "    \"early_stop_patience\": 10,\n",
      "    \"alpha\": 0.7,\n",
      "    \"feature_loss_weight\": 0.3,\n",
      "    \"cal_weight\": 0.1,\n",
      "    \"use_curriculum\": true,\n",
      "    \"curriculum_start_epoch\": 0,\n",
      "    \"curriculum_ramp_epochs\": 30,\n",
      "    \"checkpoint_dir\": \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Models\\\\EnsembleDistillation\\\\checkpoints\",\n",
      "    \"results_dir\": \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Results\\\\EnsembleDistillation\",\n",
      "    \"export_dir\": \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\\\\Models\\\\EnsembleDistillation\\\\exports\",\n",
      "    \"per_teacher_calibration\": true,\n",
      "    \"weight_by_calibration\": true\n",
      "}\n",
      "2025-05-07 15:45:34,451 [INFO] - Random seed set to 42\n",
      "2025-05-07 15:45:34,451 [INFO] - GPU Memory: Current=0.00MB, Peak=0.00MB, Reserved=0.00MB\n",
      "2025-05-07 15:45:34,452 [INFO] - Preparing data loaders...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 15:45:36,682 [INFO] - Training samples: 45000\n",
      "2025-05-07 15:45:36,682 [INFO] - Validation samples: 5000\n",
      "2025-05-07 15:45:36,682 [INFO] - Test samples: 10000\n",
      "2025-05-07 15:45:36,689 [INFO] - Loading pre-trained teacher models...\n",
      "2025-05-07 15:45:36,689 [INFO] - Loading ViT-B16 model...\n",
      "2025-05-07 15:45:37,255 [INFO] - Loading EfficientNetB0 model...\n",
      "2025-05-07 15:45:37,321 [INFO] - Loading InceptionV3 model...\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\models\\inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n",
      "2025-05-07 15:45:37,614 [INFO] - Loading MobileNetV3 model...\n",
      "2025-05-07 15:45:37,688 [INFO] - Loading ResNet50 model...\n",
      "2025-05-07 15:45:37,918 [INFO] - Loading DenseNet121 model...\n",
      "2025-05-07 15:45:38,008 [INFO] - Loading pre-trained weights for vit from C:\\Users\\Gading\\Downloads\\Research\\Models\\ViT\\checkpoints\\vit_b16_teacher_20250321_053628_best.pth\n",
      "C:\\Users\\Gading\\AppData\\Local\\Temp\\ipykernel_26924\\2968733938.py:471: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n",
      "2025-05-07 15:45:40,508 [INFO] - Successfully loaded pre-trained weights for vit\n",
      "2025-05-07 15:45:40,508 [INFO] - Loading pre-trained weights for efficientnet from C:\\Users\\Gading\\Downloads\\Research\\Models\\EfficientNetB0\\checkpoints\\efficientnet_b0_teacher_20250325_132652_best.pth\n",
      "2025-05-07 15:45:40,759 [INFO] - Successfully loaded pre-trained weights for efficientnet\n",
      "2025-05-07 15:45:40,759 [INFO] - Loading pre-trained weights for inception from C:\\Users\\Gading\\Downloads\\Research\\Models\\InceptionV3\\checkpoints\\inception_v3_teacher_20250428_140923_best.pth\n",
      "2025-05-07 15:45:41,908 [ERROR] - Error loading weights for inception: Error(s) in loading state_dict for Inception3:\n",
      "\tMissing key(s) in state_dict: \"AuxLogits.fc.weight\", \"AuxLogits.fc.bias\", \"fc.weight\", \"fc.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"AuxLogits.fc.1.weight\", \"AuxLogits.fc.1.bias\", \"fc.1.weight\", \"fc.1.bias\". \n",
      "2025-05-07 15:45:41,908 [ERROR] - Attempting to continue with pretrained ImageNet weights\n",
      "2025-05-07 15:45:42,523 [INFO] - Loading pre-trained weights for mobilenet from C:\\Users\\Gading\\Downloads\\Research\\Models\\MobileNetV3\\checkpoints\\mobilenetv3_20250326_035725_best.pth\n",
      "2025-05-07 15:45:43,022 [INFO] - Successfully loaded pre-trained weights for mobilenet\n",
      "2025-05-07 15:45:43,022 [INFO] - Loading pre-trained weights for resnet from C:\\Users\\Gading\\Downloads\\Research\\Models\\ResNet50\\checkpoints\\resnet50_teacher_20250322_225032_best.pth\n",
      "2025-05-07 15:45:43,647 [INFO] - Successfully loaded pre-trained weights for resnet\n",
      "2025-05-07 15:45:43,731 [INFO] - Loading pre-trained weights for densenet from C:\\Users\\Gading\\Downloads\\Research\\Models\\DenseNet121\\checkpoints\\densenet121_teacher_20250325_160534_best.pth\n",
      "2025-05-07 15:45:44,420 [INFO] - Successfully loaded pre-trained weights for densenet\n",
      "2025-05-07 15:45:44,466 [INFO] - Model vit loaded and moved to cuda\n",
      "2025-05-07 15:45:44,467 [INFO] - Model vit set to evaluation mode\n",
      "2025-05-07 15:45:44,483 [INFO] - Model efficientnet loaded and moved to cuda\n",
      "2025-05-07 15:45:44,484 [INFO] - Model efficientnet set to evaluation mode\n",
      "2025-05-07 15:45:44,521 [INFO] - Model inception loaded and moved to cuda\n",
      "2025-05-07 15:45:44,522 [INFO] - Model inception set to evaluation mode\n",
      "2025-05-07 15:45:44,537 [INFO] - Model mobilenet loaded and moved to cuda\n",
      "2025-05-07 15:45:44,538 [INFO] - Model mobilenet set to evaluation mode\n",
      "2025-05-07 15:45:44,585 [INFO] - Model resnet loaded and moved to cuda\n",
      "2025-05-07 15:45:44,585 [INFO] - Model resnet set to evaluation mode\n",
      "2025-05-07 15:45:44,633 [INFO] - Model densenet loaded and moved to cuda\n",
      "2025-05-07 15:45:44,634 [INFO] - Model densenet set to evaluation mode\n",
      "2025-05-07 15:45:44,638 [INFO] - Skipping teacher fine-tuning as pre-trained models are being used\n",
      "2025-05-07 15:45:44,638 [INFO] - Creating student model...\n",
      "2025-05-07 15:45:44,639 [INFO] - Creating scaled EfficientNet-B0 student model...\n",
      "2025-05-07 15:45:44,945 [INFO] - Student model created with 4.02M parameters\n",
      "2025-05-07 15:45:44,967 [INFO] - Training student with calibration-aware ensemble distillation...\n",
      "2025-05-07 15:45:44,968 [INFO] - Training student model with ensemble distillation (ACP enabled)...\n",
      "2025-05-07 15:45:44,970 [INFO] - Teacher weighting initialized with scheme: adaptive\n",
      "2025-05-07 15:45:44,971 [INFO] - Initial teacher weights: {'vit': 0.17543859649122806, 'efficientnet': 0.17543859649122806, 'inception': 0.12280701754385964, 'mobilenet': 0.17543859649122806, 'resnet': 0.17543859649122806, 'densenet': 0.17543859649122806}\n",
      "2025-05-07 15:45:44,971 [INFO] - Initial teacher temperatures: {'vit': 4.0, 'efficientnet': 4.0, 'inception': 5.0, 'mobilenet': 4.0, 'resnet': 4.0, 'densenet': 4.0}\n",
      "2025-05-07 15:45:44,973 [INFO] - Hook registered for encoder.ln\n",
      "2025-05-07 15:45:46,017 [INFO] - Feature shape for vit: torch.Size([197, 768])\n",
      "2025-05-07 15:45:46,018 [INFO] - Hook registered for features.8\n",
      "2025-05-07 15:45:46,626 [INFO] - Feature shape for efficientnet: torch.Size([1280, 7, 7])\n",
      "2025-05-07 15:45:46,626 [INFO] - Hook registered for Mixed_7c\n",
      "2025-05-07 15:45:47,307 [INFO] - Feature shape for inception: torch.Size([2048, 5, 5])\n",
      "2025-05-07 15:45:47,313 [INFO] - Hook registered for features.15.block.2\n",
      "2025-05-07 15:45:47,459 [INFO] - Feature shape for mobilenet: torch.Size([960, 7, 7])\n",
      "2025-05-07 15:45:47,460 [INFO] - Hook registered for layer4\n",
      "2025-05-07 15:45:48,180 [INFO] - Feature shape for resnet: torch.Size([2048, 7, 7])\n",
      "2025-05-07 15:45:48,181 [INFO] - Hook registered for features.norm5\n",
      "2025-05-07 15:45:48,668 [INFO] - Feature shape for densenet: torch.Size([1024, 7, 7])\n",
      "2025-05-07 15:45:48,672 [INFO] - Hook registered for features.8\n",
      "2025-05-07 15:45:48,724 [INFO] - Feature shape for student: torch.Size([1280, 7, 7])\n",
      "2025-05-07 15:45:48,726 [INFO] - HFI module initialized with 6 teachers\n",
      "2025-05-07 15:45:48,726 [INFO] - Target student feature shape: torch.Size([1280, 7, 7])\n",
      "2025-05-07 15:45:48,726 [INFO] - HFI module initialized and its parameters added to optimizer.\n",
      "2025-05-07 15:45:48,726 [INFO] - Learnable teacher temperatures added to optimizer.\n",
      "2025-05-07 15:45:48,730 [INFO] - Config saved to C:\\Users\\Gading\\Downloads\\Research\\Results\\EnsembleDistillation\\ensemble_distillation_20250507_154548_config.json\n",
      "2025-05-07 15:45:48,731 [INFO] - GPU Memory: Current=606.17MB, Peak=1031.56MB, Reserved=680.00MB\n",
      "2025-05-07 15:45:48,731 [INFO] - --- Epoch 1/50 ---\n",
      "2025-05-07 15:45:48,892 [INFO] - GPU cache cleared: 606.17MB → 606.17MB (freed 0.00MB)\n",
      "2025-05-07 15:45:48,893 [INFO] - ACP Weights - Alpha(KL): 0.0233, Feature: 0.0100, Cal: 0.0033\n",
      "2025-05-07 15:45:48,894 [INFO] - Updated teacher weights: {'vit': 0.16882743243486237, 'efficientnet': 0.17071548019347993, 'inception': 0.149551363889738, 'mobilenet': 0.17078740582237967, 'resnet': 0.169169079172136, 'densenet': 0.170949238487404}\n",
      "2025-05-07 15:45:48,894 [INFO] - Teacher gating status: {'vit': 1.0, 'efficientnet': 1.0, 'inception': 1.0, 'mobilenet': 1.0, 'resnet': 1.0, 'densenet': 1.0}\n",
      "2025-05-07 15:45:49,113 [INFO] - HFI attention weights: {'vit': 0.1666666716337204, 'efficientnet': 0.1666666716337204, 'inception': 0.1666666716337204, 'mobilenet': 0.1666666716337204, 'resnet': 0.1666666716337204, 'densenet': 0.1666666716337204}\n",
      "2025-05-07 15:46:26,327 [ERROR] - An error occurred: adaptive_avg_pool2d: output_size must be 2\n",
      "2025-05-07 15:46:26,345 [ERROR] - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Gading\\AppData\\Local\\Temp\\ipykernel_26924\\2968733938.py\", line 1998, in main\n",
      "    student, history = train_student(\n",
      "                       ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Gading\\AppData\\Local\\Temp\\ipykernel_26924\\2968733938.py\", line 1496, in train_student\n",
      "    fused_teacher_features_hfi = hfi_module(current_teacher_features_dict) # HFI expects detached features\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Gading\\AppData\\Local\\Temp\\ipykernel_26924\\2968733938.py\", line 847, in forward\n",
      "    projected = F.adaptive_avg_pool2d(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py\", line 1382, in adaptive_avg_pool2d\n",
      "    return torch._C._nn.adaptive_avg_pool2d(input, _output_size)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: adaptive_avg_pool2d: output_size must be 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ensemble Distillation Training Script for Six Teacher Models on CIFAR-10\n",
    "- Teachers: ViT-B16, EfficientNetB0, InceptionV3, MobileNetV3, ResNet50, DenseNet121\n",
    "- Student: Scaled EfficientNetB0\n",
    "\n",
    "Part of the research: \n",
    "\"Comparative Analysis of Ensemble Distillation and Mutual Learning: \n",
    "A Unified Framework for Uncertainty-Calibrated Vision Systems\"\n",
    "\n",
    "Target Hardware: RTX 3060 Laptop (6GB VRAM)\n",
    "Optimizations: AMP, gradient accumulation, memory-efficient techniques, GPU cache clearing\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from tensorboardX import SummaryWriter\n",
    "# Replace broad imports with specific model imports\n",
    "from torchvision.models import (\n",
    "    vit_b_16, ViT_B_16_Weights,\n",
    "    efficientnet_b0, EfficientNet_B0_Weights,\n",
    "    inception_v3, Inception_V3_Weights,\n",
    "    mobilenet_v3_large, MobileNet_V3_Large_Weights,\n",
    "    resnet50, ResNet50_Weights,\n",
    "    densenet121, DenseNet121_Weights\n",
    ")\n",
    "import timm\n",
    "from datetime import datetime\n",
    "import gc  # For explicit garbage collection\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# Define base paths\n",
    "BASE_PATH = \"C:\\\\Users\\\\Gading\\\\Downloads\\\\Research\"\n",
    "DATASET_PATH = os.path.join(BASE_PATH, \"Dataset\")\n",
    "RESULTS_PATH = os.path.join(BASE_PATH, \"Results\")\n",
    "MODELS_PATH = os.path.join(BASE_PATH, \"Models\")\n",
    "SCRIPTS_PATH = os.path.join(BASE_PATH, \"Scripts\")\n",
    "\n",
    "# Create model-specific paths\n",
    "MODEL_NAME = \"EnsembleDistillation\"\n",
    "MODEL_RESULTS_PATH = os.path.join(RESULTS_PATH, MODEL_NAME)\n",
    "MODEL_CHECKPOINT_PATH = os.path.join(MODELS_PATH, MODEL_NAME, \"checkpoints\")\n",
    "MODEL_EXPORT_PATH = os.path.join(MODELS_PATH, MODEL_NAME, \"exports\")\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(DATASET_PATH, exist_ok=True)\n",
    "os.makedirs(MODEL_RESULTS_PATH, exist_ok=True)\n",
    "os.makedirs(MODEL_CHECKPOINT_PATH, exist_ok=True)\n",
    "os.makedirs(MODEL_EXPORT_PATH, exist_ok=True)\n",
    "os.makedirs(SCRIPTS_PATH, exist_ok=True)\n",
    "os.makedirs(os.path.join(MODEL_RESULTS_PATH, \"logs\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(MODEL_RESULTS_PATH, \"plots\"), exist_ok=True)\n",
    "\n",
    "# Setup logging\n",
    "log_file = os.path.join(MODEL_RESULTS_PATH, \"logs\", \"ensemble_distillation.log\")\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s [%(levelname)s] - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Set up tensorboard writer\n",
    "writer = SummaryWriter(log_dir=os.path.join(MODEL_RESULTS_PATH, \"logs\"))\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    logger.info(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    logger.info(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    logger.info(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    # Enable cuDNN benchmark for optimal performance\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    logger.info(\"cuDNN benchmark mode enabled\")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False  # Slightly faster with False\n",
    "    logger.info(f\"Random seed set to {seed}\")\n",
    "\n",
    "# REPLACE the existing Config class with this one:\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # General settings\n",
    "        self.seed = 42\n",
    "        self.model_name = \"ensemble_distillation\"\n",
    "        self.dataset = \"CIFAR-10\"\n",
    "        \n",
    "        # Hardware-specific optimizations - FIXED VALUES for RTX 3060 Laptop (6GB)\n",
    "        self.use_amp = True  # Automatic Mixed Precision\n",
    "        self.memory_efficient_attention = True  # Memory-efficient attention\n",
    "        self.prefetch_factor = 2  # DataLoader prefetch factor\n",
    "        self.pin_memory = True  # Pin memory for faster CPU->GPU transfers\n",
    "        self.persistent_workers = True  # Keep workers alive between epochs\n",
    "        \n",
    "        # RTX 3060 Laptop specific fixes\n",
    "        self.batch_size = 64  # Safe value based on testing\n",
    "        self.gradient_accumulation_steps = 8  # Accumulate for effective batch of 512\n",
    "        self.find_batch_size = False  # Disable auto-finding (using known values)\n",
    "        self.gpu_memory_fraction = 0.75  # More conservative memory usage\n",
    "        \n",
    "        # Data settings\n",
    "        self.input_size = 32  # Original CIFAR-10 image size\n",
    "        self.model_input_size = 224  # Required size for pretrained models\n",
    "        self.num_workers = 4  # For data loading\n",
    "        self.val_split = 0.1  # 10% validation split\n",
    "        self.dataset_path = DATASET_PATH\n",
    "        \n",
    "        # GPU cache clearing settings\n",
    "        self.clear_cache_every_n_epochs = 1  # Clear cache every epoch\n",
    "        \n",
    "        # Model settings\n",
    "        self.pretrained = True  # Use pretrained models\n",
    "        self.num_classes = 10  # CIFAR-10 has 10 classes\n",
    "        \n",
    "        # Teacher models\n",
    "        self.teacher_models = ['vit', 'efficientnet', 'inception', 'mobilenet', 'resnet', 'densenet']\n",
    "        self.teacher_finetune_epochs = 5  # Number of epochs to fine-tune each teacher\n",
    "        self.freeze_teacher_backbones = True  # Freeze teacher backbones during fine-tuning\n",
    "        \n",
    "        # Pre-trained teacher model paths\n",
    "        self.teacher_model_paths = {\n",
    "            'vit': r\"C:\\Users\\Gading\\Downloads\\Research\\Models\\ViT\\checkpoints\\vit_b16_teacher_20250321_053628_best.pth\",\n",
    "            'efficientnet': r\"C:\\Users\\Gading\\Downloads\\Research\\Models\\EfficientNetB0\\checkpoints\\efficientnet_b0_teacher_20250325_132652_best.pth\",\n",
    "            'inception': r\"C:\\Users\\Gading\\Downloads\\Research\\Models\\InceptionV3\\checkpoints\\inception_v3_teacher_20250428_140923_best.pth\",\n",
    "            'mobilenet': r\"C:\\Users\\Gading\\Downloads\\Research\\Models\\MobileNetV3\\checkpoints\\mobilenetv3_20250326_035725_best.pth\",\n",
    "            'resnet': r\"C:\\Users\\Gading\\Downloads\\Research\\Models\\ResNet50\\checkpoints\\resnet50_teacher_20250322_225032_best.pth\",\n",
    "            'densenet': r\"C:\\Users\\Gading\\Downloads\\Research\\Models\\DenseNet121\\checkpoints\\densenet121_teacher_20250325_160534_best.pth\"\n",
    "        }\n",
    "        self.use_pretrained_teachers = True  # Flag to use pre-trained teacher models\n",
    "        \n",
    "        # Teacher calibration and accuracy metrics\n",
    "        self.teacher_accuracies = {\n",
    "            'densenet': 95.07,\n",
    "            'efficientnet': 94.94,\n",
    "            'inception': 83.17,\n",
    "            'mobilenet': 94.98,\n",
    "            'resnet': 94.08,\n",
    "            'vit': 93.89\n",
    "        }\n",
    "        \n",
    "        # Initial teacher weights (will be dynamically adjusted during training)\n",
    "        self.teacher_init_weights = {\n",
    "            'densenet': 1.0,\n",
    "            'efficientnet': 1.0,\n",
    "            'inception': 0.7,  # Lower initial weight due to lower accuracy\n",
    "            'mobilenet': 1.0,\n",
    "            'resnet': 1.0,\n",
    "            'vit': 1.0\n",
    "        }\n",
    "        \n",
    "        # Teacher temperature scaling\n",
    "        self.use_adaptive_temperature = True  # Use teacher-specific temperatures\n",
    "        self.teacher_temperatures = {\n",
    "            'densenet': 4.0,\n",
    "            'efficientnet': 4.0,\n",
    "            'inception': 5.0,  # Higher temperature for less confident predictions\n",
    "            'mobilenet': 4.0,\n",
    "            'resnet': 4.0,\n",
    "            'vit': 4.0\n",
    "        }\n",
    "        self.learn_temperatures = True  # Whether to learn temperatures during training\n",
    "        \n",
    "        # Teacher gating settings\n",
    "        self.use_teacher_gating = True  # Use dynamic teacher gating/pruning\n",
    "        self.gating_threshold = 0.2  # Minimum weight for teacher contribution\n",
    "        self.dynamic_weight_update = True  # Update weights during training\n",
    "        \n",
    "        # Weighting scheme options\n",
    "        self.weighting_scheme = 'adaptive'  # Options: 'fixed', 'accuracy', 'calibration', 'adaptive', 'learned'\n",
    "        self.weight_update_interval = 5  # Update weights every N batches\n",
    "        \n",
    "        # Temperature settings\n",
    "        self.soft_target_temp = 4.0  # Temperature for soft targets\n",
    "        \n",
    "        # Training settings\n",
    "        self.epochs = 50  # Total training epochs\n",
    "        self.lr = 1e-3  # Learning rate\n",
    "        self.weight_decay = 1e-5  # Weight decay\n",
    "        self.early_stop_patience = 10  # Early stopping patience\n",
    "        \n",
    "        # Loss weights (TARGET values after ramp-up for ACP)\n",
    "        self.alpha = 0.7  # Target weight for KL distillation loss (distillation strength)\n",
    "        self.feature_loss_weight = 0.3  # Target weight for Feature loss\n",
    "        self.cal_weight = 0.1  # Target weight for Calibration loss\n",
    "        \n",
    "        # Curriculum scheduling settings\n",
    "        self.use_curriculum = True  # Whether to use curriculum scheduling\n",
    "        self.curriculum_start_epoch = 0 # Epoch to start ramping weights (0-indexed)\n",
    "        self.curriculum_ramp_epochs = 30  # Epochs over which to ramp up loss component weights\n",
    "\n",
    "        # Output settings\n",
    "        self.checkpoint_dir = MODEL_CHECKPOINT_PATH\n",
    "        self.results_dir = MODEL_RESULTS_PATH\n",
    "        self.export_dir = MODEL_EXPORT_PATH\n",
    "        \n",
    "        # Enhanced calibration settings\n",
    "        self.per_teacher_calibration = True  # Use per-teacher calibration loss\n",
    "        self.weight_by_calibration = True  # Weight losses by teacher calibration quality\n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"String representation of the configuration\"\"\"\n",
    "        return json.dumps(self.__dict__, indent=4)\n",
    "    \n",
    "    def save(self, path):\n",
    "        \"\"\"Save configuration to a JSON file\"\"\"\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(self.__dict__, f, indent=4)\n",
    "\n",
    "    # --- ACP Weight Calculation ---\n",
    "    def _get_ramped_weight(self, epoch, target_weight, start_epoch, ramp_epochs):\n",
    "        \"\"\"Helper function to calculate ramped weight.\"\"\"\n",
    "        if not self.use_curriculum or epoch < start_epoch:\n",
    "            # If curriculum is disabled or before start epoch, return 0 if target > 0, else target\n",
    "            # This ensures that if a weight is meant to be 0 initially, it stays 0.\n",
    "            # If it's meant to ramp up to a non-zero value, it starts at 0.\n",
    "            return 0.0 if target_weight > 0 else target_weight \n",
    "        \n",
    "        ramp_epoch = epoch - start_epoch # Current epoch within the ramp phase\n",
    "        if ramp_epoch < ramp_epochs:\n",
    "            ramp_duration = max(1, ramp_epochs) # Avoid division by zero if ramp_epochs is 0\n",
    "            # Linear ramp: current_weight = target_weight * (current_ramp_progress)\n",
    "            return target_weight * (ramp_epoch + 1) / ramp_duration\n",
    "        return target_weight # Return full target weight after ramp completes\n",
    "\n",
    "    def get_calibration_weight(self, epoch):\n",
    "        \"\"\"Get the calibration loss weight for the current epoch.\"\"\"\n",
    "        return self._get_ramped_weight(epoch, self.cal_weight, self.curriculum_start_epoch, self.curriculum_ramp_epochs)\n",
    "\n",
    "    def get_alpha_weight(self, epoch): # This is for the KL divergence part of distillation\n",
    "        \"\"\"Get the KL divergence loss weight (alpha) for the current epoch.\"\"\"\n",
    "        # Alpha is the weight for KL, (1-alpha) for CE. We ramp up KL's influence.\n",
    "        return self._get_ramped_weight(epoch, self.alpha, self.curriculum_start_epoch, self.curriculum_ramp_epochs)\n",
    "\n",
    "    def get_feature_loss_weight(self, epoch):\n",
    "        \"\"\"Get the feature alignment loss weight for the current epoch.\"\"\"\n",
    "        return self._get_ramped_weight(epoch, self.feature_loss_weight, self.curriculum_start_epoch, self.curriculum_ramp_epochs)\n",
    "    # --- End ACP Weight Calculation ---\n",
    "\n",
    "\n",
    "# Memory utilities\n",
    "def print_gpu_memory_stats():\n",
    "    \"\"\"Print GPU memory usage statistics\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        current_mem = torch.cuda.memory_allocated() / 1024**2\n",
    "        max_mem = torch.cuda.max_memory_allocated() / 1024**2\n",
    "        reserved_mem = torch.cuda.memory_reserved() / 1024**2\n",
    "        logger.info(f\"GPU Memory: Current={current_mem:.2f}MB, Peak={max_mem:.2f}MB, Reserved={reserved_mem:.2f}MB\")\n",
    "\n",
    "def clear_gpu_cache():\n",
    "    \"\"\"Clear GPU cache to free up memory\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        before_mem = torch.cuda.memory_allocated() / 1024**2\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()  # Explicit garbage collection\n",
    "        after_mem = torch.cuda.memory_allocated() / 1024**2\n",
    "        logger.info(f\"GPU cache cleared: {before_mem:.2f}MB → {after_mem:.2f}MB (freed {before_mem-after_mem:.2f}MB)\")\n",
    "\n",
    "# Calibration Metrics\n",
    "class CalibrationMetrics:\n",
    "    @staticmethod\n",
    "    def compute_ece(probs, targets, n_bins=15):\n",
    "        \"\"\"Compute Expected Calibration Error (ECE)\"\"\"\n",
    "        confidences, predictions = torch.max(probs, dim=1)\n",
    "        accuracies = (predictions == targets).float()\n",
    "        sorted_indices = torch.argsort(confidences)\n",
    "        sorted_confidences = confidences[sorted_indices]\n",
    "        sorted_accuracies = accuracies[sorted_indices]\n",
    "        bin_size = 1.0 / n_bins\n",
    "        bins = torch.linspace(0, 1.0, n_bins + 1)\n",
    "        ece = 0.0\n",
    "        for i in range(n_bins):\n",
    "            bin_start = bins[i]\n",
    "            bin_end = bins[i+1]\n",
    "            in_bin = (sorted_confidences >= bin_start) & (sorted_confidences < bin_end)\n",
    "            bin_count = in_bin.sum()\n",
    "            if bin_count > 0:\n",
    "                bin_conf = sorted_confidences[in_bin].mean()\n",
    "                bin_acc = sorted_accuracies[in_bin].mean()\n",
    "                ece += (bin_count / len(confidences)) * torch.abs(bin_acc - bin_conf)\n",
    "        return ece\n",
    "    \n",
    "    @staticmethod\n",
    "    def calibration_loss(logits, targets):\n",
    "        \"\"\"Compute a loss term that encourages better calibration (MSE-based)\"\"\"\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(probs, dim=1)\n",
    "        accuracies = (predictions == targets).float()\n",
    "        # MSE between confidence and accuracy\n",
    "        return torch.mean((confidences - accuracies) ** 2)\n",
    "\n",
    "\n",
    "# Data Preparation\n",
    "def get_cifar10_loaders(config):\n",
    "    \"\"\"Prepare CIFAR-10 dataset and dataloaders\"\"\"\n",
    "    # For pretrained models, we need to use ImageNet normalization\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    # Calculate padding required to bring 32x32 to config.model_input_size\n",
    "    pad_size = (config.model_input_size - config.input_size) // 2\n",
    "    \n",
    "    # Transform for training with data augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "        transforms.Resize(config.model_input_size, antialias=True)\n",
    "    ])\n",
    "    \n",
    "    # Transform for validation/test (no augmentation)\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "        transforms.Resize(config.model_input_size, antialias=True)\n",
    "    ])\n",
    "    \n",
    "    # Set CIFAR-10 dataset path\n",
    "    cifar10_path = os.path.join(config.dataset_path, \"CIFAR-10\")\n",
    "    \n",
    "    # Load CIFAR-10 dataset\n",
    "    full_train_dataset = datasets.CIFAR10(\n",
    "        root=cifar10_path, train=True, download=True, transform=train_transform\n",
    "    )\n",
    "    test_dataset = datasets.CIFAR10(\n",
    "        root=cifar10_path, train=False, download=True, transform=test_transform\n",
    "    )\n",
    "    \n",
    "    # Split training set into train and validation\n",
    "    val_size = int(len(full_train_dataset) * config.val_split)\n",
    "    train_size = len(full_train_dataset) - val_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        full_train_dataset, [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(config.seed)\n",
    "    )\n",
    "    \n",
    "    # Create a custom dataset for validation to apply the test transform\n",
    "    val_dataset_with_transform = torch.utils.data.Subset(\n",
    "        datasets.CIFAR10(\n",
    "            root=cifar10_path, train=True, download=False, transform=test_transform\n",
    "        ),\n",
    "        val_dataset.indices\n",
    "    )\n",
    "    \n",
    "    # Create data loaders with optimized settings for RTX 3060\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=config.num_workers, \n",
    "        pin_memory=config.pin_memory,\n",
    "        persistent_workers=config.persistent_workers if config.num_workers > 0 else False,\n",
    "        prefetch_factor=config.prefetch_factor if config.num_workers > 0 else None\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset_with_transform, \n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False, \n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=config.pin_memory,\n",
    "        persistent_workers=config.persistent_workers if config.num_workers > 0 else False,\n",
    "        prefetch_factor=config.prefetch_factor if config.num_workers > 0 else None\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False, \n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=config.pin_memory,\n",
    "        persistent_workers=config.persistent_workers if config.num_workers > 0 else False,\n",
    "        prefetch_factor=config.prefetch_factor if config.num_workers > 0 else None\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Training samples: {len(train_dataset)}\")\n",
    "    logger.info(f\"Validation samples: {len(val_dataset)}\")\n",
    "    logger.info(f\"Test samples: {len(test_dataset)}\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# Teacher Models\n",
    "def load_teacher_models(config):\n",
    "    \"\"\"Load the six teacher models with pretrained weights\"\"\"\n",
    "    teachers = {}\n",
    "    \n",
    "    # ViT-B16 - Use torchvision implementation instead of timm\n",
    "    logger.info(\"Loading ViT-B16 model...\")\n",
    "    teachers['vit'] = vit_b_16(weights=None)\n",
    "    num_classes = config.num_classes\n",
    "    # Adjust the classifier head\n",
    "    if hasattr(teachers['vit'], 'heads'):\n",
    "        if hasattr(teachers['vit'].heads, 'head'):\n",
    "            in_features = teachers['vit'].heads.head.in_features\n",
    "            teachers['vit'].heads.head = nn.Linear(in_features, num_classes)\n",
    "        else:\n",
    "            logger.warning(\"ViT model structure differs from expected - trying alternative configuration\")\n",
    "            in_features = teachers['vit'].hidden_dim\n",
    "            teachers['vit'].heads = nn.Linear(in_features, num_classes)\n",
    "    elif hasattr(teachers['vit'], 'head'):\n",
    "        in_features = teachers['vit'].head.in_features\n",
    "        teachers['vit'].head = nn.Linear(in_features, num_classes)\n",
    "    else:\n",
    "        logger.error(\"Could not locate classification head of ViT model\")\n",
    "    \n",
    "    # EfficientNetB0 - Use torchvision implementation\n",
    "    logger.info(\"Loading EfficientNetB0 model...\")\n",
    "    teachers['efficientnet'] = efficientnet_b0(weights=None)\n",
    "    if hasattr(teachers['efficientnet'], 'classifier'):\n",
    "        in_features = teachers['efficientnet'].classifier[1].in_features\n",
    "        teachers['efficientnet'].classifier[1] = nn.Linear(in_features, config.num_classes)\n",
    "    else:\n",
    "        logger.warning(\"EfficientNet structure differs from expected\")\n",
    "    \n",
    "    # InceptionV3\n",
    "    logger.info(\"Loading InceptionV3 model...\")\n",
    "    teachers['inception'] = inception_v3(weights=None)\n",
    "    teachers['inception'].fc = nn.Linear(teachers['inception'].fc.in_features, config.num_classes)\n",
    "    teachers['inception'].aux_logits = False\n",
    "    \n",
    "    # MobileNetV3\n",
    "    logger.info(\"Loading MobileNetV3 model...\")\n",
    "    teachers['mobilenet'] = mobilenet_v3_large(weights=None)\n",
    "    teachers['mobilenet'].classifier[-1] = nn.Linear(teachers['mobilenet'].classifier[-1].in_features, config.num_classes)\n",
    "    \n",
    "    # ResNet50\n",
    "    logger.info(\"Loading ResNet50 model...\")\n",
    "    teachers['resnet'] = resnet50(weights=None)\n",
    "    teachers['resnet'].fc = nn.Linear(teachers['resnet'].fc.in_features, config.num_classes)\n",
    "    \n",
    "    # DenseNet121\n",
    "    logger.info(\"Loading DenseNet121 model...\")\n",
    "    teachers['densenet'] = densenet121(weights=None)\n",
    "    teachers['densenet'].classifier = nn.Linear(teachers['densenet'].classifier.in_features, config.num_classes)\n",
    "    \n",
    "    # Load fine-tuned weights if use_pretrained_teachers is enabled\n",
    "    if config.use_pretrained_teachers:\n",
    "        for name, model in teachers.items():\n",
    "            if name in config.teacher_model_paths:\n",
    "                checkpoint_path = config.teacher_model_paths[name]\n",
    "                if os.path.exists(checkpoint_path):\n",
    "                    logger.info(f\"Loading pre-trained weights for {name} from {checkpoint_path}\")\n",
    "                    try:\n",
    "                        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "                        \n",
    "                        # Handle different checkpoint formats\n",
    "                        if 'model_state_dict' in checkpoint:\n",
    "                            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                        elif 'state_dict' in checkpoint:\n",
    "                            model.load_state_dict(checkpoint['state_dict'])\n",
    "                        else:\n",
    "                            model.load_state_dict(checkpoint)\n",
    "                            \n",
    "                        logger.info(f\"Successfully loaded pre-trained weights for {name}\")\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Error loading weights for {name}: {str(e)}\")\n",
    "                        logger.error(\"Attempting to continue with pretrained ImageNet weights\")\n",
    "                        # Fall back to ImageNet pretrained weights\n",
    "                        if name == 'vit':\n",
    "                            teachers[name] = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "                            if hasattr(teachers[name], 'heads') and hasattr(teachers[name].heads, 'head'):\n",
    "                                in_features = teachers[name].heads.head.in_features\n",
    "                                teachers[name].heads.head = nn.Linear(in_features, config.num_classes)\n",
    "                        elif name == 'efficientnet':\n",
    "                            teachers[name] = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "                            in_features = teachers[name].classifier[1].in_features\n",
    "                            teachers[name].classifier[1] = nn.Linear(in_features, config.num_classes)\n",
    "                        elif name == 'inception':\n",
    "                            teachers[name] = inception_v3(weights=Inception_V3_Weights.IMAGENET1K_V1)\n",
    "                            teachers[name].fc = nn.Linear(teachers[name].fc.in_features, config.num_classes)\n",
    "                            teachers[name].aux_logits = False\n",
    "                        elif name == 'mobilenet':\n",
    "                            teachers[name] = mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1)\n",
    "                            teachers[name].classifier[-1] = nn.Linear(teachers[name].classifier[-1].in_features, config.num_classes)\n",
    "                        elif name == 'resnet':\n",
    "                            teachers[name] = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "                            teachers[name].fc = nn.Linear(teachers[name].fc.in_features, config.num_classes)\n",
    "                        elif name == 'densenet':\n",
    "                            teachers[name] = densenet121(weights=DenseNet121_Weights.IMAGENET1K_V1)\n",
    "                            teachers[name].classifier = nn.Linear(teachers[name].classifier.in_features, config.num_classes)\n",
    "                else:\n",
    "                    logger.warning(f\"Checkpoint file for {name} not found at {checkpoint_path}\")\n",
    "                    # Load ImageNet pretrained weights as fallback\n",
    "                    if name == 'vit':\n",
    "                        teachers[name] = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "                        if hasattr(teachers[name], 'heads') and hasattr(teachers[name].heads, 'head'):\n",
    "                            in_features = teachers[name].heads.head.in_features\n",
    "                            teachers[name].heads.head = nn.Linear(in_features, config.num_classes)\n",
    "                    # Add similar fallbacks for other models\n",
    "    \n",
    "    # Move all models to device\n",
    "    for name, model in teachers.items():\n",
    "        teachers[name] = model.to(device)\n",
    "        logger.info(f\"Model {name} loaded and moved to {device}\")\n",
    "        \n",
    "        # Set to evaluation mode since they're already trained\n",
    "        if config.use_pretrained_teachers:\n",
    "            teachers[name].eval()\n",
    "            logger.info(f\"Model {name} set to evaluation mode\")\n",
    "        \n",
    "    return teachers\n",
    "\n",
    "def freeze_teacher_backbone(teacher, model_name):\n",
    "    \"\"\"Freeze all layers except the classifier/output layer\"\"\"\n",
    "    if model_name == 'vit':\n",
    "        for param in teacher.parameters():\n",
    "            param.requires_grad = False\n",
    "        # Unfreeze the classifier head based on model structure\n",
    "        if hasattr(teacher, 'heads') and hasattr(teacher.heads, 'head'):\n",
    "            for param in teacher.heads.head.parameters():\n",
    "                param.requires_grad = True\n",
    "        elif hasattr(teacher, 'head'):\n",
    "            for param in teacher.head.parameters():\n",
    "                param.requires_grad = True\n",
    "    elif model_name == 'efficientnet':\n",
    "        for param in teacher.parameters():\n",
    "            param.requires_grad = False\n",
    "        # Unfreeze classifier\n",
    "        for param in teacher.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "    elif model_name == 'inception':\n",
    "        for param in teacher.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in teacher.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "    elif model_name == 'mobilenet':\n",
    "        for param in teacher.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in teacher.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "    elif model_name == 'resnet':\n",
    "        for param in teacher.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in teacher.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "    elif model_name == 'densenet':\n",
    "        for param in teacher.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in teacher.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    return teacher\n",
    "\n",
    "# Student Model\n",
    "def create_student_model(config):\n",
    "    \"\"\"Create a student model based on EfficientNetB0\"\"\"\n",
    "    logger.info(f\"Creating scaled EfficientNet-B0 student model...\")\n",
    "    \n",
    "    # Initialize the model with ImageNet weights\n",
    "    model = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "    \n",
    "    # Modify the classifier for our number of classes\n",
    "    if hasattr(model, 'classifier'):\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, config.num_classes)\n",
    "    \n",
    "    # Log model parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    logger.info(f\"Student model created with {total_params/1e6:.2f}M parameters\")\n",
    "    \n",
    "    return model.to(device)\n",
    "\n",
    "# Loss Functions\n",
    "class DistillationLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, temperature=2.0):\n",
    "        super(DistillationLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "# In class EnhancedDistillationLoss:\n",
    "# REPLACE the existing forward method with this one:\n",
    "    def forward(self, student_logits, teacher_ensemble_logits, teacher_individual_logits, \n",
    "                teacher_names, labels, alpha_e): # Added alpha_e argument\n",
    "        # Cross-entropy loss for hard labels\n",
    "        ce_loss_val = self.ce_loss(student_logits, labels)\n",
    "        \n",
    "        # KL divergence loss for soft targets (teacher ensemble)\n",
    "        kl_loss_val = torch.tensor(0.0, device=student_logits.device)\n",
    "        if teacher_ensemble_logits is not None and alpha_e > 0: # Only compute if needed\n",
    "            # Using a single temperature for the ensemble target for simplicity here,\n",
    "            # as individual teacher temps are handled by teacher_weighting.get_weighted_ensemble\n",
    "            temp_ensemble = self.config.soft_target_temp \n",
    "            # Ensure teacher_ensemble_logits is detached if not already\n",
    "            soft_targets = F.softmax(teacher_ensemble_logits.detach() / temp_ensemble, dim=1) \n",
    "            soft_prob = F.log_softmax(student_logits / temp_ensemble, dim=1)\n",
    "            # Use log_target=False for KLDivLoss when targets are probabilities\n",
    "            kl_loss_val = F.kl_div(soft_prob, soft_targets, reduction='batchmean', log_target=False) * (temp_ensemble ** 2) \n",
    "            # Note: Original KLDivLoss expects log-probabilities for input and probabilities for target.\n",
    "            # If soft_targets are probabilities (output of softmax), log_target should be False.\n",
    "            # If soft_targets were log-probabilities, log_target should be True.\n",
    "            # The scaling by T^2 is common practice in distillation.\n",
    "\n",
    "        # Calculate calibration loss (using the separate function)\n",
    "        # This is calculated outside based on student logits only\n",
    "        cal_loss_val = CalibrationMetrics.calibration_loss(student_logits, labels)\n",
    "        \n",
    "        # Combine CE and KL using the dynamic alpha_e\n",
    "        distillation_component_loss = (1 - alpha_e) * ce_loss_val + alpha_e * kl_loss_val\n",
    "        \n",
    "        # Return all components for logging and final combination\n",
    "        # The 'cal_loss' returned here is the one calculated based on student logits.\n",
    "        return distillation_component_loss, ce_loss_val, kl_loss_val, cal_loss_val\n",
    "\n",
    "class FeatureAlignmentLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureAlignmentLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.projections = {}  # Cache projections for efficiency\n",
    "        \n",
    "    def forward(self, student_features, teacher_features):\n",
    "        # Log shape information for debugging\n",
    "        student_shape = student_features.shape\n",
    "        teacher_shape = teacher_features.shape\n",
    "        \n",
    "        # If dimensions don't match, apply transformations\n",
    "        if student_shape != teacher_shape:\n",
    "            # Get shape information\n",
    "            if len(student_shape) == 4:  # 2D features (B, C, H, W)\n",
    "                batch_size, student_channels, student_h, student_w = student_shape\n",
    "                batch_size, teacher_channels, teacher_h, teacher_w = teacher_shape\n",
    "                \n",
    "                # Step 1: Handle spatial dimensions with adaptive pooling\n",
    "                if student_h != teacher_h or student_w != teacher_w:\n",
    "                    spatial_pool = nn.AdaptiveAvgPool2d((teacher_h, teacher_w))\n",
    "                    student_features = spatial_pool(student_features)\n",
    "                \n",
    "                # Step 2: Handle channel dimension mismatch with 1x1 convolution\n",
    "                if student_channels != teacher_channels:\n",
    "                    key = f\"{student_channels}_{teacher_channels}\"\n",
    "                    if key not in self.projections:\n",
    "                        # Create and cache a 1x1 convolution for channel projection\n",
    "                        self.projections[key] = nn.Conv2d(\n",
    "                            student_channels, teacher_channels, kernel_size=1, bias=False\n",
    "                        ).to(student_features.device)\n",
    "                        # Initialize with identity-like weights if possible\n",
    "                        if student_channels <= teacher_channels:\n",
    "                            # Partial identity initialization (first channels are copied)\n",
    "                            with torch.no_grad():\n",
    "                                self.projections[key].weight[:student_channels].fill_diagonal_(1.0)\n",
    "                    \n",
    "                    # Apply the channel projection\n",
    "                    student_features = self.projections[key](student_features)\n",
    "                \n",
    "            elif len(student_shape) == 2:  # 1D features (B, C)\n",
    "                batch_size, student_channels = student_shape\n",
    "                batch_size, teacher_channels = teacher_shape\n",
    "                \n",
    "                # Handle channel dimension mismatch with linear projection\n",
    "                if student_channels != teacher_channels:\n",
    "                    key = f\"{student_channels}_{teacher_channels}\"\n",
    "                    if key not in self.projections:\n",
    "                        # Create and cache a linear projection\n",
    "                        self.projections[key] = nn.Linear(\n",
    "                            student_channels, teacher_channels, bias=False\n",
    "                        ).to(student_features.device)\n",
    "                        # Initialize with partial identity if possible\n",
    "                        if student_channels <= teacher_channels:\n",
    "                            with torch.no_grad():\n",
    "                                torch.nn.init.eye_(self.projections[key].weight[:student_channels, :student_channels])\n",
    "                    \n",
    "                    # Apply the linear projection\n",
    "                    student_features = self.projections[key](student_features)\n",
    "                    \n",
    "            elif len(student_shape) == 3:  # Sequence features (B, L, C)\n",
    "                batch_size, student_len, student_channels = student_shape\n",
    "                batch_size, teacher_len, teacher_channels = teacher_shape\n",
    "                \n",
    "                # Handle sequence length mismatch\n",
    "                if student_len != teacher_len:\n",
    "                    # Use adaptive pooling along sequence dimension\n",
    "                    student_features = student_features.transpose(1, 2)  # (B, C, L)\n",
    "                    student_features = F.adaptive_avg_pool1d(student_features, teacher_len)\n",
    "                    student_features = student_features.transpose(1, 2)  # Back to (B, L, C)\n",
    "                \n",
    "                # Handle channel dimension mismatch\n",
    "                if student_channels != teacher_channels:\n",
    "                    key = f\"seq_{student_channels}_{teacher_channels}\"\n",
    "                    if key not in self.projections:\n",
    "                        # Create and cache a linear projection for this dimension\n",
    "                        self.projections[key] = nn.Linear(\n",
    "                            student_channels, teacher_channels, bias=False\n",
    "                        ).to(student_features.device)\n",
    "                    \n",
    "                    # Apply the channel projection\n",
    "                    student_features = self.projections[key](student_features)\n",
    "        \n",
    "        # Verify the shapes match after transformation\n",
    "        if student_features.shape != teacher_features.shape:\n",
    "            # If still not matching, try a last-resort reshape if dimensions are compatible\n",
    "            total_student_elements = student_features.numel() // student_features.size(0)\n",
    "            total_teacher_elements = teacher_features.numel() // teacher_features.size(0)\n",
    "            \n",
    "            if total_student_elements == total_teacher_elements:\n",
    "                student_features = student_features.view(teacher_features.shape)\n",
    "            else:\n",
    "                logger.warning(f\"Could not align features: student {student_features.shape} vs teacher {teacher_features.shape}\")\n",
    "                # Fall back to using the mean of each feature map to avoid crash\n",
    "                if len(student_features.shape) == 4:\n",
    "                    student_features = student_features.mean(dim=[2, 3], keepdim=True).expand_as(teacher_features)\n",
    "                elif len(student_features.shape) == 3:\n",
    "                    student_features = student_features.mean(dim=1, keepdim=True).expand_as(teacher_features)\n",
    "                elif len(student_features.shape) == 2:\n",
    "                    student_features = student_features.mean(dim=1, keepdim=True).expand_as(teacher_features)\n",
    "        \n",
    "        # Apply MSE loss on aligned features\n",
    "        return self.mse_loss(student_features, teacher_features)\n",
    "\n",
    "# Feature extraction\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, model, layer_name):\n",
    "        self.model = model\n",
    "        self.features = None\n",
    "        \n",
    "        # Flag to track if hook was registered successfully\n",
    "        self.hook_registered = False\n",
    "        \n",
    "        # Register hook to extract features\n",
    "        for name, module in model.named_modules():\n",
    "            if layer_name in name:  # More flexible matching\n",
    "                module.register_forward_hook(self.hook)\n",
    "                self.hook_registered = True\n",
    "                logger.info(f\"Hook registered for {name}\")\n",
    "                break\n",
    "        \n",
    "        if not self.hook_registered:\n",
    "            logger.warning(f\"Could not find layer {layer_name} in model, listing available layers:\")\n",
    "            for name, _ in model.named_modules():\n",
    "                logger.warning(f\"  - {name}\")\n",
    "                \n",
    "    def hook(self, module, input, output):\n",
    "        self.features = output\n",
    "        \n",
    "    def get_features(self, x):\n",
    "        _ = self.model(x)\n",
    "        return self.features\n",
    "\n",
    "# Heterogeneous Feature Integration (HFI)\n",
    "class HeterogeneousFeatureIntegrator(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements the Heterogeneous Feature Integration (HFI) mechanism described in the paper.\n",
    "    This module fuses features from multiple teacher models using learnable projections and attention weights.\n",
    "    \"\"\"\n",
    "    def __init__(self, teacher_feature_shapes, student_feature_shape):\n",
    "        super(HeterogeneousFeatureIntegrator, self).__init__()\n",
    "        self.teacher_names = list(teacher_feature_shapes.keys())\n",
    "        self.K = len(self.teacher_names)\n",
    "        \n",
    "        # Step 2: Learnable projections (φ_j)\n",
    "        # Create projection networks for each teacher\n",
    "        self.projections = nn.ModuleDict()\n",
    "        \n",
    "        for teacher_name, feature_shape in teacher_feature_shapes.items():\n",
    "            # Different projection types based on tensor dimensions\n",
    "            if len(feature_shape) == 4:  # CNN features (B, C, H, W)\n",
    "                # 1x1 convolution to match student channels\n",
    "                self.projections[teacher_name] = nn.Conv2d(\n",
    "                    feature_shape[1], student_feature_shape[1], kernel_size=1, bias=False\n",
    "                )\n",
    "            elif len(feature_shape) == 3:  # Transformer features (B, L, D)\n",
    "                # Linear projection for sequence features\n",
    "                self.projections[teacher_name] = nn.Linear(\n",
    "                    feature_shape[2], student_feature_shape[1], bias=False\n",
    "                )\n",
    "            elif len(feature_shape) == 2:  # Vector features (B, D)\n",
    "                # Linear projection for vector features\n",
    "                self.projections[teacher_name] = nn.Linear(\n",
    "                    feature_shape[1], student_feature_shape[1], bias=False\n",
    "                )\n",
    "        \n",
    "        # Step 3: Learnable attention weights (W)\n",
    "        # Initialize with zeros, softmax will be applied during forward pass\n",
    "        self.attention_weights = nn.Parameter(torch.zeros(self.K))\n",
    "        \n",
    "        # Store shapes for spatial adaptations\n",
    "        self.student_feature_shape = student_feature_shape\n",
    "        self.teacher_feature_shapes = teacher_feature_shapes\n",
    "        \n",
    "        logger.info(f\"HFI module initialized with {self.K} teachers\")\n",
    "        logger.info(f\"Target student feature shape: {student_feature_shape}\")\n",
    "    \n",
    "    def forward(self, teacher_features):\n",
    "        \"\"\"\n",
    "        Fuse features from multiple teachers using learned projections and attention.\n",
    "        \n",
    "        Args:\n",
    "            teacher_features: Dict with teacher_name -> feature_tensor\n",
    "        \n",
    "        Returns:\n",
    "            Fused feature tensor with same shape as student features\n",
    "        \"\"\"\n",
    "        device = self.attention_weights.device\n",
    "        batch_size = list(teacher_features.values())[0].size(0)\n",
    "        \n",
    "        # Step 3: Calculate attention weights (α) using softmax\n",
    "        alpha = F.softmax(self.attention_weights, dim=0)\n",
    "        \n",
    "        # For logging/debugging\n",
    "        alpha_dict = {name: alpha[i].item() for i, name in enumerate(self.teacher_names)}\n",
    "        \n",
    "        # Step 4: Project and fuse teacher features\n",
    "        fused_features = None\n",
    "        \n",
    "        for i, teacher_name in enumerate(self.teacher_names):\n",
    "            if teacher_name not in teacher_features:\n",
    "                continue\n",
    "                \n",
    "            # Get teacher features\n",
    "            feat = teacher_features[teacher_name]\n",
    "            \n",
    "            # Get projection for this teacher\n",
    "            proj = self.projections[teacher_name]\n",
    "            \n",
    "            # Project features to common space (φ_j(f_j))\n",
    "            if len(feat.shape) == 4:  # CNN features\n",
    "                # Apply 1x1 convolution\n",
    "                projected = proj(feat)\n",
    "                # Ensure spatial dimensions match student's using adaptive pooling\n",
    "                if projected.shape[2:] != self.student_feature_shape[2:]:\n",
    "                    projected = F.adaptive_avg_pool2d(\n",
    "                        projected, output_size=self.student_feature_shape[2:]\n",
    "                    )\n",
    "            elif len(feat.shape) == 3:  # Transformer features\n",
    "                # For sequence features, we need special handling\n",
    "                if isinstance(proj, nn.Linear):\n",
    "                    # Apply linear projection along sequence dimension\n",
    "                    projected = proj(feat)\n",
    "                    # Reshape to match student's CNN format if needed\n",
    "                    if len(self.student_feature_shape) == 4:\n",
    "                        # Convert (B, L, D) to (B, D, H, W) format\n",
    "                        seq_len = projected.size(1)\n",
    "                        channels = projected.size(2)\n",
    "                        # Try to find factors for H,W that multiply to seq_len\n",
    "                        h = int(np.sqrt(seq_len))\n",
    "                        w = seq_len // h\n",
    "                        if h * w == seq_len:\n",
    "                            # Perfect square, reshape directly\n",
    "                            projected = projected.transpose(1, 2).reshape(\n",
    "                                batch_size, channels, h, w\n",
    "                            )\n",
    "                        else:\n",
    "                            # Not perfect square, use adaptive pooling\n",
    "                            projected = projected.transpose(1, 2).unsqueeze(-1)  # B, D, L, 1\n",
    "                            projected = F.adaptive_avg_pool2d(\n",
    "                                projected, output_size=self.student_feature_shape[2:]\n",
    "                            )\n",
    "            elif len(feat.shape) == 2:  # Vector features\n",
    "                # Project vector features\n",
    "                projected = proj(feat)\n",
    "                # Reshape to match student's format if needed\n",
    "                if len(self.student_feature_shape) == 4:\n",
    "                    # Reshape (B, D) to (B, D, 1, 1) then expand\n",
    "                    projected = projected.unsqueeze(-1).unsqueeze(-1)\n",
    "                    projected = projected.expand(\n",
    "                        -1, -1, self.student_feature_shape[2], self.student_feature_shape[3]\n",
    "                    )\n",
    "                elif len(self.student_feature_shape) == 3:\n",
    "                    # Reshape (B, D) to (B, 1, D) then expand\n",
    "                    projected = projected.unsqueeze(1)\n",
    "                    projected = projected.expand(-1, self.student_feature_shape[1], -1)\n",
    "            \n",
    "            # Step 4: Feature Fusion with attention weights\n",
    "            # α[j] * φ_j(f_j)\n",
    "            weighted = alpha[i] * projected\n",
    "            \n",
    "            if fused_features is None:\n",
    "                fused_features = weighted\n",
    "            else:\n",
    "                # Handle potential shape mismatch \n",
    "                if weighted.shape != fused_features.shape:\n",
    "                    # Try to adapt weighted feature to match fused shape\n",
    "                    if len(weighted.shape) == len(fused_features.shape):\n",
    "                        if len(weighted.shape) == 4:  # CNN features\n",
    "                            weighted = F.adaptive_avg_pool2d(\n",
    "                                weighted, output_size=fused_features.shape[2:]\n",
    "                            )\n",
    "                        elif len(weighted.shape) == 3:  # Sequence features\n",
    "                            weighted = F.adaptive_avg_pool1d(\n",
    "                                weighted.transpose(1, 2), fused_features.shape[1]\n",
    "                            ).transpose(1, 2)\n",
    "                \n",
    "                # Add to fusion\n",
    "                fused_features = fused_features + weighted\n",
    "        \n",
    "        return fused_features\n",
    "\n",
    "# Training and evaluation functions\n",
    "def fine_tune_teacher(teacher, model_name, train_loader, val_loader, config, epoch_callback=None):\n",
    "    \"\"\"Fine-tune a single teacher model on CIFAR-10\"\"\"\n",
    "    logger.info(f\"Fine-tuning {model_name} teacher model...\")\n",
    "    \n",
    "    # Freeze the backbone if configured\n",
    "    if config.freeze_teacher_backbones:\n",
    "        teacher = freeze_teacher_backbone(teacher, model_name)\n",
    "        \n",
    "    # Optimizer and loss\n",
    "    optimizer = optim.Adam([p for p in teacher.parameters() if p.requires_grad], \n",
    "                          lr=config.lr, weight_decay=config.weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=config.teacher_finetune_epochs)\n",
    "    scaler = GradScaler() if config.use_amp else None\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_state_dict = None\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(config.teacher_finetune_epochs):\n",
    "        # Training phase\n",
    "        teacher.train()\n",
    "        train_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"{model_name} Epoch {epoch+1}/{config.teacher_finetune_epochs}\")\n",
    "        for inputs, labels in pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass with mixed precision - ADD DEVICE TYPE\n",
    "            with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu', enabled=config.use_amp):\n",
    "                outputs = teacher(inputs)\n",
    "                \n",
    "                # Handle inception output format\n",
    "                if model_name == 'inception' and isinstance(outputs, tuple):\n",
    "                    outputs = outputs[0]\n",
    "                    \n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "            # Backward pass with mixed precision\n",
    "            if config.use_amp:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            # Update statistics\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': train_loss / (pbar.n + 1),\n",
    "                'acc': 100. * correct / total\n",
    "            })\n",
    "        \n",
    "        train_acc = 100. * correct / total\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        teacher.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu', enabled=config.use_amp):\n",
    "                    outputs = teacher(inputs)\n",
    "                    \n",
    "                    # Handle inception output format\n",
    "                    if model_name == 'inception' and isinstance(outputs, tuple):\n",
    "                        outputs = outputs[0]\n",
    "                        \n",
    "                    loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_acc = 100. * correct / total\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        logger.info(f\"{model_name} Epoch {epoch+1}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.2f}%, \"\n",
    "                   f\"Val Loss={val_loss:.4f}, Val Acc={val_acc:.2f}%\")\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_state_dict = teacher.state_dict()\n",
    "            logger.info(f\"New best model for {model_name} (Val Loss: {val_loss:.4f})\")\n",
    "        \n",
    "        # Log to tensorboard\n",
    "        writer.add_scalar(f'teacher/{model_name}/train_loss', train_loss, epoch)\n",
    "        writer.add_scalar(f'teacher/{model_name}/train_acc', train_acc, epoch)\n",
    "        writer.add_scalar(f'teacher/{model_name}/val_loss', val_loss, epoch)\n",
    "        writer.add_scalar(f'teacher/{model_name}/val_acc', val_acc, epoch)\n",
    "        \n",
    "        # Call epoch callback if provided\n",
    "        if epoch_callback:\n",
    "            epoch_callback(epoch, train_loss, train_acc, val_loss, val_acc)\n",
    "        \n",
    "        # Clear GPU cache\n",
    "        if epoch % config.clear_cache_every_n_epochs == 0:\n",
    "            clear_gpu_cache()\n",
    "    \n",
    "    # Restore best model and save\n",
    "    if best_state_dict is not None:\n",
    "        teacher.load_state_dict(best_state_dict)\n",
    "        save_path = os.path.join(config.checkpoint_dir, f\"{model_name}_teacher.pth\")\n",
    "        torch.save({\n",
    "            'model_state_dict': best_state_dict,\n",
    "            'val_loss': best_val_loss,\n",
    "        }, save_path)\n",
    "        logger.info(f\"Saved best {model_name} teacher model to {save_path}\")\n",
    "    \n",
    "    return teacher\n",
    "\n",
    "# Teacher Weighting\n",
    "class TeacherWeighting:\n",
    "    def __init__(self, config, device):\n",
    "        \"\"\"Initialize teacher weighting mechanism\"\"\"\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "        self.teacher_names = config.teacher_models\n",
    "        \n",
    "        # Initialize weights based on config\n",
    "        self.weights = {name: config.teacher_init_weights.get(name, 1.0) for name in self.teacher_names}\n",
    "        self.normalized_weights = self._normalize_weights()\n",
    "        \n",
    "        # Initialize temperatures based on config\n",
    "        self.temperatures = {name: config.teacher_temperatures.get(name, config.soft_target_temp) for name in self.teacher_names}\n",
    "        \n",
    "        # If temperatures are learnable, create parameters\n",
    "        self.learnable_temps = None\n",
    "        if config.learn_temperatures:\n",
    "            self.learnable_temps = nn.ParameterDict({\n",
    "                name: nn.Parameter(torch.tensor(temp).to(device))\n",
    "                for name, temp in self.temperatures.items()\n",
    "            })\n",
    "        \n",
    "        # Track metrics for each teacher\n",
    "        self.teacher_metrics = {\n",
    "            name: {\n",
    "                'accuracy': config.teacher_accuracies.get(name, 90.0),  # Default to 90% if not specified\n",
    "                'ece': 0.05,  # Initial ECE estimate\n",
    "                'batch_entropies': [],\n",
    "                'batch_accuracies': []\n",
    "            }\n",
    "            for name in self.teacher_names\n",
    "        }\n",
    "        \n",
    "        # Dynamic gating status (1 = active, 0 = gated/pruned)\n",
    "        self.gating_status = {name: 1.0 for name in self.teacher_names}\n",
    "        \n",
    "        logger.info(f\"Teacher weighting initialized with scheme: {config.weighting_scheme}\")\n",
    "        logger.info(f\"Initial teacher weights: {self.normalized_weights}\")\n",
    "        logger.info(f\"Initial teacher temperatures: {self.temperatures}\")\n",
    "    \n",
    "    def _normalize_weights(self):\n",
    "        \"\"\"Normalize weights to sum to 1\"\"\"\n",
    "        total = sum(self.weights.values())\n",
    "        if total > 0:\n",
    "            return {name: weight / total for name, weight in self.weights.items()}\n",
    "        return {name: 1.0 / len(self.weights) for name in self.weights}\n",
    "    \n",
    "    def get_temperature(self, teacher_name):\n",
    "        \"\"\"Get temperature for a specific teacher\"\"\"\n",
    "        if self.learnable_temps is not None:\n",
    "            # Use learned temperature (with positive constraint)\n",
    "            return torch.abs(self.learnable_temps[teacher_name]) + 1.0\n",
    "        else:\n",
    "            # Use fixed temperature\n",
    "            return self.temperatures[teacher_name]\n",
    "    \n",
    "    def update_metrics(self, teacher_outputs, labels, teacher_names):\n",
    "        \"\"\"Update accuracy and calibration metrics for teachers\"\"\"\n",
    "        batch_size = labels.size(0)\n",
    "        \n",
    "        for i, name in enumerate(teacher_names):\n",
    "            outputs = teacher_outputs[i]\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = outputs.max(1)\n",
    "            accuracy = (predicted == labels).float().mean().item() * 100\n",
    "            \n",
    "            # Calculate entropy\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            log_probs = F.log_softmax(outputs, dim=1)\n",
    "            entropy = -(probs * log_probs).sum(dim=1).mean().item()\n",
    "            \n",
    "            # Calculate ECE\n",
    "            ece = CalibrationMetrics.compute_ece(probs, labels).item()\n",
    "            \n",
    "            # Update metrics\n",
    "            self.teacher_metrics[name]['batch_accuracies'].append(accuracy)\n",
    "            self.teacher_metrics[name]['batch_entropies'].append(entropy)\n",
    "            self.teacher_metrics[name]['ece'] = ece\n",
    "    \n",
    "    def update_weights(self, validation=False):\n",
    "        \"\"\"Update teacher weights based on the selected scheme\"\"\"\n",
    "        if not self.config.dynamic_weight_update and not validation:\n",
    "            return\n",
    "        \n",
    "        scheme = self.config.weighting_scheme\n",
    "        \n",
    "        if scheme == 'fixed':\n",
    "            # Use fixed weights from config\n",
    "            pass\n",
    "        \n",
    "        elif scheme == 'accuracy':\n",
    "            # Weight by accuracy\n",
    "            for name in self.teacher_names:\n",
    "                acc = self.teacher_metrics[name]['accuracy']\n",
    "                self.weights[name] = acc / 100.0  # Normalize to [0, 1]\n",
    "        \n",
    "        elif scheme == 'calibration':\n",
    "            # Weight inversely by ECE (lower ECE = better calibration = higher weight)\n",
    "            for name in self.teacher_names:\n",
    "                ece = max(0.01, self.teacher_metrics[name]['ece'])  # Avoid division by zero\n",
    "                self.weights[name] = 1.0 / (ece * 10.0)  # Scale for reasonable values\n",
    "        \n",
    "        elif scheme == 'adaptive':\n",
    "            # Combine accuracy and calibration\n",
    "            for name in self.teacher_names:\n",
    "                acc = self.teacher_metrics[name]['accuracy'] / 100.0\n",
    "                ece = max(0.01, self.teacher_metrics[name]['ece'])\n",
    "                # Higher accuracy and lower ECE = higher weight\n",
    "                self.weights[name] = acc / (ece * 5.0 + 0.1)\n",
    "        \n",
    "        # Apply gating if enabled\n",
    "        if self.config.use_teacher_gating:\n",
    "            for name in self.teacher_names:\n",
    "                # Apply binary gating (on/off)\n",
    "                if self.weights[name] < self.config.gating_threshold:\n",
    "                    self.gating_status[name] = 0.0\n",
    "                else:\n",
    "                    self.gating_status[name] = 1.0\n",
    "                \n",
    "                # Apply gating to weights\n",
    "                self.weights[name] *= self.gating_status[name]\n",
    "        \n",
    "        # Normalize weights\n",
    "        self.normalized_weights = self._normalize_weights()\n",
    "        \n",
    "        # Log updated weights\n",
    "        if validation:\n",
    "            logger.info(f\"Updated teacher weights: {self.normalized_weights}\")\n",
    "            logger.info(f\"Teacher gating status: {self.gating_status}\")\n",
    "    \n",
    "    def get_weighted_ensemble(self, outputs, teacher_names):\n",
    "        \"\"\"Combine teacher outputs using current weights\"\"\"\n",
    "        weighted_outputs = []\n",
    "        \n",
    "        for i, name in enumerate(teacher_names):\n",
    "            # Apply temperature scaling\n",
    "            temp = self.get_temperature(name) if self.config.use_adaptive_temperature else self.config.soft_target_temp\n",
    "            scaled_output = outputs[i] / temp\n",
    "            \n",
    "            # Apply weight\n",
    "            weight = self.normalized_weights[name]\n",
    "            weighted_outputs.append(scaled_output * weight)\n",
    "        \n",
    "        # Sum weighted outputs\n",
    "        ensemble_output = sum(weighted_outputs)\n",
    "        \n",
    "        return ensemble_output\n",
    "\n",
    "def get_ensemble_predictions(teachers, inputs, config, teacher_weighting=None):\n",
    "    \"\"\"Get ensemble predictions from all teacher models with calibration-aware weighting\"\"\"\n",
    "    ensemble_outputs = []\n",
    "    teacher_raw_outputs = []\n",
    "    teacher_names = []\n",
    "    \n",
    "    for name, model in teachers.items():\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu', enabled=config.use_amp):\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Handle inception output format\n",
    "                if name == 'inception' and isinstance(outputs, tuple):\n",
    "                    outputs = outputs[0]\n",
    "                \n",
    "                teacher_raw_outputs.append(outputs)\n",
    "                teacher_names.append(name)\n",
    "    \n",
    "    # If teacher weighting is provided, use it to get weighted predictions\n",
    "    if teacher_weighting is not None:\n",
    "        # Update teacher metrics\n",
    "        with torch.no_grad():\n",
    "            labels = torch.argmax(teacher_raw_outputs[0], dim=1)  # Use first teacher's predictions as pseudo-labels\n",
    "            teacher_weighting.update_metrics(teacher_raw_outputs, labels, teacher_names)\n",
    "        \n",
    "        # Get weighted ensemble\n",
    "        ensemble_pred = teacher_weighting.get_weighted_ensemble(teacher_raw_outputs, teacher_names)\n",
    "    else:\n",
    "        # Simple averaging (original method)\n",
    "        ensemble_pred = torch.mean(torch.stack(teacher_raw_outputs), dim=0)\n",
    "    \n",
    "    return ensemble_pred, teacher_raw_outputs, teacher_names\n",
    "\n",
    "class EnhancedDistillationLoss(nn.Module):\n",
    "    def __init__(self, config, teacher_weighting=None):\n",
    "        super(EnhancedDistillationLoss, self).__init__()\n",
    "        self.config = config\n",
    "        self.alpha = config.alpha\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.teacher_weighting = teacher_weighting\n",
    "        \n",
    "    def forward(self, student_logits, teacher_ensemble_logits, teacher_individual_logits, \n",
    "                teacher_names, labels):\n",
    "        # Cross-entropy loss for hard labels\n",
    "        ce_loss = self.ce_loss(student_logits, labels)\n",
    "        \n",
    "        # KL divergence loss for soft targets (teacher ensemble)\n",
    "        # Use global temperature if teacher_weighting is not provided\n",
    "        if self.teacher_weighting is None or not self.config.use_adaptive_temperature:\n",
    "            temp = self.config.soft_target_temp\n",
    "            soft_targets = F.softmax(teacher_ensemble_logits / temp, dim=1)\n",
    "            soft_prob = F.log_softmax(student_logits / temp, dim=1)\n",
    "            kl_loss = F.kl_div(soft_prob, soft_targets, reduction='batchmean') * (temp ** 2)\n",
    "        else:\n",
    "            # Use teacher-specific temperature scaling and weights\n",
    "            kl_losses = []\n",
    "            weights = []\n",
    "            \n",
    "            for i, name in enumerate(teacher_names):\n",
    "                # Get teacher-specific temperature\n",
    "                temp = self.teacher_weighting.get_temperature(name)\n",
    "                \n",
    "                # Get teacher weight\n",
    "                weight = self.teacher_weighting.normalized_weights[name]\n",
    "                \n",
    "                # Calculate KL divergence with this teacher\n",
    "                teacher_logits = teacher_individual_logits[i]\n",
    "                soft_targets = F.softmax(teacher_logits / temp, dim=1)\n",
    "                soft_prob = F.log_softmax(student_logits / temp, dim=1)\n",
    "                teacher_kl = F.kl_div(soft_prob, soft_targets, reduction='batchmean') * (temp ** 2)\n",
    "                \n",
    "                kl_losses.append(teacher_kl)\n",
    "                weights.append(weight)\n",
    "            \n",
    "            # Weight KL losses by teacher weights\n",
    "            if self.config.weight_by_calibration:\n",
    "                kl_loss = sum(w * l for w, l in zip(weights, kl_losses))\n",
    "            else:\n",
    "                # Simple average if not weighting by calibration\n",
    "                kl_loss = sum(kl_losses) / len(kl_losses)\n",
    "        \n",
    "        # Calculate per-teacher calibration loss if enabled\n",
    "        cal_loss = 0\n",
    "        if self.config.per_teacher_calibration and self.teacher_weighting is not None:\n",
    "            cal_losses = []\n",
    "            \n",
    "            for i, name in enumerate(teacher_names):\n",
    "                # Get teacher weight\n",
    "                weight = self.teacher_weighting.normalized_weights[name]\n",
    "                \n",
    "                # Calculate calibration loss for this teacher\n",
    "                teacher_cal_loss = CalibrationMetrics.calibration_loss(student_logits, labels)\n",
    "                cal_losses.append(teacher_cal_loss * weight)\n",
    "            \n",
    "            cal_loss = sum(cal_losses)\n",
    "        else:\n",
    "            # Use standard calibration loss\n",
    "            cal_loss = CalibrationMetrics.calibration_loss(student_logits, labels)\n",
    "        \n",
    "        # Combine losses using alpha as weight\n",
    "        loss = (1 - self.alpha) * ce_loss + self.alpha * kl_loss\n",
    "        \n",
    "        return loss, ce_loss, kl_loss, cal_loss\n",
    "\n",
    "def validate(model, val_loader, criterion, config):\n",
    "    \"\"\"Validate the model and compute metrics\"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(val_loader, desc=\"Validating\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass with mixed precision\n",
    "            with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu', enabled=config.use_amp):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Update statistics\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            # Store for metrics calculation\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_probs.append(F.softmax(outputs, dim=1).cpu())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    all_probs = torch.cat(all_probs, dim=0)\n",
    "    all_targets_tensor = torch.tensor(all_targets)\n",
    "    \n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    f1 = f1_score(all_targets, all_predictions, average='macro')\n",
    "    ece = CalibrationMetrics.compute_ece(all_probs, all_targets_tensor).item()\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    precision = precision_score(all_targets, all_predictions, average='macro')\n",
    "    recall = recall_score(all_targets, all_predictions, average='macro')\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': val_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'ece': ece\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# REPLACE the existing train_student function with this one:\n",
    "def train_student(student, teachers, train_loader, val_loader, config):\n",
    "    \"\"\"Train the student model with knowledge distillation from teachers\"\"\"\n",
    "    logger.info(\"Training student model with ensemble distillation (ACP enabled)...\") # Updated log message\n",
    "    \n",
    "    teacher_weighting = TeacherWeighting(config, device)\n",
    "    distil_loss_fn = EnhancedDistillationLoss(config, teacher_weighting) # Pass teacher_weighting\n",
    "    feature_loss_fn = FeatureAlignmentLoss() # This is MSELoss with adaptation\n",
    "    # calibration_loss_fn is CalibrationMetrics.calibration_loss (MSE-based)\n",
    "\n",
    "    teacher_feature_extractors = {}\n",
    "    teacher_feature_layers = {'vit': 'encoder.ln', 'efficientnet': 'features.8', 'inception': 'Mixed_7c', 'mobilenet': 'features.15.block.2', 'resnet': 'layer4', 'densenet': 'features.norm5'} # Example layers\n",
    "    teacher_feature_shapes = {}\n",
    "    for name, model in teachers.items():\n",
    "        layer_name = teacher_feature_layers.get(name)\n",
    "        if layer_name:\n",
    "            teacher_feature_extractors[name] = FeatureExtractor(model, layer_name)\n",
    "            if teacher_feature_extractors[name].hook_registered:\n",
    "                with torch.no_grad():\n",
    "                    # Use a smaller dummy input to save memory during this check\n",
    "                    dummy_input = torch.randn(1, 3, config.model_input_size // 2, config.model_input_size // 2).to(device)\n",
    "                    dummy_input_resized = F.interpolate(dummy_input, size=(config.model_input_size, config.model_input_size), mode='bilinear', align_corners=False)\n",
    "                    _ = model(dummy_input_resized) # Forward pass to populate features\n",
    "                    if teacher_feature_extractors[name].features is not None:\n",
    "                        # Store shape excluding batch dimension\n",
    "                        teacher_feature_shapes[name] = teacher_feature_extractors[name].features.shape[1:] \n",
    "                        logger.info(f\"Feature shape for {name}: {teacher_feature_shapes[name]}\")\n",
    "                    else: logger.warning(f\"Dummy pass for {name} did not yield features.\")\n",
    "            else: logger.warning(f\"Feature extractor failed for {name} at layer {layer_name}\")\n",
    "    \n",
    "    student_feature_extractor = FeatureExtractor(student, 'features.8') # Student's feature layer\n",
    "    student_feature_shape = None\n",
    "    if student_feature_extractor.hook_registered:\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, 3, config.model_input_size // 2, config.model_input_size // 2).to(device)\n",
    "            dummy_input_resized = F.interpolate(dummy_input, size=(config.model_input_size, config.model_input_size), mode='bilinear', align_corners=False)\n",
    "            _ = student(dummy_input_resized)\n",
    "            if student_feature_extractor.features is not None:\n",
    "                student_feature_shape = student_feature_extractor.features.shape[1:] # Exclude batch\n",
    "                logger.info(f\"Feature shape for student: {student_feature_shape}\")\n",
    "    \n",
    "    hfi_module = None\n",
    "    if teacher_feature_shapes and student_feature_shape:\n",
    "        try:\n",
    "            hfi_module = HeterogeneousFeatureIntegrator(teacher_feature_shapes, student_feature_shape).to(device)\n",
    "            optimizer_params = list(student.parameters()) + list(hfi_module.parameters())\n",
    "            logger.info(\"HFI module initialized and its parameters added to optimizer.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"HFI module initialization failed: {e}. Disabling feature loss.\")\n",
    "            hfi_module = None\n",
    "            optimizer_params = list(student.parameters())\n",
    "            config.feature_loss_weight = 0 # Ensure feature loss is disabled\n",
    "    else:\n",
    "        logger.warning(\"HFI module not initialized due to missing feature shapes. Feature loss disabled.\")\n",
    "        optimizer_params = list(student.parameters())\n",
    "        config.feature_loss_weight = 0\n",
    "\n",
    "    if config.learn_temperatures and teacher_weighting.learnable_temps is not None:\n",
    "        optimizer_params += list(teacher_weighting.learnable_temps.parameters())\n",
    "        logger.info(\"Learnable teacher temperatures added to optimizer.\")\n",
    "    \n",
    "    optimizer = optim.AdamW(optimizer_params, lr=config.lr, weight_decay=config.weight_decay)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=config.epochs)\n",
    "    scaler = GradScaler(enabled=config.use_amp)\n",
    "    \n",
    "    best_val_loss = float('inf'); best_val_acc = 0.0; early_stop_counter = 0\n",
    "    # Added alpha_weights and feature_loss_weights to history tracking\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'val_ece': [], 'val_f1': [],\n",
    "               'ce_loss': [], 'kl_loss': [], 'feature_loss': [], 'cal_loss': [],\n",
    "               'alpha_weights': [], 'feature_loss_weights': [], 'calibration_weights': [], # ACP weights\n",
    "               'teacher_weights': [], 'teacher_temperatures': [], 'teacher_gating': [], 'hfi_weights': [], 'best_epoch': 0}\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\"); model_name_ts = f\"{config.model_name}_{timestamp}\"\n",
    "    config_path = os.path.join(config.results_dir, f\"{model_name_ts}_config.json\"); config.save(config_path)\n",
    "    logger.info(f\"Config saved to {config_path}\")\n",
    "    print_gpu_memory_stats()\n",
    "    \n",
    "    for epoch in range(config.epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        logger.info(f\"--- Epoch {epoch+1}/{config.epochs} ---\")\n",
    "        clear_gpu_cache()\n",
    "        \n",
    "        # --- Get dynamic weights from ACP ---\n",
    "        alpha_e = config.get_alpha_weight(epoch)\n",
    "        feature_weight_e = config.get_feature_loss_weight(epoch)\n",
    "        cal_weight_e = config.get_calibration_weight(epoch)\n",
    "        history['alpha_weights'].append(alpha_e)\n",
    "        history['feature_loss_weights'].append(feature_weight_e)\n",
    "        history['calibration_weights'].append(cal_weight_e)\n",
    "        logger.info(f\"ACP Weights - Alpha(KL): {alpha_e:.4f}, Feature: {feature_weight_e:.4f}, Cal: {cal_weight_e:.4f}\")\n",
    "        # --- End Get dynamic weights ---\n",
    "\n",
    "        teacher_weighting.update_weights(validation=True) # Update based on previous val metrics or initial\n",
    "        history['teacher_weights'].append(dict(teacher_weighting.normalized_weights))\n",
    "        if config.learn_temperatures and teacher_weighting.learnable_temps:\n",
    "            history['teacher_temperatures'].append({name: teacher_weighting.get_temperature(name).item() for name in config.teacher_models})\n",
    "        history['teacher_gating'].append(dict(teacher_weighting.gating_status))\n",
    "        \n",
    "        hfi_weight_dict_epoch = {}\n",
    "        if hfi_module:\n",
    "            hfi_weights_tensor = F.softmax(hfi_module.attention_weights, dim=0).detach().cpu()\n",
    "            hfi_weight_dict_epoch = {name: hfi_weights_tensor[i].item() for i, name in enumerate(hfi_module.teacher_names)}\n",
    "            hfi_module.train() # Set HFI to train mode\n",
    "        history['hfi_weights'].append(hfi_weight_dict_epoch)\n",
    "        if hfi_module: logger.info(f\"HFI attention weights: {hfi_weight_dict_epoch}\")\n",
    "\n",
    "        student.train() # Set student to train mode\n",
    "        for teacher in teachers.values(): teacher.eval() # Ensure teachers are in eval mode\n",
    "        \n",
    "        # Reset epoch metrics accumulators\n",
    "        current_epoch_metrics = {'train_loss': 0.0, 'ce_loss': 0.0, 'kl_loss': 0.0, 'feature_loss': 0.0, 'cal_loss': 0.0, 'correct': 0, 'total': 0}\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Train E{epoch+1} (A:{alpha_e:.2f}|F:{feature_weight_e:.2f}|C:{cal_weight_e:.2f})\", leave=False)\n",
    "        optimizer.zero_grad(set_to_none=True) # Zero gradients at the start of the epoch\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(pbar):\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            \n",
    "            with autocast(device_type='cuda', enabled=config.use_amp):\n",
    "                # Teacher predictions and features\n",
    "                # Ensure teachers are in eval mode before getting predictions\n",
    "                for teacher in teachers.values(): teacher.eval() \n",
    "                teacher_ensemble_logits, teacher_individual_logits, teacher_names_ordered = get_ensemble_predictions(teachers, inputs, config, teacher_weighting)\n",
    "                \n",
    "                # Student predictions and features\n",
    "                student.train() # Ensure student is in train mode for feature extraction if needed\n",
    "                student_logits = student(inputs)\n",
    "                # Get student features AFTER the forward pass\n",
    "                _ = student_feature_extractor.get_features(inputs) # This runs a forward pass again, might be inefficient. Consider getting features from the main forward pass if possible.\n",
    "                current_student_features = student_feature_extractor.features\n",
    "\n",
    "                # HFI and Feature Loss\n",
    "                current_teacher_features_dict = {}\n",
    "                # Populate teacher features (hooks should have captured them during get_ensemble_predictions)\n",
    "                for t_name in teacher_names_ordered: \n",
    "                    if t_name in teacher_feature_extractors and teacher_feature_extractors[t_name].features is not None:\n",
    "                        current_teacher_features_dict[t_name] = teacher_feature_extractors[t_name].features.detach() # Detach here\n",
    "\n",
    "                fused_teacher_features_hfi = None\n",
    "                if hfi_module and current_teacher_features_dict and current_student_features is not None:\n",
    "                    hfi_module.train() # Ensure HFI is in train mode for learnable params\n",
    "                    fused_teacher_features_hfi = hfi_module(current_teacher_features_dict) # HFI expects detached features\n",
    "                \n",
    "                feature_loss_val = torch.tensor(0.0, device=device)\n",
    "                # Only calculate feature loss if weight > 0 and features are valid\n",
    "                if feature_weight_e > 0 and current_student_features is not None and fused_teacher_features_hfi is not None:\n",
    "                    feature_loss_val = feature_loss_fn(current_student_features, fused_teacher_features_hfi) # HFI output is already detached\n",
    "\n",
    "                # Distillation and Calibration Loss\n",
    "                # Pass dynamic alpha_e to the loss function\n",
    "                # EnhancedDistillationLoss returns: dist_component_loss, ce_loss, kl_loss, internal_cal_loss (which we ignore)\n",
    "                _, ce_loss_val, kl_loss_val, _ = distil_loss_fn(\n",
    "                    student_logits, teacher_ensemble_logits, teacher_individual_logits, \n",
    "                    teacher_names_ordered, labels, alpha=alpha_e \n",
    "                )\n",
    "                # Calculate the main calibration loss based on student logits\n",
    "                cal_loss_val = CalibrationMetrics.calibration_loss(student_logits, labels) # MSE-based\n",
    "\n",
    "                # --- Final Loss Combination using ACP weights ---\n",
    "                # Note: ce_loss_val and kl_loss_val are the raw values.\n",
    "                # We apply the dynamic weights here.\n",
    "                total_loss_for_batch = (1 - alpha_e) * ce_loss_val + \\\n",
    "                                       alpha_e * kl_loss_val + \\\n",
    "                                       feature_weight_e * feature_loss_val + \\\n",
    "                                       cal_weight_e * cal_loss_val\n",
    "                # --- End Final Loss Combination ---\n",
    "                \n",
    "                # Scale loss for gradient accumulation\n",
    "                loss_to_backward = total_loss_for_batch / config.gradient_accumulation_steps\n",
    "            \n",
    "            scaler.scale(loss_to_backward).backward()\n",
    "\n",
    "            # Accumulate metrics (use unscaled loss values for logging)\n",
    "            current_batch_size = inputs.size(0)\n",
    "            current_epoch_metrics['train_loss'] += total_loss_for_batch.item() * current_batch_size\n",
    "            current_epoch_metrics['ce_loss'] += ce_loss_val.item() * current_batch_size\n",
    "            current_epoch_metrics['kl_loss'] += kl_loss_val.item() * current_batch_size\n",
    "            current_epoch_metrics['feature_loss'] += feature_loss_val.item() * current_batch_size\n",
    "            current_epoch_metrics['cal_loss'] += cal_loss_val.item() * current_batch_size\n",
    "            \n",
    "            _, predicted = student_logits.max(1)\n",
    "            current_epoch_metrics['total'] += current_batch_size\n",
    "            current_epoch_metrics['correct'] += predicted.eq(labels).sum().item()\n",
    "\n",
    "            # Optimizer step after accumulating gradients for the full batch\n",
    "            if (batch_idx + 1) % config.gradient_accumulation_steps == 0 or (batch_idx + 1) == len(train_loader):\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(optimizer_params, max_norm=1.0) # Clip all optimized params\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad(set_to_none=True) # Zero grad AFTER step\n",
    "\n",
    "            # Update progress bar less frequently if needed, e.g., every 10 steps\n",
    "            if batch_idx % 10 == 0 and current_epoch_metrics['total'] > 0:\n",
    "                 pbar.set_postfix({\n",
    "                    'loss': f\"{current_epoch_metrics['train_loss']/current_epoch_metrics['total']:.3f}\",\n",
    "                    'acc': f\"{100.*current_epoch_metrics['correct']/current_epoch_metrics['total']:.2f}%\"\n",
    "                 })\n",
    "            \n",
    "            # Optional: Update teacher weights periodically within epoch\n",
    "            batch_count += 1\n",
    "            if config.dynamic_weight_update and batch_count % config.weight_update_interval == 0:\n",
    "                teacher_weighting.update_weights(validation=False) \n",
    "        \n",
    "        # --- Epoch End ---\n",
    "        # Calculate average epoch metrics\n",
    "        total_samples = max(1, current_epoch_metrics['total'])\n",
    "        history['train_loss'].append(current_epoch_metrics['train_loss'] / total_samples)\n",
    "        history['train_acc'].append(100. * current_epoch_metrics['correct'] / total_samples)\n",
    "        history['ce_loss'].append(current_epoch_metrics['ce_loss'] / total_samples)\n",
    "        history['kl_loss'].append(current_epoch_metrics['kl_loss'] / total_samples)\n",
    "        history['feature_loss'].append(current_epoch_metrics['feature_loss'] / total_samples)\n",
    "        history['cal_loss'].append(current_epoch_metrics['cal_loss'] / total_samples)\n",
    "        \n",
    "        # Validation\n",
    "        student.eval() # Set student to eval for validation\n",
    "        if hfi_module: hfi_module.eval() # Set HFI to eval if it exists\n",
    "        val_metrics = validate(student, val_loader, nn.CrossEntropyLoss(), config) # Pass student model\n",
    "        \n",
    "        history['val_loss'].append(val_metrics['loss']); history['val_acc'].append(val_metrics['accuracy'])\n",
    "        history['val_f1'].append(val_metrics['f1_score']); history['val_ece'].append(val_metrics['ece'])\n",
    "        \n",
    "        scheduler.step(); current_lr = scheduler.get_last_lr()[0]\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        \n",
    "        # Logging\n",
    "        logger.info(f\"E{epoch+1} Results - Time:{epoch_time:.2f}s LR:{current_lr:.6f} TrL:{history['train_loss'][-1]:.4f} TrAcc:{history['train_acc'][-1]:.2f}%\")\n",
    "        logger.info(f\"  LossBreakdown: CE:{history['ce_loss'][-1]:.4f} KL:{history['kl_loss'][-1]:.4f} Feat:{history['feature_loss'][-1]:.4f} Cal:{history['cal_loss'][-1]:.4f}\")\n",
    "        logger.info(f\"  Val - Loss:{val_metrics['loss']:.4f} Acc:{val_metrics['accuracy']:.2f}% F1:{val_metrics['f1_score']:.4f} ECE:{val_metrics['ece']:.4f}\")\n",
    "\n",
    "        # Tensorboard Logging\n",
    "        writer.add_scalar('Student/TrainLoss', history['train_loss'][-1], epoch+1)\n",
    "        writer.add_scalar('Student/TrainAcc', history['train_acc'][-1], epoch+1)\n",
    "        writer.add_scalar('Student/ValLoss', val_metrics['loss'], epoch+1)\n",
    "        writer.add_scalar('Student/ValAcc', val_metrics['accuracy'], epoch+1)\n",
    "        writer.add_scalar('Student/ValECE', val_metrics['ece'], epoch+1)\n",
    "        writer.add_scalar('Student/ValF1', val_metrics['f1_score'], epoch+1)\n",
    "        writer.add_scalars('Student/LossComponents', {'CE': history['ce_loss'][-1], 'KL': history['kl_loss'][-1], 'Feature': history['feature_loss'][-1], 'Calibration': history['cal_loss'][-1]}, epoch+1)\n",
    "        writer.add_scalars('ACP_Weights', {'Alpha_KL': alpha_e, 'Feature': feature_weight_e, 'Calibration': cal_weight_e}, epoch+1)\n",
    "        writer.add_scalar('Student/LearningRate', current_lr, epoch+1)\n",
    "        for t_name, weight in teacher_weighting.normalized_weights.items(): writer.add_scalar(f'TeacherWeights/{t_name}', weight, epoch+1)\n",
    "        if hfi_module and hfi_weight_dict_epoch:\n",
    "            for t_name, weight in hfi_weight_dict_epoch.items(): writer.add_scalar(f'HFI_Attention/{t_name}', weight, epoch+1)\n",
    "        if config.learn_temperatures and teacher_weighting.learnable_temps:\n",
    "            for t_name in config.teacher_models: writer.add_scalar(f'TeacherTemperatures/{t_name}', teacher_weighting.get_temperature(t_name).item(), epoch+1)\n",
    "        \n",
    "        # Checkpointing\n",
    "        checkpoint = {'epoch': epoch + 1, 'model_state_dict': student.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), \n",
    "                      'scheduler_state_dict': scheduler.state_dict(), 'history': history, 'config': config.__dict__}\n",
    "        if hfi_module: checkpoint['hfi_state_dict'] = hfi_module.state_dict()\n",
    "        if config.learn_temperatures and teacher_weighting.learnable_temps: checkpoint['teacher_temp_state_dict'] = teacher_weighting.learnable_temps.state_dict()\n",
    "\n",
    "        torch.save(checkpoint, os.path.join(config.checkpoint_dir, f\"{model_name_ts}_latest.pth\"))\n",
    "        if val_metrics['loss'] < best_val_loss:\n",
    "            best_val_loss = val_metrics['loss']\n",
    "            torch.save(checkpoint, os.path.join(config.checkpoint_dir, f\"{model_name_ts}_best_loss.pth\"))\n",
    "            logger.info(f\"Best model (loss) saved at epoch {epoch+1}\")\n",
    "            early_stop_counter = 0 # Reset counter on improvement\n",
    "        else: early_stop_counter += 1\n",
    "        \n",
    "        if val_metrics['accuracy'] > best_val_acc:\n",
    "            best_val_acc = val_metrics['accuracy']; history['best_epoch'] = epoch + 1\n",
    "            torch.save(checkpoint, os.path.join(config.checkpoint_dir, f\"{model_name_ts}_best_acc.pth\"))\n",
    "            logger.info(f\"Best model (accuracy) saved at epoch {epoch+1}\")\n",
    "            # Reset early stopping counter also on accuracy improvement if desired\n",
    "            # early_stop_counter = 0 \n",
    "            \n",
    "        if (epoch + 1) % 10 == 0: torch.save(checkpoint, os.path.join(config.checkpoint_dir, f\"{model_name_ts}_epoch_{epoch+1}.pth\"))\n",
    "        if early_stop_counter >= config.early_stop_patience: logger.info(\"Early stopping.\"); break\n",
    "        print_gpu_memory_stats()\n",
    "    \n",
    "    logger.info(f\"Training completed. Best validation accuracy: {best_val_acc:.2f}% at epoch {history['best_epoch']}\")\n",
    "    # Load best model state before returning\n",
    "    best_model_path = os.path.join(config.checkpoint_dir, f\"{model_name_ts}_best_acc.pth\") # Or _best_loss\n",
    "    if os.path.exists(best_model_path):\n",
    "        logger.info(f\"Loading best model state from {best_model_path}\")\n",
    "        checkpoint = torch.load(best_model_path)\n",
    "        student.load_state_dict(checkpoint['model_state_dict'])\n",
    "        if hfi_module and 'hfi_state_dict' in checkpoint:\n",
    "            hfi_module.load_state_dict(checkpoint['hfi_state_dict'])\n",
    "        if config.learn_temperatures and teacher_weighting.learnable_temps and 'teacher_temp_state_dict' in checkpoint:\n",
    "             teacher_weighting.learnable_temps.load_state_dict(checkpoint['teacher_temp_state_dict'])\n",
    "    else:\n",
    "        logger.warning(\"Best model checkpoint not found. Returning model from last epoch.\")\n",
    "\n",
    "    return student, history\n",
    "\n",
    "# Visualization Functions\n",
    "# REPLACE the existing plot_training_history function with this one:\n",
    "def plot_training_history(history, config):\n",
    "    \"\"\"Plot training history with multiple metrics, including ACP weights\"\"\"\n",
    "    plt.figure(figsize=(20, 28)) # Increased height for new plots\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    main_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b'] # Adjusted colors\n",
    "    teacher_colors = plt.cm.tab10(np.linspace(0, 1, len(config.teacher_models)))\n",
    "    \n",
    "    num_epochs = len(history['train_loss'])\n",
    "    epochs_x = range(1, num_epochs + 1) # X-axis for plots\n",
    "\n",
    "    # Plot training & validation loss\n",
    "    ax1 = plt.subplot(6, 2, 1) # Adjusted grid\n",
    "    ax1.plot(epochs_x, history['train_loss'], label='Train Loss', color=main_colors[0], linewidth=2)\n",
    "    ax1.plot(epochs_x, history['val_loss'], label='Validation Loss', color=main_colors[1], linewidth=2)\n",
    "    if 'best_epoch' in history and history['best_epoch'] > 0: ax1.axvline(x=history['best_epoch'], color='r', linestyle='--', label=f'Best Epoch ({history[\"best_epoch\"]})')\n",
    "    ax1.set_title('Loss Over Time', fontsize=14, fontweight='bold'); ax1.set_xlabel('Epoch', fontsize=12); ax1.set_ylabel('Loss', fontsize=12); ax1.legend(fontsize=10); ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot training & validation accuracy\n",
    "    ax2 = plt.subplot(6, 2, 2)\n",
    "    ax2.plot(epochs_x, history['train_acc'], label='Train Accuracy', color=main_colors[0], linewidth=2)\n",
    "    ax2.plot(epochs_x, history['val_acc'], label='Validation Accuracy', color=main_colors[1], linewidth=2)\n",
    "    if 'best_epoch' in history and history['best_epoch'] > 0: ax2.axvline(x=history['best_epoch'], color='r', linestyle='--', label=f'Best Epoch ({history[\"best_epoch\"]})')\n",
    "    ax2.set_title('Accuracy Over Time', fontsize=14, fontweight='bold'); ax2.set_xlabel('Epoch', fontsize=12); ax2.set_ylabel('Accuracy (%)', fontsize=12); ax2.legend(fontsize=10); ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot loss components\n",
    "    ax3 = plt.subplot(6, 2, 3)\n",
    "    ax3.plot(epochs_x, history['ce_loss'], label='CE Loss', linewidth=1.5, color=main_colors[0], alpha=0.8)\n",
    "    ax3.plot(epochs_x, history['kl_loss'], label='KL Loss', linewidth=1.5, color=main_colors[1], alpha=0.8)\n",
    "    ax3.plot(epochs_x, history['feature_loss'], label='Feature Loss', linewidth=1.5, color=main_colors[2], alpha=0.8)\n",
    "    ax3.plot(epochs_x, history['cal_loss'], label='Calibration Loss', linewidth=1.5, color=main_colors[3], alpha=0.8)\n",
    "    if 'best_epoch' in history and history['best_epoch'] > 0: ax3.axvline(x=history['best_epoch'], color='r', linestyle='--', label=f'Best Epoch ({history[\"best_epoch\"]})')\n",
    "    ax3.set_title('Training Loss Components', fontsize=14, fontweight='bold'); ax3.set_xlabel('Epoch', fontsize=12); ax3.set_ylabel('Loss Value', fontsize=12); ax3.legend(fontsize=10); ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot calibration metrics (ECE)\n",
    "    ax4 = plt.subplot(6, 2, 4)\n",
    "    ax4.plot(epochs_x, history['val_ece'], label='Validation ECE', linewidth=2.5, color=main_colors[0])\n",
    "    if 'best_epoch' in history and history['best_epoch'] > 0: ax4.axvline(x=history['best_epoch'], color='r', linestyle='--', label=f'Best Epoch ({history[\"best_epoch\"]})')\n",
    "    ax4.set_title('Validation Expected Calibration Error', fontsize=14, fontweight='bold'); ax4.set_xlabel('Epoch', fontsize=12); ax4.set_ylabel('ECE', fontsize=12); ax4.legend(fontsize=10); ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot F1 Score\n",
    "    ax5 = plt.subplot(6, 2, 5)\n",
    "    ax5.plot(epochs_x, history['val_f1'], label='Validation F1 Score', linewidth=2.5, color=main_colors[1])\n",
    "    if 'best_epoch' in history and history['best_epoch'] > 0: ax5.axvline(x=history['best_epoch'], color='r', linestyle='--', label=f'Best Epoch ({history[\"best_epoch\"]})')\n",
    "    ax5.set_title('Validation F1 Score', fontsize=14, fontweight='bold'); ax5.set_xlabel('Epoch', fontsize=12); ax5.set_ylabel('F1 Score', fontsize=12); ax5.legend(fontsize=10); ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot ACP loss weights\n",
    "    ax6 = plt.subplot(6, 2, 6)\n",
    "    ax6.plot(epochs_x, history['alpha_weights'], label='Alpha (KL Weight)', linewidth=2, color=main_colors[0])\n",
    "    ax6.plot(epochs_x, history['feature_loss_weights'], label='Feature Loss Weight', linewidth=2, color=main_colors[1])\n",
    "    ax6.plot(epochs_x, history['calibration_weights'], label='Calibration Weight', linewidth=2, color=main_colors[2])\n",
    "    ax6.set_title('ACP Loss Weights Curriculum', fontsize=14, fontweight='bold'); ax6.set_xlabel('Epoch', fontsize=12); ax6.set_ylabel('Weight Value', fontsize=12); ax6.legend(fontsize=10); ax6.grid(True, alpha=0.3); ax6.set_ylim(bottom=-0.05) # Ensure 0 is visible\n",
    "\n",
    "    # Plot teacher adaptive weights\n",
    "    ax7 = plt.subplot(6, 2, 7)\n",
    "    if 'teacher_weights' in history and history['teacher_weights'] and any(history['teacher_weights']):\n",
    "        for i, teacher_name in enumerate(config.teacher_models):\n",
    "            weights = [epoch_weights.get(teacher_name, 0) for epoch_weights in history['teacher_weights']]\n",
    "            ax7.plot(epochs_x, weights, label=teacher_name, linewidth=1.5, color=teacher_colors[i % len(teacher_colors)])\n",
    "        ax7.legend(fontsize=9, loc='center left', bbox_to_anchor=(1, 0.5)) # Adjust legend position\n",
    "    ax7.set_title('Adaptive Teacher Weights', fontsize=14, fontweight='bold'); ax7.set_xlabel('Epoch', fontsize=12); ax7.set_ylabel('Weight', fontsize=12); ax7.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot teacher temperatures\n",
    "    ax8 = plt.subplot(6, 2, 8)\n",
    "    if 'teacher_temperatures' in history and history['teacher_temperatures'] and any(history['teacher_temperatures']):\n",
    "        for i, teacher_name in enumerate(config.teacher_models):\n",
    "            temps = [epoch_temps.get(teacher_name, config.soft_target_temp) for epoch_temps in history['teacher_temperatures']]\n",
    "            ax8.plot(epochs_x, temps, label=teacher_name, linewidth=1.5, color=teacher_colors[i % len(teacher_colors)])\n",
    "        ax8.legend(fontsize=9, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    ax8.set_title('Adaptive Teacher Temperatures', fontsize=14, fontweight='bold'); ax8.set_xlabel('Epoch', fontsize=12); ax8.set_ylabel('Temperature', fontsize=12); ax8.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot HFI attention weights\n",
    "    ax9 = plt.subplot(6, 2, 9)\n",
    "    if 'hfi_weights' in history and history['hfi_weights'] and any(history['hfi_weights']):\n",
    "        first_valid_hfi = next((item for item in history['hfi_weights'] if item), None)\n",
    "        if first_valid_hfi:\n",
    "            hfi_teacher_names = list(first_valid_hfi.keys())\n",
    "            for i, teacher_name in enumerate(hfi_teacher_names):\n",
    "                 weights = [epoch_weights.get(teacher_name, 0) for epoch_weights in history['hfi_weights']]\n",
    "                 ax9.plot(epochs_x, weights, label=f\"HFI: {teacher_name}\", linewidth=1.5, color=teacher_colors[i % len(teacher_colors)])\n",
    "            ax9.legend(fontsize=9, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    ax9.set_title('HFI Attention Weights', fontsize=14, fontweight='bold'); ax9.set_xlabel('Epoch', fontsize=12); ax9.set_ylabel('Weight', fontsize=12); ax9.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot teacher gating status\n",
    "    ax10 = plt.subplot(6, 2, 10)\n",
    "    if 'teacher_gating' in history and history['teacher_gating'] and any(history['teacher_gating']):\n",
    "        for i, teacher_name in enumerate(config.teacher_models):\n",
    "            status = [epoch_gating.get(teacher_name, 0) for epoch_gating in history['teacher_gating']]\n",
    "            ax10.plot(epochs_x, status, label=f\"Gate: {teacher_name}\", linewidth=1.5, color=teacher_colors[i % len(teacher_colors)], marker='.', linestyle=':', markersize=4)\n",
    "        ax10.legend(fontsize=9, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    ax10.set_title('Teacher Gating Status', fontsize=14, fontweight='bold'); ax10.set_xlabel('Epoch', fontsize=12); ax10.set_ylabel('Status (0=Pruned, 1=Active)', fontsize=12); ax10.set_yticks([0, 1]); ax10.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.96]) # Adjust layout\n",
    "    plt.suptitle('Ensemble Distillation Training Analytics (ACP Applied)', fontsize=18, fontweight='bold', y=0.99)\n",
    "    \n",
    "    timestamp_fig = datetime.now().strftime(\"%Y-%m-%d %H:%M\"); \n",
    "    info_text = f\"Generated: {timestamp_fig}\\nLR: {config.lr}, Target Alpha: {config.alpha}, Target CalW: {config.cal_weight}, Target FeatW: {config.feature_loss_weight}\"\n",
    "    plt.figtext(0.01, 0.005, info_text, fontsize=8, va=\"bottom\", ha=\"left\")\n",
    "    \n",
    "    plot_path = os.path.join(config.results_dir, 'plots', 'training_history_acp.png')\n",
    "    pdf_path = os.path.join(config.results_dir, 'plots', 'training_history_acp.pdf')\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight'); plt.savefig(pdf_path, format='pdf', bbox_inches='tight')\n",
    "    logger.info(f\"ACP training history plot saved to {plot_path} and {pdf_path}\")\n",
    "    plt.close() # Close the figure to free memory\n",
    "\n",
    "def plot_calibration_curve(model, test_loader, config):\n",
    "    \"\"\"Plot calibration reliability diagram\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    confidences = []\n",
    "    accuracies = []\n",
    "    \n",
    "    # Compute confidences and accuracies\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader, desc=\"Computing calibration data\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu', enabled=config.use_amp):\n",
    "                outputs = model(inputs)\n",
    "            \n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            confidence, predictions = torch.max(probabilities, dim=1)\n",
    "            \n",
    "            accuracy = (predictions == targets).float()\n",
    "            \n",
    "            confidences.append(confidence.cpu())\n",
    "            accuracies.append(accuracy.cpu())\n",
    "    \n",
    "    # Concatenate lists\n",
    "    confidences = torch.cat(confidences)\n",
    "    accuracies = torch.cat(accuracies)\n",
    "    \n",
    "    # Calculate ECE\n",
    "    n_bins = 10\n",
    "    bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    \n",
    "    bin_confidences = []\n",
    "    bin_accuracies = []\n",
    "    bin_sizes = []\n",
    "    \n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        in_bin = (confidences >= bin_lower) & (confidences < bin_upper)\n",
    "        bin_size = in_bin.sum().item()\n",
    "        \n",
    "        if bin_size > 0:\n",
    "            bin_confidence = confidences[in_bin].mean().item()\n",
    "            bin_accuracy = accuracies[in_bin].mean().item()\n",
    "        else:\n",
    "            bin_confidence = (bin_lower + bin_upper) / 2  # Use bin center if empty\n",
    "            bin_accuracy = 0\n",
    "            \n",
    "        bin_confidences.append(bin_confidence)\n",
    "        bin_accuracies.append(bin_accuracy)\n",
    "        bin_sizes.append(bin_size)\n",
    "    \n",
    "    bin_sizes = np.array(bin_sizes) / sum(bin_sizes)  # Normalize sizes\n",
    "    \n",
    "    # Plot reliability diagram\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Perfect calibration line\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n",
    "    \n",
    "    # Plot bins\n",
    "    plt.bar(bin_lowers, bin_accuracies, width=1/n_bins, align='edge', alpha=0.5, label='Accuracy in bin')\n",
    "    for i, (conf, acc) in enumerate(zip(bin_confidences, bin_accuracies)):\n",
    "        plt.plot([conf, conf], [0, acc], 'r--', alpha=0.3)\n",
    "    \n",
    "    # Add histogram of confidence distribution\n",
    "    twin_ax = plt.twinx()\n",
    "    twin_ax.bar(bin_lowers, bin_sizes, width=1/n_bins, align='edge', alpha=0.3, color='g', label='Samples')\n",
    "    twin_ax.set_ylabel('Proportion of Samples')\n",
    "    \n",
    "    # Calculate ECE\n",
    "    ece = sum(bin_sizes[i] * abs(bin_accuracies[i] - bin_confidences[i]) for i in range(len(bin_sizes)))\n",
    "    \n",
    "    plt.title(f'Calibration Reliability Diagram (ECE = {ece:.4f})')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig(os.path.join(config.results_dir, 'plots', 'calibration_curve.png'), dpi=300)\n",
    "    logger.info(f\"Calibration curve saved to {os.path.join(config.results_dir, 'plots', 'calibration_curve.png')}\")\n",
    "    plt.close()\n",
    "    \n",
    "    return ece\n",
    "\n",
    "def plot_teacher_calibration_curves(teachers, test_loader, student, config):\n",
    "    \"\"\"Plot calibration reliability diagrams for all teachers and the student\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Setup for plotting multiple reliability diagrams\n",
    "    n_bins = 10\n",
    "    bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1].numpy()\n",
    "    bin_uppers = bin_boundaries[1:].numpy()\n",
    "    \n",
    "    # Perfect calibration line\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n",
    "    \n",
    "    # Color mapping\n",
    "    colors = {'student': 'blue', 'densenet': 'green', 'efficientnet': 'red', \n",
    "              'inception': 'purple', 'mobilenet': 'orange', 'resnet': 'brown', 'vit': 'pink'}\n",
    "    \n",
    "    # Process each model\n",
    "    all_models = {'student': student}\n",
    "    all_models.update(teachers)\n",
    "    \n",
    "    # Track ECE values\n",
    "    ece_values = {}\n",
    "    \n",
    "    for name, model in all_models.items():\n",
    "        model.eval()\n",
    "        \n",
    "        confidences = []\n",
    "        accuracies = []\n",
    "        \n",
    "        # Compute confidences and accuracies\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(test_loader, desc=f\"Computing calibration for {name}\"):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                \n",
    "                with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu', enabled=config.use_amp):\n",
    "                    outputs = model(inputs)\n",
    "                    \n",
    "                    # Handle inception output format\n",
    "                    if name == 'inception' and isinstance(outputs, tuple):\n",
    "                        outputs = outputs[0]\n",
    "                \n",
    "                probabilities = F.softmax(outputs, dim=1)\n",
    "                confidence, predictions = torch.max(probabilities, dim=1)\n",
    "                \n",
    "                accuracy = (predictions == targets).float()\n",
    "                \n",
    "                confidences.append(confidence.cpu())\n",
    "                accuracies.append(accuracy.cpu())\n",
    "        \n",
    "        # Concatenate lists\n",
    "        confidences = torch.cat(confidences)\n",
    "        accuracies = torch.cat(accuracies)\n",
    "        \n",
    "        # Calculate bin statistics\n",
    "        bin_confidences = []\n",
    "        bin_accuracies = []\n",
    "        bin_sizes = []\n",
    "        \n",
    "        for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "            in_bin = (confidences >= bin_lower) & (confidences < bin_upper)\n",
    "            bin_size = in_bin.sum().item()\n",
    "            \n",
    "            if bin_size > 0:\n",
    "                bin_confidence = confidences[in_bin].mean().item()\n",
    "                bin_accuracy = accuracies[in_bin].mean().item()\n",
    "            else:\n",
    "                bin_confidence = (bin_lower + bin_upper) / 2\n",
    "                bin_accuracy = 0\n",
    "                \n",
    "            bin_confidences.append(bin_confidence)\n",
    "            bin_accuracies.append(bin_accuracy)\n",
    "            bin_sizes.append(bin_size)\n",
    "        \n",
    "        # Calculate ECE\n",
    "        bin_sizes_norm = np.array(bin_sizes) / sum(bin_sizes)\n",
    "        ece = sum(bin_sizes_norm[i] * abs(bin_accuracies[i] - bin_confidences[i]) for i in range(len(bin_sizes)))\n",
    "        ece_values[name] = ece\n",
    "        \n",
    "        # Plot reliability curve\n",
    "        color = colors.get(name, 'gray')\n",
    "        line_style = '-' if name == 'student' else '--'\n",
    "        line_width = 2 if name == 'student' else 1\n",
    "        \n",
    "        # Plot accuracy points\n",
    "        plt.plot(bin_confidences, bin_accuracies, 'o-', color=color, linestyle=line_style, \n",
    "                 linewidth=line_width, label=f\"{name} (ECE={ece:.4f})\")\n",
    "    \n",
    "    plt.title('Calibration Reliability Diagrams')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig(os.path.join(config.results_dir, 'plots', 'teacher_calibration_curves.png'), dpi=300)\n",
    "    logger.info(f\"Teacher calibration curves saved to {os.path.join(config.results_dir, 'plots', 'teacher_calibration_curves.png')}\")\n",
    "    plt.close()\n",
    "    \n",
    "    return ece_values\n",
    "\n",
    "def test_student_model(student, test_loader, config):\n",
    "    \"\"\"Evaluate the student model on the test set and log detailed metrics\"\"\"\n",
    "    logger.info(\"Testing student model on test set...\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    metrics = validate(student, test_loader, criterion, config)\n",
    "    \n",
    "    logger.info(f\"Test Results:\")\n",
    "    logger.info(f\"Loss: {metrics['loss']:.4f}\")\n",
    "    logger.info(f\"Accuracy: {metrics['accuracy']:.2f}%\")\n",
    "    logger.info(f\"F1 Score: {metrics['f1_score']:.4f}\")\n",
    "    logger.info(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    logger.info(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    logger.info(f\"ECE: {metrics['ece']:.4f}\")\n",
    "    \n",
    "    # Save metrics\n",
    "    metrics_path = os.path.join(config.results_dir, 'test_metrics.json')\n",
    "    with open(metrics_path, 'w') as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    try:\n",
    "        # Initialize configuration\n",
    "        config = Config()\n",
    "        logger.info(f\"Configuration: {config}\")\n",
    "        \n",
    "        # Set seed for reproducibility\n",
    "        set_seed(config.seed)\n",
    "        \n",
    "        # Initial GPU memory stats\n",
    "        print_gpu_memory_stats()\n",
    "        \n",
    "        # Get data loaders\n",
    "        logger.info(\"Preparing data loaders...\")\n",
    "        train_loader, val_loader, test_loader = get_cifar10_loaders(config)\n",
    "        \n",
    "        # Load teacher models\n",
    "        logger.info(\"Loading pre-trained teacher models...\")\n",
    "        teachers = load_teacher_models(config)\n",
    "        \n",
    "        # Skip fine-tuning if we're using pre-trained teacher models\n",
    "        if not config.use_pretrained_teachers:\n",
    "            # Fine-tune each teacher model\n",
    "            for name in config.teacher_models:\n",
    "                logger.info(f\"Fine-tuning {name} model...\")\n",
    "                teachers[name] = fine_tune_teacher(\n",
    "                    teachers[name], name, train_loader, val_loader, config\n",
    "                )\n",
    "                \n",
    "                # Clear GPU cache after fine-tuning each teacher\n",
    "                clear_gpu_cache()\n",
    "        else:\n",
    "            logger.info(\"Skipping teacher fine-tuning as pre-trained models are being used\")\n",
    "        \n",
    "        # Create student model\n",
    "        logger.info(\"Creating student model...\")\n",
    "        student = create_student_model(config)\n",
    "        \n",
    "        # Train student model with calibration-aware ensemble distillation\n",
    "        logger.info(\"Training student with calibration-aware ensemble distillation...\")\n",
    "        student, history = train_student(\n",
    "            student, teachers, train_loader, val_loader, config\n",
    "        )\n",
    "        \n",
    "        # Plot training history\n",
    "        logger.info(\"Plotting training history...\")\n",
    "        plot_training_history(history, config)\n",
    "        \n",
    "        # Test student model\n",
    "        logger.info(\"Testing student model...\")\n",
    "        test_metrics = test_student_model(student, test_loader, config)\n",
    "        \n",
    "        # Plot calibration curves for all models\n",
    "        logger.info(\"Plotting calibration curves for all models...\")\n",
    "        ece_values = plot_teacher_calibration_curves(\n",
    "            teachers, test_loader, student, config\n",
    "        )\n",
    "        logger.info(f\"ECE values: {ece_values}\")\n",
    "        \n",
    "        # Plot standard calibration curve for student\n",
    "        logger.info(\"Plotting calibration curve for student...\")\n",
    "        plot_calibration_curve(student, test_loader, config)\n",
    "        \n",
    "        # Export final model\n",
    "        logger.info(\"Exporting final model...\")\n",
    "        final_model_path = os.path.join(config.export_dir, \"cal_aware_distilled_model.pth\")\n",
    "        torch.save({\n",
    "            'model_state_dict': student.state_dict(),\n",
    "            'test_metrics': test_metrics,\n",
    "            'config': config.__dict__,\n",
    "            'teacher_weights': history['teacher_weights'][-1] if history['teacher_weights'] else None,\n",
    "            'teacher_temperatures': history['teacher_temperatures'][-1] if history['teacher_temperatures'] else None,\n",
    "            'ece_values': ece_values\n",
    "        }, final_model_path)\n",
    "        logger.info(f\"Final model exported to {final_model_path}\")\n",
    "        \n",
    "        # Final GPU memory stats\n",
    "        print_gpu_memory_stats()\n",
    "        \n",
    "        logger.info(\"Calibration-aware ensemble distillation completed successfully.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        logger.error(traceback.format_exc())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
