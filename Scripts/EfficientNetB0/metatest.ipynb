{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bf868d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "S_meta (EfficientNet-B1) CIFAR-10 Standalone Evaluation\n",
      "============================================================\n",
      "[INFO] Using device: cuda\n",
      "[INFO] GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "[INFO] Available memory: 6.44 GB\n",
      "[INFO] Preparing CIFAR-10 test dataset...\n",
      "Files already downloaded and verified\n",
      "[INFO] CIFAR-10 Test dataset loaded with 10000 samples\n",
      "[INFO] Creating DataLoader...\n",
      "[INFO] DataLoader created with batch size 32\n",
      "[INFO] Loading S_meta model from: C:\\Users\\Gading\\Downloads\\Research\\Models\\MetaStudent_AKTP\\exports\\MetaStudent_AKTP_20250509_131233_S_meta_final.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gading\\AppData\\Local\\Temp\\ipykernel_24512\\3126786459.py:118: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] S_meta (EfficientNet-B1) model loaded successfully and set to evaluation mode\n",
      "[INFO] Running inference on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation Progress: 100%|██████████| 313/313 [00:17<00:00, 17.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inference complete on 10000 samples\n",
      "[INFO] Analyzing S_meta_EffNetB1_CIFAR10 performance...\n",
      "[RESULT] Average Cross-Entropy Loss: 0.9315\n",
      "[RESULT] Test Accuracy: 83.39%\n",
      "\n",
      "[RESULT] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane      0.983     0.876     0.926      1000\n",
      "  automobile      0.989     0.353     0.520      1000\n",
      "        bird      0.983     0.869     0.923      1000\n",
      "         cat      0.959     0.925     0.941      1000\n",
      "        deer      0.978     0.902     0.939      1000\n",
      "         dog      0.859     0.969     0.911      1000\n",
      "        frog      0.987     0.984     0.985      1000\n",
      "       horse      0.987     0.975     0.981      1000\n",
      "        ship      0.422     0.996     0.593      1000\n",
      "       truck      0.963     0.490     0.649      1000\n",
      "\n",
      "    accuracy                          0.834     10000\n",
      "   macro avg      0.911     0.834     0.837     10000\n",
      "weighted avg      0.911     0.834     0.837     10000\n",
      "\n",
      "[RESULT] Macro F1-Score: 0.837\n",
      "[RESULT] Weighted F1-Score: 0.837\n",
      "[RESULT] Expected Calibration Error (ECE): 0.3908\n",
      "[RESULT] ROC AUC (Micro Avg): 0.983\n",
      "[RESULT] ROC AUC (Macro Avg): 0.991\n",
      "[RESULT] Avg Precision (Micro Avg): 0.858\n",
      "[INFO] Evaluation results for S_meta_EffNetB1_CIFAR10 saved to output_S_meta_CIFAR10\n",
      "[INFO] Generating prediction visualizations for S_meta_EffNetB1_CIFAR10...\n",
      "Files already downloaded and verified\n",
      "[INFO] Prediction visualizations for S_meta_EffNetB1_CIFAR10 saved.\n",
      "[INFO] Generating GradCAM visualizations for S_meta_EffNetB1_CIFAR10...\n",
      "[INFO] GradCAM target layer for S_meta_EffNetB1_CIFAR10: model.features[-1][0] (Conv2d in final features block).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[INFO] GradCAM visualizations for S_meta_EffNetB1_CIFAR10 saved.\n",
      "============================================================\n",
      "S_meta Evaluation on CIFAR-10 completed successfully.\n",
      "Accuracy: 83.39%, Log Loss: 0.9315, Macro F1-Score: 0.837\n",
      "Results saved to directory: 'output_S_meta_CIFAR10'\n",
      "Total execution time: 0:00:33.170950\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.amp import autocast\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.models import efficientnet_b1, EfficientNet_B1_Weights # efficientnet_b1 needed for type check\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve, log_loss\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from itertools import cycle\n",
    "import gc\n",
    "import traceback\n",
    "import torchvision.transforms.functional as TF # For image resizing in GradCAM\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
    "\n",
    "class EvalConfig:\n",
    "    def __init__(self):\n",
    "        self.dataset_path = r\"C:\\Users\\Gading\\Downloads\\Research\\Dataset\\CIFAR-10\" # Example path\n",
    "        self.checkpoint_path = r\"C:\\Users\\Gading\\Downloads\\Research\\Models\\MetaStudent_AKTP\\exports\\MetaStudent_AKTP_20250509_131233_S_meta_final.pth\"\n",
    "        self.output_dir = \"output_S_meta_CIFAR10\"\n",
    "        self.batch_size = 32\n",
    "        self.num_workers = 0\n",
    "        self.use_amp = True\n",
    "        self.pin_memory = True\n",
    "        self.classes = ('airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "                        'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "        self.num_classes = 10\n",
    "        self.mean = [0.4914, 0.4822, 0.4465]\n",
    "        self.std = [0.2023, 0.1994, 0.2010]\n",
    "        self.model_input_size = 224\n",
    "\n",
    "def setup_environment():\n",
    "    config = EvalConfig()\n",
    "    os.makedirs(config.output_dir, exist_ok=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"[INFO] Using device: {device}\")\n",
    "    if device.type == 'cuda':\n",
    "        print(f\"[INFO] GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"[INFO] Available memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    return config, device\n",
    "\n",
    "def get_test_dataset(config):\n",
    "    print(\"[INFO] Preparing CIFAR-10 test dataset...\")\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(config.model_input_size, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=config.mean, std=config.std),\n",
    "    ])\n",
    "    try:\n",
    "        test_dataset = datasets.CIFAR10(\n",
    "            root=config.dataset_path,\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=transform\n",
    "        )\n",
    "        print(f\"[INFO] CIFAR-10 Test dataset loaded with {len(test_dataset)} samples\")\n",
    "        return test_dataset\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to load CIFAR-10 dataset: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def get_original_images(config, indices):\n",
    "    # Ensure dataset is downloaded if not present, but don't re-transform\n",
    "    # This assumes the dataset path is correctly set up for CIFAR10 raw data\n",
    "    orig_dataset_path = os.path.join(config.dataset_path) # Path to the root of CIFAR-10 dataset\n",
    "    orig_dataset = datasets.CIFAR10(\n",
    "        root=orig_dataset_path, # Use the parent directory if CIFAR-10-batches-py is inside\n",
    "        train=False,\n",
    "        download=True # Download if not present\n",
    "    )\n",
    "    originals = []\n",
    "    labels = []\n",
    "    for idx in indices:\n",
    "        # orig_dataset.data contains numpy arrays (H, W, C)\n",
    "        img_np, label = orig_dataset.data[idx], orig_dataset.targets[idx]\n",
    "        img = Image.fromarray(img_np) # Convert numpy array to PIL Image\n",
    "        img_tensor = transforms.ToTensor()(img) # Convert PIL Image to tensor (C, H, W)\n",
    "        originals.append(img_tensor)\n",
    "        labels.append(label)\n",
    "    return originals, labels\n",
    "\n",
    "def create_data_loader(dataset, config):\n",
    "    print(\"[INFO] Creating DataLoader...\")\n",
    "    loader = DataLoader(\n",
    "        dataset, batch_size=config.batch_size, shuffle=False,\n",
    "        num_workers=config.num_workers, pin_memory=config.pin_memory,\n",
    "        persistent_workers=False if config.num_workers == 0 else True, # Adjusted for num_workers\n",
    "        drop_last=False\n",
    "    )\n",
    "    print(f\"[INFO] DataLoader created with batch size {config.batch_size}\")\n",
    "    return loader\n",
    "\n",
    "def load_model(config, device):\n",
    "    print(f\"[INFO] Loading S_meta model from: {config.checkpoint_path}\")\n",
    "    try:\n",
    "        # Initialize EfficientNet-B1 without pretrained weights from torchvision\n",
    "        model = efficientnet_b1(weights=None) # Changed from EfficientNet_B1_Weights.IMAGENET1K_V1\n",
    "        \n",
    "        # Modify the classifier for the number of classes in CIFAR-10\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.3, inplace=True), # Default dropout for EfficientNet-B1 is 0.2, adjust if needed\n",
    "            nn.Linear(in_features, config.num_classes)\n",
    "        )\n",
    "        \n",
    "        # Load the checkpoint\n",
    "        # Set map_location to ensure model loads correctly whether on CPU or GPU\n",
    "        checkpoint = torch.load(\n",
    "            config.checkpoint_path,\n",
    "            map_location=device\n",
    "            # weights_only=True # Removed for compatibility with older PyTorch versions or non-weights_only checkpoints\n",
    "        )\n",
    "        \n",
    "        # Handle different checkpoint structures\n",
    "        if 'meta_student_state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['meta_student_state_dict'])\n",
    "        elif 'model_state_dict' in checkpoint: # Common key for saved models\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        else: # Assuming the checkpoint is directly the state_dict\n",
    "            model.load_state_dict(checkpoint)\n",
    "            \n",
    "        model.to(device)\n",
    "        model.eval() # Set the model to evaluation mode\n",
    "        print(\"[INFO] S_meta (EfficientNet-B1) model loaded successfully and set to evaluation mode\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to load S_meta model: {str(e)}\")\n",
    "        traceback.print_exc() # Print full traceback for debugging\n",
    "        raise\n",
    "\n",
    "def run_inference(model, loader, config, device):\n",
    "    print(\"[INFO] Running inference on test set...\")\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache() # Clear CUDA cache before inference\n",
    "        gc.collect() # Python garbage collection\n",
    "\n",
    "    model.eval() # Ensure model is in evaluation mode\n",
    "    with torch.no_grad(): # Disable gradient calculations for inference\n",
    "        for images, targets in tqdm(loader, desc=\"Evaluation Progress\"):\n",
    "            images = images.to(device, non_blocking=True if config.pin_memory else False)\n",
    "            targets_np = targets.numpy() # Keep targets on CPU as numpy\n",
    "\n",
    "            if config.use_amp and device.type == 'cuda':\n",
    "                with autocast(device_type='cuda'): # Use AMP if enabled and on CUDA\n",
    "                    outputs = model(images)\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "            \n",
    "            probs_batch = torch.softmax(outputs, dim=1)\n",
    "            _, preds_batch = torch.max(probs_batch, dim=1)\n",
    "            \n",
    "            all_targets.extend(targets_np)\n",
    "            all_preds.extend(preds_batch.cpu().numpy())\n",
    "            all_probs.append(probs_batch.cpu().numpy())\n",
    "            \n",
    "            # Clean up to free memory\n",
    "            del images, outputs, probs_batch, preds_batch\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    all_probs = np.concatenate(all_probs, axis=0)\n",
    "    print(f\"[INFO] Inference complete on {len(all_targets)} samples\")\n",
    "    return np.array(all_targets), np.array(all_preds), all_probs\n",
    "\n",
    "def compute_ece(probs, labels, n_bins=15):\n",
    "    \"\"\"Compute Expected Calibration Error (ECE) for multiclass classification.\"\"\"\n",
    "    confidences = np.max(probs, axis=1)\n",
    "    predictions = np.argmax(probs, axis=1)\n",
    "    accuracies = (predictions == labels)\n",
    "    \n",
    "    bin_boundaries = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    ece = 0.0\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        bin_lower = bin_boundaries[i]\n",
    "        bin_upper = bin_boundaries[i + 1]\n",
    "        \n",
    "        in_bin = (confidences > bin_lower) & (confidences <= bin_upper)\n",
    "        prop_in_bin = np.mean(in_bin) # Proportion of samples in this bin\n",
    "        \n",
    "        if prop_in_bin > 0:\n",
    "            accuracy_in_bin = np.mean(accuracies[in_bin])\n",
    "            avg_confidence_in_bin = np.mean(confidences[in_bin])\n",
    "            ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "            \n",
    "    return ece\n",
    "\n",
    "def analyze_results(y_true, y_pred, y_probs, class_names, config, model_name_str=\"S_meta (EfficientNet-B1)\"):\n",
    "    print(f\"[INFO] Analyzing {model_name_str} performance...\")\n",
    "    model_name_safe = model_name_str.replace(' ','_').replace('(','').replace(')','')\n",
    "\n",
    "    try:\n",
    "        # Clip probabilities to avoid log(0) issues in log_loss\n",
    "        y_probs_clipped = np.clip(y_probs, 1e-15, 1 - 1e-15)\n",
    "        loss = log_loss(y_true, y_probs_clipped)\n",
    "        print(f\"[RESULT] Average Cross-Entropy Loss: {loss:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Could not calculate log_loss: {e}\"); loss = -1.0 # Default value\n",
    "\n",
    "    accuracy = np.mean(y_true == y_pred) * 100\n",
    "    print(f\"[RESULT] Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f\"Confusion Matrix - {model_name_str} on CIFAR-10 (Acc: {accuracy:.2f}%)\")\n",
    "    plt.xlabel(\"Predicted Label\"); plt.ylabel(\"True Label\"); plt.tight_layout(pad=1.1)\n",
    "    plt.savefig(f\"{config.output_dir}/confusion_matrix_{model_name_safe}.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Classification Report\n",
    "    report_dict = classification_report(y_true, y_pred, target_names=class_names, digits=3, output_dict=True, zero_division=0)\n",
    "    report_str = classification_report(y_true, y_pred, target_names=class_names, digits=3, zero_division=0)\n",
    "    print(\"\\n[RESULT] Classification Report:\"); print(report_str)\n",
    "    macro_f1 = report_dict['macro avg']['f1-score']\n",
    "    weighted_f1 = report_dict['weighted avg']['f1-score']\n",
    "    print(f\"[RESULT] Macro F1-Score: {macro_f1:.3f}\"); print(f\"[RESULT] Weighted F1-Score: {weighted_f1:.3f}\")\n",
    "\n",
    "    # ECE calculation\n",
    "    ece = compute_ece(y_probs, y_true, n_bins=15)\n",
    "    print(f\"[RESULT] Expected Calibration Error (ECE): {ece:.4f}\")\n",
    "\n",
    "    # Save report to file\n",
    "    with open(f\"{config.output_dir}/classification_report_{model_name_safe}.txt\", \"w\") as f:\n",
    "        f.write(f\"Model: {model_name_str}\\n\")\n",
    "        f.write(f\"Test Accuracy: {accuracy:.2f}%\\n\"); f.write(f\"Avg CE Loss: {loss:.4f}\\n\")\n",
    "        f.write(f\"Macro F1: {macro_f1:.3f}\\n\"); f.write(f\"Weighted F1: {weighted_f1:.3f}\\n\")\n",
    "        f.write(f\"Expected Calibration Error (ECE): {ece:.4f}\\n\\n\")\n",
    "        f.write(report_str)\n",
    "\n",
    "    # Per-Class Accuracy\n",
    "    class_acc = cm.diagonal() / np.maximum(cm.sum(axis=1), 1e-9) * 100 # Avoid division by zero\n",
    "    plt.figure(figsize=(12, 6)); sns.barplot(x=list(class_names), y=class_acc)\n",
    "    plt.title(f\"Per-Class Accuracy - {model_name_str}\"); plt.xlabel(\"Class\"); plt.ylabel(\"Accuracy (%)\"); plt.ylim(0, 100)\n",
    "    plt.xticks(rotation=45, ha=\"right\"); plt.tight_layout(pad=1.1)\n",
    "    plt.savefig(f\"{config.output_dir}/per_class_accuracy_{model_name_safe}.png\", dpi=300); plt.close()\n",
    "\n",
    "    # ROC Curves\n",
    "    y_true_binarized = label_binarize(y_true, classes=range(len(class_names)))\n",
    "    n_classes = y_true_binarized.shape[1]\n",
    "    fpr, tpr, roc_auc = dict(), dict(), dict()\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'olive'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_probs[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2, label=f'ROC {class_names[i]} (AUC={roc_auc[i]:.2f})')\n",
    "    \n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_binarized.ravel(), y_probs.ravel()); roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"], label=f'Micro-avg ROC (AUC={roc_auc[\"micro\"]:.2f})', color='deeppink', linestyle=':', linewidth=4)\n",
    "    \n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)])); mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes): mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "    mean_tpr /= n_classes\n",
    "    fpr[\"macro\"] = all_fpr; tpr[\"macro\"] = mean_tpr; roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"], label=f'Macro-avg ROC (AUC={roc_auc[\"macro\"]:.2f})', color='navy', linestyle=':', linewidth=4)\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2); plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title(f'ROC Curves - {model_name_str}'); plt.legend(loc=\"lower right\"); plt.tight_layout(pad=1.1)\n",
    "    plt.savefig(f\"{config.output_dir}/roc_curves_{model_name_safe}.png\", dpi=300); plt.close()\n",
    "    print(f\"[RESULT] ROC AUC (Micro Avg): {roc_auc['micro']:.3f}\"); print(f\"[RESULT] ROC AUC (Macro Avg): {roc_auc['macro']:.3f}\")\n",
    "    with open(f\"{config.output_dir}/classification_report_{model_name_safe}.txt\", \"a\") as f:\n",
    "        f.write(f\"\\nROC AUC (Micro Avg): {roc_auc['micro']:.3f}\\nROC AUC (Macro Avg): {roc_auc['macro']:.3f}\\n\")\n",
    "        for i in range(n_classes): f.write(f\"ROC AUC Class {class_names[i]}: {roc_auc[i]:.3f}\\n\")\n",
    "\n",
    "    # Precision-Recall Curves\n",
    "    precision, recall, average_precision = dict(), dict(), dict()\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    colors_pr = cycle(['blue', 'red', 'green', 'purple', 'orange', 'cyan', 'magenta', 'yellow', 'black', 'brown'])\n",
    "    for i, color in zip(range(n_classes), colors_pr):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(y_true_binarized[:, i], y_probs[:, i])\n",
    "        average_precision[i] = auc(recall[i], precision[i]) # Using sklearn.metrics.auc\n",
    "        plt.plot(recall[i], precision[i], color=color, lw=2, label=f'PR {class_names[i]} (AP={average_precision[i]:.2f})')\n",
    "    \n",
    "    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_true_binarized.ravel(), y_probs.ravel())\n",
    "    average_precision[\"micro\"] = auc(recall[\"micro\"], precision[\"micro\"]) # Using sklearn.metrics.auc\n",
    "    plt.plot(recall[\"micro\"], precision[\"micro\"], label=f'Micro-avg PR (AP={average_precision[\"micro\"]:.2f})', color='gold', linestyle=':', linewidth=4)\n",
    "    \n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision'); plt.ylim([0.0, 1.05]); plt.xlim([0.0, 1.0])\n",
    "    plt.title(f'Precision-Recall Curves - {model_name_str}'); plt.legend(loc=\"lower left\"); plt.tight_layout(pad=1.1)\n",
    "    plt.savefig(f\"{config.output_dir}/precision_recall_curves_{model_name_safe}.png\", dpi=300); plt.close()\n",
    "    print(f\"[RESULT] Avg Precision (Micro Avg): {average_precision['micro']:.3f}\")\n",
    "    with open(f\"{config.output_dir}/classification_report_{model_name_safe}.txt\", \"a\") as f:\n",
    "        f.write(f\"\\nAvg Precision (Micro Avg): {average_precision['micro']:.3f}\\n\")\n",
    "        for i in range(n_classes): f.write(f\"Avg Precision Class {class_names[i]}: {average_precision[i]:.3f}\\n\")\n",
    "\n",
    "    print(f\"[INFO] Evaluation results for {model_name_str} saved to {config.output_dir}\")\n",
    "    return accuracy, loss, macro_f1\n",
    "\n",
    "def visualize_predictions(model, test_dataset, config, device, num_examples=5, model_name_str=\"S_meta (EfficientNet-B1)\"):\n",
    "    print(f\"[INFO] Generating prediction visualizations for {model_name_str}...\")\n",
    "    model_name_safe = model_name_str.replace(' ','_').replace('(','').replace(')','')\n",
    "    plt.style.use('seaborn-v0_8-whitegrid'); \n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'sans-serif', \n",
    "        'font.sans-serif': ['Arial', 'Helvetica', 'DejaVu Sans'], \n",
    "        'font.size': 9, \n",
    "        'axes.titlesize': 10, \n",
    "        'axes.labelsize': 9\n",
    "    })\n",
    "    correct_color = '#1f77b4'; incorrect_color = '#d62728' # Blue for correct, Red for incorrect\n",
    "\n",
    "    # Ensure we don't try to sample more examples than available per class or in total\n",
    "    num_to_sample = min(len(test_dataset), num_examples * len(config.classes))\n",
    "    indices = np.random.choice(len(test_dataset), size=num_to_sample, replace=False)\n",
    "    \n",
    "    # Get original (unnormalized, non-resized) images for display\n",
    "    originals, true_labels_list = get_original_images(config, indices) # Returns list of tensors and list of labels\n",
    "    \n",
    "    # Get transformed images for model prediction\n",
    "    batch_images_transformed = torch.stack([test_dataset[idx][0] for idx in indices]).to(device)\n",
    "    \n",
    "    model.eval() # Ensure model is in eval mode\n",
    "    with torch.no_grad():\n",
    "        if config.use_amp and device.type == 'cuda':\n",
    "            with autocast(device_type='cuda'): \n",
    "                outputs = model(batch_images_transformed)\n",
    "        else: \n",
    "            outputs = model(batch_images_transformed)\n",
    "            \n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    pred_scores, pred_labels_tensor = torch.max(probs, dim=1)\n",
    "    \n",
    "    pred_labels_np = pred_labels_tensor.cpu().numpy()\n",
    "    pred_scores_np = pred_scores.cpu().numpy()\n",
    "    true_labels_np = np.array(true_labels_list) # Convert list of true labels to numpy array\n",
    "\n",
    "    fig, axes = plt.subplots(len(config.classes), num_examples, figsize=(num_examples * 2.5, len(config.classes) * 2.2))\n",
    "    if len(config.classes) == 1: # Handle single class case for axes\n",
    "        axes = np.array([axes])\n",
    "    if num_examples == 1:\n",
    "        axes = axes.reshape(-1,1)\n",
    "\n",
    "    fig.suptitle(f\"CIFAR-10 Prediction Examples ({model_name_str})\", fontsize=14, y=0.995) # Adjusted y for suptitle\n",
    "\n",
    "    # Map original indices (from `indices` array) to their true class\n",
    "    class_indices_map = {i: [] for i in range(len(config.classes))}\n",
    "    for i, original_idx_in_test_dataset in enumerate(indices):\n",
    "        true_label_for_sample = true_labels_np[i]\n",
    "        class_indices_map[true_label_for_sample].append(i) # Store the index within the 'originals'/'true_labels_np' arrays\n",
    "\n",
    "    for class_idx_display in range(len(config.classes)): # Iterate through each class to display\n",
    "        for example_idx_display in range(num_examples): # Iterate through number of examples per class\n",
    "            ax = axes[class_idx_display, example_idx_display]\n",
    "            if example_idx_display < len(class_indices_map[class_idx_display]):\n",
    "                # Get the index from our sampled batch that corresponds to this class and example number\n",
    "                sample_batch_idx = class_indices_map[class_idx_display][example_idx_display]\n",
    "                \n",
    "                img_tensor_original = originals[sample_batch_idx] # Original image tensor (C, H, W)\n",
    "                img_display_np = img_tensor_original.permute(1, 2, 0).numpy() # Convert to (H, W, C) for imshow\n",
    "                \n",
    "                ax.imshow(img_display_np)\n",
    "                \n",
    "                true_label_val = true_labels_np[sample_batch_idx]\n",
    "                pred_label_val = pred_labels_np[sample_batch_idx]\n",
    "                pred_score_val = pred_scores_np[sample_batch_idx]\n",
    "                \n",
    "                color = correct_color if true_label_val == pred_label_val else incorrect_color\n",
    "                ax.set_title(f\"True: {config.classes[true_label_val]}\\nPred: {config.classes[pred_label_val]}\\nConf: {pred_score_val:.2f}\", \n",
    "                            color=color, fontsize=8, pad=3)\n",
    "                \n",
    "                # Add colored border\n",
    "                for spine in ax.spines.values(): \n",
    "                    spine.set_edgecolor(color)\n",
    "                    spine.set_linewidth(2)\n",
    "            else:\n",
    "                ax.set_visible(False) # Hide unused subplots\n",
    "            ax.set_xticks([]); ax.set_yticks([])\n",
    "\n",
    "    # Set class labels on the y-axis of the first column\n",
    "    for class_idx_display in range(len(config.classes)):\n",
    "        if axes[class_idx_display, 0].get_visible(): # Check if the plot is visible\n",
    "            axes[class_idx_display, 0].set_ylabel(config.classes[class_idx_display], fontsize=9, rotation=0, labelpad=30, va='center', ha='right')\n",
    "\n",
    "    plt.figtext(0.5, 0.005, f\"{model_name_str} evaluation on CIFAR-10 test set\", ha=\"center\", fontsize=9, style='italic')\n",
    "    plt.tight_layout(rect=[0.05, 0.02, 0.95, 0.97]) # Adjust rect to make space for y-labels and suptitle\n",
    "    plt.savefig(f\"{config.output_dir}/prediction_examples_{model_name_safe}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Prediction visualizations for {model_name_str} saved.\")\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.activations = None\n",
    "        self.gradients = None\n",
    "        self.hook_handles = []\n",
    "        if self.target_layer is not None:\n",
    "            self._register_hooks()\n",
    "        else:\n",
    "            print(\"[ERROR] GradCAM: Target layer is None. Hooks not registered.\")\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output.detach() # Detach from graph\n",
    "        def backward_hook(module, grad_input, grad_output):\n",
    "            self.gradients = grad_output[0].detach() # Detach from graph\n",
    "\n",
    "        if self.target_layer is None:\n",
    "            print(\"[ERROR] GradCAM: Cannot register hooks, target_layer is None.\")\n",
    "            return\n",
    "\n",
    "        handle_fw = self.target_layer.register_forward_hook(forward_hook)\n",
    "        handle_bw = self.target_layer.register_full_backward_hook(backward_hook) # Use full_backward_hook\n",
    "        self.hook_handles.extend([handle_fw, handle_bw])\n",
    "\n",
    "    def generate_cam(self, input_tensor, target_class_idx=None):\n",
    "        if self.target_layer is None:\n",
    "            print(\"[ERROR] GradCAM: Target layer not set. Cannot generate CAM.\")\n",
    "            return torch.zeros_like(input_tensor[:, 0:1, :, :]) # Return blank CAM\n",
    "\n",
    "        self.model.zero_grad() # Zero gradients before backward pass\n",
    "        logits = self.model(input_tensor.requires_grad_(True)) # Ensure input_tensor requires grad for this path\n",
    "\n",
    "        if target_class_idx is None:\n",
    "            target_class_idx = logits.argmax(dim=1).item()\n",
    "        \n",
    "        target_class_logit = logits[0, target_class_idx] # Assuming batch size 1 for CAM generation input_tensor\n",
    "\n",
    "        # Backward pass to get gradients\n",
    "        self.model.zero_grad() # Zero gradients again before specific backward call\n",
    "        target_class_logit.backward(retain_graph=False) # retain_graph=False if not needing further backward passes from this point\n",
    "\n",
    "        if self.gradients is None or self.activations is None:\n",
    "            print(\"[ERROR] GradCAM: Gradients or activations not captured. Check hook registration and target layer.\")\n",
    "            return torch.zeros_like(input_tensor[:, 0:1, :, :])\n",
    "\n",
    "        # Global average pooling of gradients\n",
    "        weights = self.gradients.mean(dim=(2, 3), keepdim=True) # (batch, channels, 1, 1)\n",
    "        \n",
    "        # Weighted sum of activations\n",
    "        cam = (weights * self.activations).sum(dim=1, keepdim=True) # (batch, 1, H, W)\n",
    "        cam = torch.relu(cam) # Apply ReLU\n",
    "\n",
    "        # Resize CAM to input image size\n",
    "        cam = F.interpolate(cam, size=input_tensor.shape[2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Normalize CAM\n",
    "        cam_min = cam.min()\n",
    "        cam_max = cam.max()\n",
    "        if cam_max - cam_min < 1e-8 : # Avoid division by zero or tiny number\n",
    "             cam = cam - cam_min # if all values are same, cam becomes all zeros\n",
    "        else:\n",
    "            cam = (cam - cam_min) / (cam_max - cam_min + 1e-8)\n",
    "        \n",
    "        return cam\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        for handle in self.hook_handles:\n",
    "            handle.remove()\n",
    "        self.hook_handles = []\n",
    "        self.activations = None # Clear stored data\n",
    "        self.gradients = None\n",
    "\n",
    "\n",
    "def visualize_gradcam(model, test_dataset, config, device, model_name_str=\"S_meta (EfficientNet-B1)\"):\n",
    "    print(f\"[INFO] Generating GradCAM visualizations for {model_name_str}...\")\n",
    "    model_name_safe = model_name_str.replace(' ','_').replace('(','').replace(')','')\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'sans-serif', \n",
    "        'font.sans-serif': ['Arial'], \n",
    "        'font.size': 9, \n",
    "        'axes.titlesize': 10, \n",
    "        'axes.labelsize': 9\n",
    "    })\n",
    "\n",
    "    # --- Determine GradCAM Target Layer ---\n",
    "    target_layer = None\n",
    "    # The model is loaded as efficientnet_b1.\n",
    "    # For torchvision.models.efficientnet_b1, the target is model.features[-1][0] (the Conv2d in the last Conv2dNormActivation).\n",
    "    try:\n",
    "        if (hasattr(model, 'features') and isinstance(model.features, nn.Sequential) and\n",
    "                len(model.features) > 0 and\n",
    "                # model.features[-1] should be a Conv2dNormActivation block, which is nn.Sequential\n",
    "                isinstance(model.features[-1], nn.Sequential) and \n",
    "                len(model.features[-1]) > 0 and\n",
    "                # model.features[-1][0] should be the Conv2d layer\n",
    "                isinstance(model.features[-1][0], nn.Conv2d)):\n",
    "            target_layer = model.features[-1][0]\n",
    "            print(f\"[INFO] GradCAM target layer for {model_name_str}: model.features[-1][0] (Conv2d in final features block).\")\n",
    "        else:\n",
    "            print(f\"[WARN] Standard EfficientNet target layer (model.features[-1][0]) not found for {model_name_str}. Structure might be altered.\")\n",
    "            print(f\"[INFO] Attempting to find the last globally registered Conv2d layer as fallback.\")\n",
    "            last_conv_layer = None\n",
    "            for name, module_found in model.named_modules(): # Corrected variable name\n",
    "                if isinstance(module_found, nn.Conv2d):\n",
    "                    last_conv_layer = module_found \n",
    "            \n",
    "            if last_conv_layer:\n",
    "                target_layer = last_conv_layer\n",
    "                print(f\"[INFO] Using globally last found Conv2d layer as GradCAM target: {target_layer}\")\n",
    "            else:\n",
    "                print(f\"[ERROR] No Conv2d layer found anywhere in the model {model_name_str}.\")\n",
    "                if hasattr(model, 'features') and len(model.features) > 0:\n",
    "                    target_layer = model.features[-1] # Original script's default (likely a block, not Conv2d)\n",
    "                    print(f\"[WARN] Desperate fallback: Using model.features[-1] as GradCAM target. This may not be a Conv2d layer and could lead to poor results or errors.\")\n",
    "                else:\n",
    "                    print(f\"[ERROR] CRITICAL: Cannot determine any GradCAM target layer for {model_name_str}. Skipping GradCAM.\")\n",
    "                    return \n",
    "\n",
    "    except Exception as e_target_layer: # Renamed exception variable\n",
    "        print(f\"[ERROR] Exception while determining GradCAM target layer for {model_name_str}: {e_target_layer}\")\n",
    "        traceback.print_exc()\n",
    "        print(\"[INFO] Skipping GradCAM due to error in target layer selection.\")\n",
    "        return\n",
    "\n",
    "    if target_layer is None:\n",
    "        print(f\"[ERROR] GradCAM target layer is None for {model_name_str} after attempts. Skipping GradCAM.\")\n",
    "        return\n",
    "    # --- End Target Layer Determination ---\n",
    "\n",
    "    grad_cam_instance = GradCAM(model, target_layer)\n",
    "    \n",
    "    # Get one sample per class for GradCAM visualization\n",
    "    samples_by_class = {c: None for c in range(len(config.classes))}\n",
    "    indices_by_class = {c: None for c in range(len(config.classes))} # To fetch original image later\n",
    "\n",
    "    # Iterate through dataset to find one sample for each class\n",
    "    # Using a set to track found classes for efficiency\n",
    "    found_classes_set = set()\n",
    "    for idx in tqdm(range(len(test_dataset)), desc=\"Finding class samples for GradCAM\", leave=False):\n",
    "        transformed_img_tensor, label = test_dataset[idx] # label is an int\n",
    "        if label not in found_classes_set:\n",
    "            samples_by_class[label] = transformed_img_tensor.unsqueeze(0) # Add batch dim\n",
    "            indices_by_class[label] = idx\n",
    "            found_classes_set.add(label)\n",
    "        if len(found_classes_set) == len(config.classes): # Stop if all classes found\n",
    "            break\n",
    "            \n",
    "    cmap_heatmap = 'inferno' # Colormap for the heatmap\n",
    "    \n",
    "    # Determine plot grid: 2 rows of images (original, overlay) for 5 classes per row = 4 rows total\n",
    "    # (Original_Row1, Overlay_Row1, Original_Row2, Overlay_Row2)\n",
    "    num_classes_to_plot = len(config.classes)\n",
    "    cols_plot = 5 # Max 5 classes per \"meta-row\" (original + overlay)\n",
    "    rows_plot = ((num_classes_to_plot + cols_plot -1) // cols_plot) * 2 # Each class takes 2 rows in the plot\n",
    "\n",
    "    fig, axes = plt.subplots(rows_plot, cols_plot, figsize=(cols_plot * 2.5, rows_plot * 2.3), constrained_layout=False)\n",
    "    if rows_plot == 1: axes = np.array([axes]) # Ensure axes is 2D\n",
    "    if cols_plot == 1: axes = axes.reshape(-1,1)\n",
    "\n",
    "    fig.suptitle(f\"GradCAM - {model_name_str} on CIFAR-10\", fontsize=14, y=0.99)\n",
    "    \n",
    "    heatmap_mappable = None # For colorbar\n",
    "\n",
    "    for class_idx in range(num_classes_to_plot):\n",
    "        plot_row_original = (class_idx // cols_plot) * 2\n",
    "        plot_row_overlay = plot_row_original + 1\n",
    "        plot_col = class_idx % cols_plot\n",
    "\n",
    "        if samples_by_class[class_idx] is None:\n",
    "            print(f\"[WARN] No sample found for class '{config.classes[class_idx]}' for GradCAM.\")\n",
    "            # Hide the axes for this missing class\n",
    "            if plot_row_original < rows_plot and plot_col < cols_plot:\n",
    "                 axes[plot_row_original, plot_col].set_visible(False)\n",
    "            if plot_row_overlay < rows_plot and plot_col < cols_plot:\n",
    "                 axes[plot_row_overlay, plot_col].set_visible(False)\n",
    "            continue\n",
    "\n",
    "        input_tensor = samples_by_class[class_idx].to(device) # Transformed image tensor\n",
    "        \n",
    "        # Generate CAM for the true class\n",
    "        cam_tensor = grad_cam_instance.generate_cam(input_tensor, target_class_idx=class_idx)\n",
    "        cam_np = cam_tensor.cpu().numpy()[0, 0] # (H, W)\n",
    "        \n",
    "        # Get original image for display (unnormalized, original size)\n",
    "        original_img_tensors, _ = get_original_images(config, [indices_by_class[class_idx]])\n",
    "        original_img_tensor_display = original_img_tensors[0] # (C, H_orig, W_orig)\n",
    "        \n",
    "        # Resize original image to model input size for consistent display with heatmap\n",
    "        # Using NEAREST to preserve pixelation of original low-res CIFAR images if upscaled\n",
    "        img_display_resized_tensor = TF.resize(original_img_tensor_display, \n",
    "                                               [config.model_input_size, config.model_input_size], \n",
    "                                               interpolation=TF.InterpolationMode.NEAREST)\n",
    "        img_display_np = img_display_resized_tensor.permute(1, 2, 0).numpy() # (H, W, C) for imshow\n",
    "\n",
    "        # Plot Original Image\n",
    "        ax_orig = axes[plot_row_original, plot_col]\n",
    "        ax_orig.imshow(img_display_np)\n",
    "        ax_orig.set_title(f\"{config.classes[class_idx]} (Input)\", fontsize=9, pad=2)\n",
    "        ax_orig.set_xticks([]); ax_orig.set_yticks([])\n",
    "        \n",
    "        # Plot Overlay\n",
    "        ax_overlay = axes[plot_row_overlay, plot_col]\n",
    "        ax_overlay.imshow(img_display_np) # Base image\n",
    "        current_mappable = ax_overlay.imshow(cam_np, cmap=cmap_heatmap, alpha=0.55) # Overlay heatmap\n",
    "        if heatmap_mappable is None: heatmap_mappable = current_mappable # Store for colorbar\n",
    "        ax_overlay.set_title(f\"{config.classes[class_idx]} (GradCAM)\", fontsize=9, pad=2)\n",
    "        ax_overlay.set_xticks([]); ax_overlay.set_yticks([])\n",
    "\n",
    "    # Hide any unused subplots at the end if num_classes is not a multiple of cols_plot\n",
    "    for i in range(num_classes_to_plot, ((num_classes_to_plot + cols_plot -1) // cols_plot) * cols_plot ):\n",
    "        plot_row_original = (i // cols_plot) * 2\n",
    "        plot_row_overlay = plot_row_original + 1\n",
    "        plot_col = i % cols_plot\n",
    "        if plot_row_original < rows_plot and plot_col < cols_plot:\n",
    "            axes[plot_row_original, plot_col].set_visible(False)\n",
    "        if plot_row_overlay < rows_plot and plot_col < cols_plot:\n",
    "            axes[plot_row_overlay, plot_col].set_visible(False)\n",
    "\n",
    "    if heatmap_mappable:\n",
    "        # Add colorbar to the right of the subplots\n",
    "        fig.subplots_adjust(right=0.88) # Make space for colorbar\n",
    "        cbar_ax = fig.add_axes([0.9, 0.15, 0.02, 0.7]) # [left, bottom, width, height]\n",
    "        cbar = fig.colorbar(heatmap_mappable, cax=cbar_ax)\n",
    "        cbar.set_label('Activation Strength', fontsize=9)\n",
    "        cbar.ax.tick_params(labelsize=8)\n",
    "    \n",
    "    plt.figtext(0.5, 0.01, f\"GradCAM for {model_name_str}\", ha=\"center\", fontsize=9, style='italic')\n",
    "    plt.savefig(f\"{config.output_dir}/gradcam_visualization_{model_name_safe}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    grad_cam_instance.remove_hooks() # Important to remove hooks after use\n",
    "    print(f\"[INFO] GradCAM visualizations for {model_name_str} saved.\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 60); print(\"S_meta (EfficientNet-B1) CIFAR-10 Standalone Evaluation\"); print(\"=\" * 60)\n",
    "    start_time = datetime.now()\n",
    "    config, device = setup_environment()\n",
    "    \n",
    "    try:\n",
    "        test_dataset = get_test_dataset(config)\n",
    "        test_loader = create_data_loader(test_dataset, config)\n",
    "        model = load_model(config, device)\n",
    "        \n",
    "        targets, predictions, probabilities = run_inference(model, test_loader, config, device)\n",
    "        \n",
    "        accuracy, loss, macro_f1 = analyze_results(\n",
    "            targets, predictions, probabilities, \n",
    "            config.classes, config, \n",
    "            model_name_str=\"S_meta_EffNetB1_CIFAR10\" # Consistent model name\n",
    "        )\n",
    "        \n",
    "        visualize_predictions(\n",
    "            model, test_dataset, config, device, \n",
    "            model_name_str=\"S_meta_EffNetB1_CIFAR10\"\n",
    "        )\n",
    "        \n",
    "        visualize_gradcam(\n",
    "            model, test_dataset, config, device, \n",
    "            model_name_str=\"S_meta_EffNetB1_CIFAR10\"\n",
    "        )\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(f\"S_meta Evaluation on CIFAR-10 completed successfully.\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}%, Log Loss: {loss:.4f}, Macro F1-Score: {macro_f1:.3f}\")\n",
    "        print(f\"Results saved to directory: '{config.output_dir}'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Main evaluation pipeline failed: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        print(\"=\" * 60)\n",
    "        print(\"S_meta Evaluation on CIFAR-10 failed.\")\n",
    "        return 1 # Indicate failure\n",
    "    finally:\n",
    "        end_time = datetime.now()\n",
    "        print(f\"Total execution time: {end_time - start_time}\")\n",
    "        print(\"=\" * 60)\n",
    "        # Clean up CUDA memory if possible\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    return 0 # Indicate success\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
